{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Physics-based loss and machine learing approach in application to fluids flow modelling: 2D flow domains**\n",
        "\n",
        "The program recieves an image of the flow domain and the flow rate value, then calculate velocity distribution. The main idea is power loss minimization. The main unknown function is the stream function $\\psi = \\psi(x_1, x_2)$ that determines the velocity field $\\textbf{V} = [[v_1, v_2]]$, where $v_1 = \\frac{\\partial \\psi}{\\partial x_2}$, $v_2 = - \\frac{\\partial \\psi}{\\partial x_1}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "RJkKJ83igGYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "ozT2l1DxVSOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "s3KFs0M9r7EQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "jPSaJ-z614Tm"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "ydwhZV95sFoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "Go3JwW4hICsK"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "BT8OQ6AkVb6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional functions"
      ],
      "metadata": {
        "id": "Hw2AD3oWsfJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical derivative"
      ],
      "metadata": {
        "id": "2JAf1YAHtV15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mydiff(j,y,dx):\n",
        "  '''The function calculates the first order derivative in a specific direction \n",
        "     'dx' at a specific point 'j' for a given array 'y' \n",
        "     using parabolic approximation\n",
        "  '''\n",
        "  dydx = 0\n",
        "  n = len(y)\n",
        "  if j==0:\n",
        "    dydx=(-y[3]+4*y[2]-3*y[1])/(2*dx)\n",
        "  elif j==n-1:\n",
        "    dydx=(3*y[j]-4*y[j-1]+y[j-2])/(2*dx)\n",
        "  else:\n",
        "    dydx=(y[j+1]-y[j-1])/(2*dx);\n",
        "  return dydx"
      ],
      "metadata": {
        "id": "MSTF3qPgtbn8"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_diff(f, dx1, dx2):\n",
        "  '''function to find partial derivatives of a two variables function:\n",
        "  i - index along x1\n",
        "  j - index along x2\n",
        "  for internal points - central differences e.q. df_dx = (f_{i+1}-f_{i-1})/(2*dx)\n",
        "  for boundaries - left and right finite differences e.q. df_dx = (f_{i+1}-f_{i})/dx or df_dx = (f_{i}-f_{i-1})/dx\n",
        "  '''\n",
        "  n1, n2 = f.shape\n",
        "  df_dx1, df_dx2 = torch.zeros(n1,n2), torch.zeros(n1,n2)\n",
        "  # x1 derivative:\n",
        "  df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:])/(2*dx1)\n",
        "  df_dx1[0,:] = (f[1,:] - f[0,:])/dx1\n",
        "  df_dx1[n1-1,:] = (f[n1-1,:] - f[n1-2,:])/dx1\n",
        "  # x2 derivative:\n",
        "  df_dx2[:, 1:n2-1] = (f[:,2:] - f[:,:-2])/(2*dx2)\n",
        "  df_dx2[:, 0] = (f[:,1] - f[:,0])/dx2\n",
        "  df_dx2[:,n2-1] = (f[:,n2-1] - f[:,n2-2])/dx2\n",
        "  return df_dx1, df_dx2"
      ],
      "metadata": {
        "id": "5P2RND6cYEOK"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical integrals: single and double"
      ],
      "metadata": {
        "id": "1i1RAg4ozeGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singleIntegral(f,lowerLim,upperLim):\n",
        "  '''The function calculates the single integral using Simpson's formula. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the difference between the upper and lower limits.\n",
        "  '''  \n",
        "  sglInt = 0\n",
        "  n = len(f)\n",
        "  x = torch.linspace(0,1,n)\n",
        "  dxn = x[1]-x[0]\n",
        "\n",
        "  for i in range (1, (n-1), 2):\n",
        "    sglInt += (f[i-1] + 4*f[i]+f[i+1])*dxn/3\n",
        "  if (n % 2) == 0:\n",
        "    sglInt += (f[-1]+f[-2])*dxn/2\n",
        "\n",
        "  sglInt = sglInt*(upperLim-lowerLim)\n",
        "\n",
        "  return sglInt"
      ],
      "metadata": {
        "id": "MbSgsSbO0srV"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doublelIntegral(f,lim1,lim2):\n",
        "  '''The function calculates the double integral using Simpson's formula twice. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the differences between the upper and lower limits.\n",
        "  '''\n",
        "  dblInt = 0\n",
        "  n = f.shape\n",
        "  x1 = torch.linspace(0,1,n[0])\n",
        "  x2 = torch.linspace(0,1,n[1])\n",
        "  dx1n = x1[1]-x1[0]\n",
        "  dx2n = x2[1]-x2[0]\n",
        "\n",
        "  for i in range (1, (n[0]-1), 2):\n",
        "    for j in range (1, (n[1]-1), 2):\n",
        "      dblInt += (f[i-1][j-1] + f[i+1][j-1] + f[i-1][j+1] + f[i+1][j+1] + \n",
        "                   4*(f[i][j+1] + f[i][j-1] + f[i-1][j] + f[i+1][j]) + \n",
        "                   16*f[i][j])*dx1n*dx2n/9\n",
        "          \n",
        "  dblInt = dblInt*(lim1[1]-lim1[0])*(lim2[1]-lim2[0])\n",
        "\n",
        "  return (dblInt)"
      ],
      "metadata": {
        "id": "fxibGVL-zkCW"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check double integral "
      ],
      "metadata": {
        "id": "qyl0qTFMj-lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 101\n",
        "x = torch.linspace(0,1,ss)\n",
        "y = torch.linspace(0,1,ss)\n",
        "y = y.reshape(1,-1).t()\n",
        "z = (x*x) * (y*y)\n",
        "print(doublelIntegral(z,[0,1],[0,1]),'- calculated', 1/9, '- exact')"
      ],
      "metadata": {
        "id": "byisjmu7c8C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a28b424-3fb7-4682-eabb-fa3280093494"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1111) - calculated 0.1111111111111111 - exact\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color filter "
      ],
      "metadata": {
        "id": "lon3t_mIeGEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colorFilter(img, color):\n",
        "  white = (255,255,255,255)\n",
        "  black = (0,0,0,255)\n",
        "  width,heigth = img.size\n",
        "  for i in range(width):\n",
        "    for j in range(heigth):\n",
        "      if img.getpixel((i,j)) == color:\n",
        "        img.putpixel((i,j),black)\n",
        "      else:\n",
        "        #print(img.getpixel((i,j)))\n",
        "        img.putpixel((i,j),white)\n",
        "  return (img)"
      ],
      "metadata": {
        "id": "626DXTn0eKR-"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Major functions\n",
        "\n",
        "Distributions: the velocity components [[$v_1$, $v_2$]], the strain rate tensor components [[$\\xi_{ij}$]], $\\xi_{ij}=\\xi_{ji}$ . And the shear rate intensity Î—. "
      ],
      "metadata": {
        "id": "mH8zURs8A1Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def velocityDistr(psi,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = psi.shape\n",
        "  dpsidx1, dpsidx2 = num_diff(psi, dx1n, dx2n)\n",
        "  v1 = dpsidx2/lim2[1]\n",
        "  v2 = - dpsidx1/lim1[1]\n",
        "\n",
        "  return v1,v2"
      ],
      "metadata": {
        "id": "WMUIipgs5t3Q"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = v1.shape\n",
        "  dv1dx1, dv1dx2 = num_diff(v1, dx1n, dx2n)\n",
        "  dv2dx1, dv2dx2 = num_diff(v2, dx1n, dx2n)\n",
        "\n",
        "  xi11 = dv1dx1/lim1[1]\n",
        "  xi12 = 0.5*(dv1dx2/lim2[1] + dv2dx1/lim1[1])\n",
        "  xi22 = dv2dx2/lim2[1]\n",
        "  EtaEta = (2*(xi11*xi11 + 2*xi12*xi12 + xi22*xi22))\n",
        "\n",
        "  return xi11,xi12,xi22,EtaEta"
      ],
      "metadata": {
        "id": "716qlRJoNglx"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "nzMpruhsYD38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image of the flow domain"
      ],
      "metadata": {
        "id": "itN_H_kFke1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path"
      ],
      "metadata": {
        "id": "3NCXTaNK4V4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " path =  Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss')\n",
        " imgPath = path/'ToyDataset'\n",
        " imgList = imgPath.ls()\n",
        " imgPath.ls()"
      ],
      "metadata": {
        "id": "tDbZIropJMjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3978c8-e0de-4a7e-8b28-61df77a754fc"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates and ball.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates with notch.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates.png')]"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometry\n",
        "The domain of size *'L x L'*  with flow channel is represented as an image of size *'imgSize x imgSize'*. S1 is the upper wall with black label [0 0 0]. S2 and S4 are outlet and inlet surfaces, respectivelly. S3 is the lower wall with blue label [0 0 255]. "
      ],
      "metadata": {
        "id": "ORhTWZZvVw7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = 0.1 # L x L flow domain\n",
        "imgSize = 512 # imgSize x imgSize pixels image\n",
        "imgNo = 2\n",
        "upperWallColor =  (0, 0, 0,255)\n",
        "lowerWallColor =  (0, 0, 255,255)\n",
        "#Normalized coordinates\n",
        "x1n = torch.linspace(0,1,imgSize)\n",
        "x2n = torch.linspace(0,1,imgSize)\n",
        "dx1n = x1n[1] - x1n[0]\n",
        "dx2n = x2n[1] - x2n[0]\n",
        "lim1 = [0, L]\n",
        "lim2 = [0, L]\n",
        "#Visualisation\n",
        "figSize = 3\n",
        "#Training\n",
        "noOfEpoch = 1000\n",
        "learnRate = 0.001"
      ],
      "metadata": {
        "id": "y8Q_jxpUYIEm"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "domainMask "
      ],
      "metadata": {
        "id": "1hKq9A5gtHzs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "3f4913ad-7bd2-4de7-daca-71cab62d7657"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB+CAYAAADiI6WIAAABQ0lEQVR4nO3cwQ3AMAgAMVJl/5XpGHmcPQHSiSecmdkh53s9AG8IHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81N31rr7IxkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkedGeeyRTY+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aN+UssG9+2j5aIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=126x126 at 0x7FA9620E8690>"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create masks for the walls and resize image"
      ],
      "metadata": {
        "id": "45EnY5VmEcjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2n.dtype"
      ],
      "metadata": {
        "id": "SgL2YvbN3rmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aaba41c-4691-49e3-9d25-d452e8b03f91"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "upperWallMask = colorFilter(domainMask, upperWallColor)\n",
        "upperWallMask = upperWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#upperWallMask"
      ],
      "metadata": {
        "id": "lmyMgC4op_o_"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "lowerWallMask = colorFilter(domainMask, lowerWallColor)\n",
        "lowerWallMask = lowerWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#lowerWallMask"
      ],
      "metadata": {
        "id": "FF424vauuCi8"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kinematic properties\n",
        "The velocity is equal to zero on all the surfaces. The flow rate is known."
      ],
      "metadata": {
        "id": "XaVb_Ejsmynq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 1 #flow rate through the inlet (outlet) boundary, m^3/s\n",
        "psim = 0 # lower wall\n",
        "psip = Q # upper wall\n",
        "psi00 = torch.linspace(0,1,imgSize, dtype=torch.float32)*torch.ones(imgSize,imgSize)\n",
        "psi0 = torch.t(psi00)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0)"
      ],
      "metadata": {
        "id": "Gb4BFZNWnBsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "ec8c220e-49f9-43a4-fd7c-42081af9ead1"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa962036190>"
            ]
          },
          "metadata": {},
          "execution_count": 267
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAADKCAYAAAACTBTsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOS0lEQVR4nO3db7BdVXnH8e/v/jFIblKIIDDihBGTUq8doDpTSodKK/UPfaEjLxoDjtTSWBj6Z5hOS6dQI3QqTvuqU8TSJiMlWLROsCKOLc5AtVNxzFRjJ5rGYTpBNChqbJIbkhh4+mLtS3ZOcvc999yz73k2+X1m9kzOWefes/fJee6z1tpr70cRgZkt3Niod8Csqxw8ZgNy8JgNyMFjNiAHj9mAHDxmA3LwmA2o9eCRtErSQ5JmJO2WtL7t9zRbChNL8B53A0eAc4BLgEckbY+IHUvw3matUZsrDCQtB/YCr4+IXdVz9wPfjYhbW3tjsyXQdrdtLXB0NnAq24Hplt/XrHVtd9umgH09z/0fsKL3hZI2ABsAxhl/w+msbHnXzOZ3iBmOxGGdrK3t4DkAJ0TBSmB/7wsj4l7gXoCVY6visom3trxrZvN74ui/ztnWdvDsAiYkrYmIb1fPXQzMM1kgGB9vedfM+nD0pEkHaDl4ImJG0lbgDkk3UGbb3gFc3vRzAqS5d9psqTR9C5diqvomYDPwA+BHwI3zTlPLmceSaPgj3nrwRMSPgXcu+AfHvPjBcluKzLNwEhp38FgCo8w8AxHutlkODYOenMEDjRFvlkHS4PGEgWXRwW6bp6othe5125x5LIuuZR7wmMfSyxk8AjxVbRl0stvmzGMpdK3bJrzCwHLoXuaBcLfNkksaPO62WRZd7LY581gGXey2OfNYdjmDRyI8YWAZdG5VNfheppZe4uBx9FhuKYMnBDHuMY+NXnjCwGz4cgaPRIw5eCyBbk4YOHgst7TB48xj2fU1pSXpZknbJB2W9LGetjdL2inpoKTHJK2utS2TtFnSPknPSLqlr70qdz305i3BNvfXtN/M8z3gL4C3Ai+vBcdZwFbgBuBh4E7gE8Bl1Us2AmuA1cC5wGOSvhkRn5/vDZ15LLu+gicitgJIeiNwfq3pXcCOiPjnqn0j8ENJF0XETuC9wPURsRfYK+nvgeuB5uCRPFVtOWju7+FixzzTlHo7wIv3pn4SmJb0feC8env17/7uHurYseQWGzxTwLM9z83W35mqPe5tO0G9Ps+y085wt81SaKqbuNjgaaq/c6D2+FBP2wnq9XlWrDw/ms7smmWw2ODZQRnXAFDVIL2QMg7aK2kPpR7Po9VL+qjNA8jLcyyJxc62SZqoXjsOjEs6DTgKPAT8laRrgEeAPwe+UU0WAPwjcJukbZRq2L8D/FZ/O+3gsdz6zTy3AR+oPb4O+GBEbKwC52+BLcBXgHW1130AuAfYDTwHfLifaWoE4UXVlkHD3/BWS8kPasUZ58elV/z+qHfDjK996W/Y/5OnTxpCXp5jNqCUwVOu5xn1Xph18noeEZ4wsBTaW2HQDk8YWBbdyzx4eY6llzZ4PGFg2eUNHseOJZcyeMJjHkuig7NtDh7LL23weMLAsssZPPKEgSXRyW6bY8eSyxs8HvNYcjmDR3jMYzl0rdsWOPNYDm3ew6A9zjyWXM7g8UlSy6Jr3TZw8Fh+eYPH1/NYcjmDR7gmqeXQyW6bE48llzJ4PFVtWTRNVc/7Fa1q7GyStFvSfklfl/T2Wvvw6/PAsROl3ryNcmvQT+aZAL4DvAl4Crga+KSkn6fcj3r49XnkzGNJNATQvMETETOUIJj1WUn/C7wBeAVt1OfBwWP5LXjMI+kcYC3lhu034vo8dopaUPBImgQeAO6LiJ2SWqnPM7HyTGcey2Ex3bYXf4c0BtwPHAFurp5upT7Py897dTjzWHb9lhgRsIlSJuTqiPhp1dROfR58nsfy6zfz3AP8HHBVRDxXe77F+jx97pnZiMwbPNV5m/cDh4FndGzN2fsj4oE26vP41lOWxaJuPRURu2nIAxHxBeCiOdoOA++rtgVx8Fh2KZfnAO62WXo5g8fdNstiGFPVS075yj2a1aUNHmceyy5n8PSxotVsSXSx2+bMY9mlDR5nHssuZfAEXp5jOXTvpoeeqrYsujjm8VS1ZZc2eJx5LLucweOpasuii902Zx7LLm3weMxj2eUMHuHb7VoO3eu2BTHmzGMZzP09TBo8eMLA0nPwmA0oZ/AITxhYDt0b8+AJA0svb/A481hyOYPHU9WWRUO3ra+vqKQtkvZUdXZ2Sbqh1tZSfZ7w5m30W4N+M8+HgN+OiMOSLgIel/Q1ys0Mh1+fB5DP81hyfQVPRNTvLx3VdiGlRs/w6/MoHDyWQ0P26XtkIekjkg4CO4E9wOeAaXrq8wCz9XnO5OT1eabn+P0bJG2TtO35/TOMvJyeN2+iUd8TBhFxk6TfA34JuJJy7+qh1eeplxhZ9ppXhTOPZbeg2baIeB74D0nXUarCDa0+T695gt5s5Aadqp6gqsNDC/V5JNDYCwPumtnwqOGveD8lRl4J/BrwWUqZkKuAd1fbl2mpPk/TTptl0E/mCUoX7aOUCYbdwB9GxGcA2qjPAzDmMY8l1099nmeBNzW0D70+jxSMudtmCahhqjrn8hzcbbP80gaPM49llzZ4nHgsu5TBIwXjzjyWQEfHPJ5ts9xSBo+AcU9VWwJNw4eUwYNwt81yWMwKg1EQwZi7bZaAunjftnEHjyWXMngEzjyWgsc8ZoPymMdsMB0d8zjzWG4pg8djHsuic2MeKZjwmMcS6OTynAk9P+pdMGuUMnjcbbMs3G0zG1Anu21jDVOEZhmkDB4RTIx5zGOj17nzPMJr2yyHzo15ACZ8ktSSW1DwSFoD/DfwqYi4rnpuPaUEyVmUO4O+LyJ+XLWtAjYBbwF+CPxpRHx8/vcJJt1tswSGOWFwN/DVY79Y08DfAb8B/BflRu0f4diND+8GjlDuFnoJ8Iik7T0lS07cYTxhYDkMpdsmaR3wE+A/gddWT18LPBwRX6xeczvwLUkrgBeAa4DXR8QByg3iPwO8B7i1eYc9YWA5LHrCQNJK4A7KPatvqDVNU4IJgIh4UtIRYC0leI5GxK7a67czx91HJW0ANgCsOPd0xvGYx3LrN/PcCWyKiKd1/K08pzi+/g4cq8HzPLBvjrYT1OvznDu9KnyS1DJYbJWESyiVES49SXNTfZ4XGtqa35Nw5rEUFtttuxK4AHiqyjpTwLik11Fqi1784htJrwGWAbsowTMhaU1EfLt6SX/1efBsm+Ww2OC5F3iw9viPKMF0I/BK4MuSrqDMtt0BbI2I/QCStgJ3VKXnLwHeAVzez057ts2y66fEyEHg4OxjSQeAQ1XpkWcl/S7wAPAK4AscX7zqJmAz8APgR8CN801TQ5kenPQlCZbAUFcYRMTGnscfB0564rM6WfrOhb5HOUl6dKE/ZjZ0nVtVLWDc3TZLoHNr20S422YpdG5VNcCYF4ZacimDx5nHsuhc5iljHmceG72Ojnk822aj173Mo+Bl7rZZAp2bqgZPGFh+KYNnDGcey6FpmVjK4AEY84SBJZcyeOTMY0l0b8IAZx7LoZNT1c48lkH3Mo98nsdy6ORUtVdVW3Ypg8cXw1kWnRzzOPNYBt0b8wCTXmFgCXQu84BvAGL5pQyesjzHmcdGr6PLc8xy6/de1Y8DlwGzJ1++GxE/W7UNv8QIMNnU2TRbIsMa89wcEf9w3C9uq8SIxMuabhJstkTU8D1cbLetpRIj7rZZDsPKPB+SdBfwP8CfRcTjDLHESO8OT8rhY6M3jOD5E+CblC7YOuDhqnrC0EqM1OvzvPpV44w37rbZ6PUVPBHxldrD+yS9G7iaIZYYqdfn+YWLl8WkxvvZNbNWqeGP+KBjnqBktB20UmIExjzqsQQW1W2TdAbwi8C/U6aqfxP4FeAPgElaKDEihDOPZdCUeRTRvAxG0tnA54CLKOOYncDtEfFo1b4euItaiZGe8zybgV+nlBi5tb9S8tpPmZg4VZ1FOS92Ksp27Ksj4uyTNcwbPKMgaVtEvHHU+zEqp/Lxd+nYPbAwG5CDx2xAWYPn3lHvwIidysffmWNPOeYx64KsmccsPQeP2YBSBY+kVZIekjQjaXd1DuklQdIySZuq49ov6euS3l5rf7OknZIOSnpM0uqen90saZ+kZyTdMpqjGA5JayQdkrSl9tz66rOZkfTp6hzhbFvK70Wq4OH463+uBe6prhl6KZgAvkNZVf4zwG3AJyVdIOksYCtwO7AK2AZ8ovazG4E1wGrgV4E/lvS2pdv1obsb+Orsg9p1Ye+h/N8fpFwXVn99uu9FmgkDScuBvZTrf3ZVz91PuWq18fqfrpL0DeCDlNUZ10fE5dXzyyln2S+NiJ2Svle1/1vVfiewJiLWzfGr05K0DngXZZX+ayPiOkl/CVwQEeur11wIfIvyubxA0u9FpsyzlpNf/zPyvzBtkHQO5Zh3UI5x+2xbRMwATwLTks4Ezqu309HPRdJKyvrH3m5n7/E/Sck0a0n8vcgUPFMs4PqfLpM0CTwA3BcRO2m+Lmqq9ri3rWvuBDZFxNM9z893/Cm/F5nuntN0bdBLhqQx4H7KX9abq6ebjv1A7fGhnrbOqC6evAq49CTNQ7subCllCp5dDHj9T1eo3E1iE2Xge3VE/LRq2gG8t/a65cCFwI6I2CtpD+WzeLR6SRc/lyuBC4CnqptqTAHjkl4HfJ4WrgtrXUSk2YAHgX8ClgO/TEnP06PeryEe30eBJ4CpnufPro71GuA04MPAE7X2uyjXU51JuTRkD/C2UR/PAo/9dODc2vbXwKeqY5+mdM2uqP7vtwAPZv9ejPxD7fmAVwGfBmaAp4D1o96nIR7basoVuIco3ZTZ7dqq/SrKtVLPAY9TZp9mf3YZ5bqofcD3gVtGfTxD+Dw2Altqj9dX/+czwL8Aq7J/L9JMVZt1TabZNrNOcfCYDcjBYzYgB4/ZgBw8ZgNy8JgNyMFjNiAHj9mAHDxmA/p/VIcgdv2GhCEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psi00.dtype"
      ],
      "metadata": {
        "id": "H-xEZhto3cLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0562b9f0-fce4-44dd-87cc-2e27e7d7faf0"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wallsMask = (tensor(upperWallMask)[:,:,1]*tensor(lowerWallMask)[:,:,1])\n",
        "inverseUpperWallMask = (tensor(upperWallMask)[:,:,1]/(-255)+1)\n",
        "psi0Masked = (psi0*wallsMask) + (inverseUpperWallMask*Q)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0Masked)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "id": "lyOiYXNSUVnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "fdf00142-f56f-4fd9-edc0-e37e325afffd"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'psi function with mask')"
            ]
          },
          "metadata": {},
          "execution_count": 269
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAADWCAYAAAB2WNYMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASuElEQVR4nO3de7RcZX3G8e+TBBNNiCbcVQwCgUiwgERQkBIuVoHVqlAVgZa0chGKqy12KasFi2BRa5e6VotIbKiYsIiWghdQKUiAYlEa5VJCQgRJAkIMSEpuJJDk1z/e9+DO5JyZOe+5zJ7k+ay1V87sd8/Muyf7mXfPnr3np4jAzPpvRKc7YNatHB6zQg6PWSGHx6yQw2NWyOExK7RNh0dSSDqjxTLTJT0s6WVJdw5T15r1Z4akjZ3uR2/afD1r2//eDKS/23R4gD2AG1oscxXwC2Bv4OQh71Em6Y15Y5ze0PQt4A3D1Y9+2uL1lLRR0ozOdaezRnW6A0MpIpa3sdhk4IqIeHKo+9OOiHgReLHT/ehNm6/n9iMiajkBdwLXAJ8HngNWATOBMZVl3gX8BFidpweB91TaAzijj8efntur04zK/Dc2LL8RmJH/3isv8yHgZmAd8Kue9sp9xgFfAZ4ENgBLgL+t9K06LcnzZwAbGx7nRODn+TFWAF8FxlbavwHcDpwDLM2v1feA3Zq8vh8FnqrcfnPux5zKvLOBp3t7PfO6bLEO1f4DR5JG9HW5729v8f/dsw4fB54C1gD/CuwAfCyv18q8Dbyqcr93523leeAF4C7gsIbHPgtYCKzPy93d8//b+HoDY4Abgf8F3tC0z50OSYvwrAK+DrwF+MO84Xw5t4/KL8SXSKPHZOADwFFthudVwO55mb/If7+a/oXnV6QA7QtckZfZLy+jvA6/At5P2i38feDs3H5IfoyT83Pv0sd/5u/lx/0yMAU4AVgGzG7Y8F4ArgcOBN4JPFFdppf13zs///6VMK0Afl1Z5nrguj7Cs0vu11/m/u9e6f/mvIEelfv8w9yfUS3Cswq4tvL/vT7f95t53kmkUfm8yv0+kP8P9gemkgL3PLBTbj809/NPgUnAW0lh2io8wATgHlIAX9dyG+10SFqEZwkwsjLvnPyCjs0rGsD0Jo/RZ3j6Wob+hefCSvtI0uh3br59XF5mWh/P+8be+s/W4ZkN3NewzPvyBjqpsuGtAEZXlvkU8EyLdV8CnJ//vg74TN6Ap+R5y4GPNnmtXnlNGvofwNsq8w6nEtQm4VnBlqPKLaS9jup6fRe4ocnjjCCNUKdXwvUCML6P5Wfk9dgTWEAadcb09fjVqe4HDO6LiE2V2z8BRgP7RMRK0rvMrZJ+KOkiSfsPc/8e6Pkj93MFsFuedSiwMiLmD/A5ppLexavuIo1sB1TmLYqIDZXbT1f60pd5wLH572OAW4H/Ao6VNDXf/46CPgdpF7raF9roz8KIeKlyeznwaMN6LQd27bkh6c2SZkt6TNIqUvhfSxplAG4jjf5PSJor6RxJOzc87wjgXuBh4I8jYn3rVezyo20RcTZpI70NOBp4WNK5A3zYzflf9cyQNJLeX6uXGm5HH8sNh976ot4WrLgDOEbSAcCOwH153rF5WhIRTxT0ZXPDm17PqfutXpuXG25HH/Oqj3Mz8CbSrvc7gIPJIxhARKwBppFGoMWkz0+PSTq02t/8OMeQ3qzaUvfwvD1vuD2OIH1ofrxnRkQ8HBFfiogTgFmkXbuBWJH/fX1l3sG03hAb/RyYIGlaH+09G/vIPtp7LCB9Vqo6mrQRLehnnxrNAyYCFwJ3R8RGUnimk3Y7W406L9G6/0NG0k6k0ffzEXFrRDxC2q3ftbpcRGyKiLsj4tOkN9tngNMaHu480tcE8yQd3M7z1z08OwFXSnqLpJOAy4GrI2KtpH0lfUHSuyRNkvRO0gfURwb4nI+RjuxcKmmKpHeRPqz398KnO0i7QN+S9L68e3GkpLNy+3OkI0p/IGl3SRP6eJwvAm+T9OXcn/cC/0z6IL+svytXFRFPAb8EzuR3QXmA9EZxEq3D8wRp5Hp9L7tCw2El8CxwtqT98jZwPZVD/fm1/2tJh0p6E+ngzZ40bCeRfJx0wOKOJm96r6h7eG4gfQi/B5hLGlovym1rSUfY5pKG4/8A/hu4YCBPmN99P0x697ofuBL4O363O9fu4wRpA/wB8DXgUWAOsHNu30za1fgQ6dDs/X08zkPAH5FGnwdJBxBuIe1+DIZ5pCOXd1T6fWd1XhOfIL2TLyFtxMMqv4YfBPYBHiIddPgKaWTpsZJ05O5HpO3kH4HPRsSsPh7zE8DVwO2S3tHs+ZWPONROPlXmsYg4q9WyZp1Q95HHrLaGPDySJkq6SdJaSUslNX5QM+tKw3Fu25WkozK7kY5a3SLpwYhoeqQoIqYPQ9/Mig3pZx5JY0kf2A6MiMV53mzSKSAXNb2zWc0N9W7bfqRTTRZX5j1IP76IMqurod5tG0c6XaLqBdK32VuQdA75C86xr9GhU/Z91RB3zay1JU++zHPPb+r1C/KhDs8aYHzDvPGk7262EBEzSaebM+2gMXHfrXsOcdfMWjvsPX1f5jXUu22LgVGSJlfmHcTATysx67ghDU9ErCWd4n2ZpLGSjiSdTj97KJ/XbDgMx5ek55MuMltBOu/ovFaHqc26wZB/zxMRz5NOxjPbpvj0HLNCDo9ZIYfHrJDDY1bI4TEr5PCYFXJ4zAo5PGaFHB6zQg6PWSGHx6yQw2NWyOExK+TwmBVyeMwKOTxmhRwes0IOj1khh8eskMNjVsjhMSvk8JgVais8ki6QNF/SBknfaGg7TtIiSeskzZM0qdI2WtI1klZJWi7pwkHuv1nHtDvyPA18FrimOjMXcb0RuIRUVXk+qaJwj0tJdUMnkcp0fzIXpDXrem2FJyJujIjvAL9taDoZWBAR/x4R60lhOUjSlNx+JnB5RKyMiIXA14EZg9Jzsw4b6GeeqaR6O8Arv039ODA1l0bfo9qOa/PYNmSg4RlHqrdT1VN/Z1zldmPbViSdkz9XzX/2t5sG2C2zoTfQ8DSrv7OmcruxbSsRMTMipkXEtF12GjnAbpkNvYGGZwGp3g7wSg3SfUifg1YCz1TbcW0e24a0e6h6lKQxwEhgpKQxkkYBNwEHSjolt38aeCgiFuW7fhO4WNKEfBDhbOAbg74WZh3Q7shzMfAicBFwRv774oh4FjgF+AdS1evDgVMr9/t70gGEpcBdwBcj4keD03WzzhrSUvKlXJPU6uKw9zzJ/AfX91rQ16fnmBVyeMwKOTxmhRwes0IOj1khh8eskMNjVsjhMSvk8JgVcnjMCjk8ZoUcHrNCDo9ZIYfHrJDDY1bI4TEr5PCYFXJ4zAo5PGaFHB6zQg6PWSGHx6xQy/DkGjuzJC2VtFrSA5JOqLS7Po9tl0a1ucyTwNHAMuBE4NuS3kr6PeobgbOA7wOXk+rzvCPf91J+V59nd2CepEda/fDhwnUTOOz+D/Z7ZcwG28J1/9ZnW8vw5LIhl1Zm3SzpCeBQYCdyfR4ASZcCz0makn9y90xgRv7d6pWSeurzNA3P5tWjeHHeLq26ZjbkNq/uOyLtjDxbkLQbsB/pB9vPo6E+j6Se+jy/off6PO9v74n62zOz4dWv8EjaAbgOuDYiFkkaBzzbsFhxfR7gHIBR4ycQPpRhddDkTbzt8EgaAcwGXgIuyLPbrc+zvqFtKxExE5gJ8Oo99gyPPFZ3bYVHkoBZwG7AiRHxcm5aQPpc07PcFvV5JPXU57ktL9J2fZ5weKzm2h15rgLeAhwfES9W5t8EfFHSKcAt9F2fZz4peGcDf9bWMzo8VnMtw5O/tzkX2AAsT4MQAOdGxHU5OP8CzAF+xtb1ea4i1ed5EfhCO/V5Qvgzj9VCsz2gdg5VL6XJOBARtwNT+mjbAPx5nvrF4bG66/eh6mHj3TaruXqGx7ttVheDcah62Kl+5R7NqmobHo88Vnf1DI/wZx6rh27cbfPIY3VX2/B45LG6q2V4Ap+eY/XQ7LBVLcPjQ9VWG934mceHqq3uahsejzxWd/UMjw9VW110426bRx6ru9qGx595rO7qGR7hn2O0eui+3bYgRnjksTroezusaXjwAQOrPYfHrFA9wyN8wMDqofs+8+ADBlZ79Q2PRx6ruXqGx4eqrS6a7La1tYlKmiPpmVxnZ7GksyptQ1OfR+HJU+enJtodeT4HfDQiNkiaAtwp6X7SjxkOen0eAPl7Hqu5tsITEdXfl4487UOq0TPo9XlQODxWD01Gn7Y/WUj6qqR1wCLgGeAHwFQa6vMAPfV5JtB7fZ6pfTz+OZLmS5q/afVaXjmz2pOnTk5NtH3AICLOl/Rx4J3AdNJvVw9afZ5qiZHRe78hPPJY3fXraFtEbALukXQGqSrcoNXnadQi9GYdV3qoehS5Dg9DUJ9HAo3YXNg1s8GjJu/i7ZQY2RU4FriZVCbkeOAjebqXIarP06zTZnXQzsgTpF20r5EOMCwF/ioivgcwFPV5RqwawY63j+3HapgNjRGr+j6mpoj6fTAfr4lxuI7rdDfM+Fn8mFXxfK/7QT4JxqyQw2NWyOExK+TwmBVyeMwKOTxmhRwes0IOj1khh8eskMNjVsjhMSvk8JgVcnjMCjk8ZoUcHrNCDo9ZIYfHrJDDY1bI4TEr5PCYFXJ4zAo5PGaF+hUeSZMlrZc0pzLvNElLJa2V9B1JEyttEyXdlNuWSjptMDtv1kn9HXmuBP6n54akqcDVwJ+QfhF0HfDVhuVfym2nA1fl+5h1vf6UGDkV+D/gx5XZpwPfj4i7I2INcAlwsqQd8+9WnwJcEhFrIuIe4HukoJl1vXbLKo4HLgMayyI21ud5nDTS7JenjRGxuLJ8W/V5XmZD+2tg1iHtjjyXA7Mi4qmG+ePYsv4ObFmfZ1UfbVuJiJkRMS0ipu3A6Da7ZdY57VRJOJhUGeGQXpqb1efZ3KTNrOu1UyVhOrAXsEyp7sc4YKSkA0i1RQ/qWVDS3sBoYDEpPKMkTY6IX+ZF2qrPY9YN2gnPTGBu5fbfkMJ0HrArcK+ko4BfkD4X3RgRqwEk3QhclkvPHwy8Dzhi0Hpv1kEtwxMR60iHoAGQtAZYHxHPAs9K+hhwHbATcDtbFq86H7gGWAH8FjivobK2WddyfR6zJlyfx2wIODxmhRwes0IOj1khh8eskMNjVsjhMSvk8JgVcnjMCjk8ZoUcHrNCDo9ZIYfHrJDDY1bI4TEr5PCYFXJ4zAo5PGaFHB6zQg6PWSGHx6yQw2NWqN0fer8z1+VZk6dHK22uz2Pbpf6MPBdExLg87Q+uz2Pbt3Z+breZV+rzAEi6BFgoaUfSb1WfAhyYa/fcI6mnPs9FA3xes47rz8jzOUnPSfqJpOl5nuvz2Har3ZHnU8AjpGCcCnw/lx5pVp9nE/2sz0P6UXnGa2L9fgPYrEFb4YmIn1VuXivpI8CJuD6PbcdKD1UHIFKtnb7q8ywm1+ep3M/1eWyb0bJKgqTXAYcDdwEbgQ+Tdq8OAXYA7gVOItXnuRoYFRGn5vvOJQWtpz7PD4AjWpUZkbQaeLTZMtu4nYHnOt2JDqnbuk+KiF16bYmIphOwC6l8/GpSNeyfAu+utJ8GLAPWAt8FJlbaJgLfyW3LgNNaPV++3/x2lttWp+15/btp3WtZn0fS/IiY1ul+dMr2vP7dtO4+PcesUF3DM7PTHeiw7Xn9u2bda7nbZtYN6jrymNWew2NWqFbh2ZYvYZA0WtKsvF6rJT0g6YRK+3GSFklaJ2mepEkN971G0ipJyyVd2Jm1GBySJudLXOZU5nXdpS21Cg/b9iUMo4AngaOB1wIXA9+WtJeknYEbgUtI343NB75Vue+lwGRgEnAM8ElJ7x2+rg+6K0nfHQLde2lLbQ4YSBoLrCRdwrA4z5sN/DoitslLGCQ9BHwG2AmYERFH5PljSd+yHxIRiyQ9ndv/M7dfDkyOfCZHN5F0KnAy6UTjfSPiDElXAHtFxGl5mX2AhaTXZTM13S7qNPL06xKGbidpN9I6L2DrSzvWAo8DUyVNAPaottOlr4uk8cBlQONu56Bd2jKc6hSecfTjEoZuJmkH4Drg2ohYRPNLO8ZVbje2dZvLgVkR8VTD/FbrX8vtYqBXkg6mZpc3bDMkjQBmk95ZL8izm637msrt9Q1tXSNf/3U86YTiRl15aUudwvPKJQwR8cs8b5u6hEGSgFmkD74nRsTLuWkBcGZlubHAPsCCiFgp6RnSa3FbXqQbX5fpwF7AsvQyMA4YKekA4Ef0fWnLZuq6XXT6zNSGM2rnAtcDY4EjScPz1E73axDX72uks9LHNczfJa/rKcAY4AvATyvtnyddEjIBmAI8A7y30+vTz3V/DbB7Zfon4Ia87lNJu2ZH5f/7OcDcum8XHX9RG17goksYumEiHWYO0q7Xmsp0em4/HlgEvAjcSTr61HPf0cA1eQP7DXBhp9dnEF6PS4E5lduDfmnLUE+1OVRt1m3qdLTNrKs4PGaFHB6zQg6PWSGHx6yQw2NWyOExK+TwmBVyeMwK/T+Vg028M5Rf0gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Velocity distribution"
      ],
      "metadata": {
        "id": "B7LQzVv63_0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psi0Masked,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "id": "qbVbaBjT3aOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "3fcf06ae-4458-451a-db71-717a7fef443a"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'v2')"
            ]
          },
          "metadata": {},
          "execution_count": 270
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dynamic properties\n",
        "The fluid is Newtonian."
      ],
      "metadata": {
        "id": "hvAQmdvsnZQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 1e-3 # koefficient of dynamic viscosity (viscosity), Pa*s"
      ],
      "metadata": {
        "id": "t4YCVOBPneFt"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check exact solution\n",
        "Newtonian fluid flows between parallel plates "
      ],
      "metadata": {
        "id": "wOpHVjQdkxS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=L/5\n",
        "pressureDrop = Q*3*mu*L/(2*h*h*h)\n",
        "internalPower = pressureDrop*Q\n",
        "print('pressure drop',pressureDrop,'internal power',internalPower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpG0AV2LlF-W",
        "outputId": "f58721fe-ec77-47c1-b889-63a4d63b8da2"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pressure drop 18.75 internal power 18.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "PhZutgNIyYhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create model\n",
        "Unet architecture [2] is used"
      ],
      "metadata": {
        "id": "FPeLHoR31p1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=4):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return torch.sigmoid(self.conv(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        \n",
        "model = UNet(in_channels=1, out_channels=1, init_features=32)"
      ],
      "metadata": {
        "id": "PID82zl-cxN4"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "2yb3P0n1c8df"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "PwikCXOPyPPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learnRate, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "oKBkisM7hASi"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input image"
      ],
      "metadata": {
        "id": "TyTAp5u0yroJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi0Masked.dtype"
      ],
      "metadata": {
        "id": "j6BFOOEv3OhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32ffdf4-46ad-4bb0-83f6-410045d6cdd1"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = torch.randn((1, 1, 512, 512))\n",
        "x = torch.ones((1, 1, imgSize, imgSize))*psi0Masked\n",
        "#fig = plt.figure(figsize=(3, 3))\n",
        "#plt.imshow(x[0,0,:,:])\n",
        "x.dtype, x.shape"
      ],
      "metadata": {
        "id": "xruHyQ-vdVhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c01c78-c42e-47ae-82fd-e8ca8211ffba"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.Size([1, 1, 512, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model(x)"
      ],
      "metadata": {
        "id": "f1L8QG9ndbML"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = dx1n*dx2n*lim1[1]*lim2[1]\n",
        "s"
      ],
      "metadata": {
        "id": "osreN0VAdhZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b938ac80-06c4-4c31-ae27-0a5ccf46eaba"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8296e-08)"
            ]
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "\n",
        "for epoch in range(noOfEpoch):\n",
        "  psi = model(x)\n",
        "  psiMasked = (psi[0,0,:,:]*wallsMask) + (inverseUpperWallMask*Q)\n",
        "  print(psi[0,0,:,:].shape)\n",
        "  v1,v2 = velocityDistr(psiMasked,dx1n,dx2n,lim1,lim2)\n",
        "  xi11,xi12,xi22,EtaEta = TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2)\n",
        "  out = 0.5*mu*s*EtaEta.sum() #doublelIntegral(0.5*mu*EtaEta,lim1,lim2) #loss\n",
        "  #out = loss(out)\n",
        "  if out < 1e-6:\n",
        "      break\n",
        "  history.append(out.item())\n",
        "  out.backward()\n",
        "  optimizer.step()\n",
        "  print('#iter',epoch,'loss',out)"
      ],
      "metadata": {
        "id": "CsBCY3g4gspY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af56304-3157-4af4-c006-e48064bde901"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 512])\n",
            "#iter 0 loss tensor(3366244., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 1 loss tensor(1137416.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 2 loss tensor(704054.3750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 3 loss tensor(453506.4062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 4 loss tensor(279395.7812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 5 loss tensor(206495.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 6 loss tensor(231448.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 7 loss tensor(237931.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 8 loss tensor(214739.6875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 9 loss tensor(163442.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 10 loss tensor(123271.0469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 11 loss tensor(104202.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 12 loss tensor(100935.2734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 13 loss tensor(105198.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 14 loss tensor(108414.3203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 15 loss tensor(108447.6641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 16 loss tensor(102081.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 17 loss tensor(91040.0547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 18 loss tensor(81631.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 19 loss tensor(76455.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 20 loss tensor(78178.0234, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 21 loss tensor(82961.6953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 22 loss tensor(87642.7109, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 23 loss tensor(92285.4766, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 24 loss tensor(105941.1328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 25 loss tensor(132065.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 26 loss tensor(158977.7031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 27 loss tensor(166507.3906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 28 loss tensor(145160.1094, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 29 loss tensor(115930.0859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 30 loss tensor(101215.5469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 31 loss tensor(103567.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 32 loss tensor(101260.8516, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 33 loss tensor(98979.4141, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 34 loss tensor(97500.7891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 35 loss tensor(94574.8203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 36 loss tensor(90133.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 37 loss tensor(86867.5703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 38 loss tensor(85245.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 39 loss tensor(84465.5703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 40 loss tensor(82561.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 41 loss tensor(80163.0078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 42 loss tensor(76661.5312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 43 loss tensor(73304.8672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 44 loss tensor(71176.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 45 loss tensor(69472.5938, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 46 loss tensor(67462.7031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 47 loss tensor(65636.0938, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 48 loss tensor(63732.9336, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 49 loss tensor(61000.0273, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 50 loss tensor(59503.5195, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 51 loss tensor(57083.2656, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 52 loss tensor(53416.2266, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 53 loss tensor(49129.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 54 loss tensor(46209.8164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 55 loss tensor(46054.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 56 loss tensor(49023.2578, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 57 loss tensor(55480.3867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 58 loss tensor(66743.4531, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 59 loss tensor(79914.0938, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 60 loss tensor(92905.9844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 61 loss tensor(101629.5703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 62 loss tensor(103958.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 63 loss tensor(98800.4062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 64 loss tensor(87644.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 65 loss tensor(72890.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 66 loss tensor(57711.9297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 67 loss tensor(45863.2422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 68 loss tensor(40053.6367, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 69 loss tensor(38412.4648, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 70 loss tensor(39147.1523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 71 loss tensor(41261.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 72 loss tensor(44030.4727, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 73 loss tensor(46136.8438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 74 loss tensor(47951.2852, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 75 loss tensor(49274.8242, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 76 loss tensor(50261.2383, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 77 loss tensor(51176.1016, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 78 loss tensor(51740.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 79 loss tensor(52217.6523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 80 loss tensor(52755.7617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 81 loss tensor(53607.3320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 82 loss tensor(54678.5195, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 83 loss tensor(55863.5391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 84 loss tensor(56882.1758, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 85 loss tensor(57830.1016, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 86 loss tensor(58561.8867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 87 loss tensor(58908.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 88 loss tensor(58911.5742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 89 loss tensor(58415.2031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 90 loss tensor(57614.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 91 loss tensor(56561.6602, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 92 loss tensor(55348.6211, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 93 loss tensor(54054.5234, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 94 loss tensor(52556.5352, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 95 loss tensor(51133.1289, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 96 loss tensor(49672.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 97 loss tensor(48119.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 98 loss tensor(46624.4961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 99 loss tensor(45267.6289, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 100 loss tensor(43959.1914, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 101 loss tensor(42741.4219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 102 loss tensor(41492.0547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 103 loss tensor(40264.7031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 104 loss tensor(39152.9609, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 105 loss tensor(38133.7422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 106 loss tensor(37293.2422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 107 loss tensor(36600.8633, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 108 loss tensor(35963.4023, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 109 loss tensor(35380.8047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 110 loss tensor(34876.2891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 111 loss tensor(34484.5703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 112 loss tensor(34092.0898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 113 loss tensor(33816.0078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 114 loss tensor(33704.5898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 115 loss tensor(33701.9570, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 116 loss tensor(33762.6445, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 117 loss tensor(33678.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 118 loss tensor(33450.8398, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 119 loss tensor(33141.3477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 120 loss tensor(32632.3223, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 121 loss tensor(32042.8105, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 122 loss tensor(31486.5918, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 123 loss tensor(30925.4941, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 124 loss tensor(30329.6543, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 125 loss tensor(29835.6992, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 126 loss tensor(29383.4160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 127 loss tensor(28959.4961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 128 loss tensor(28533.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 129 loss tensor(28099.7754, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 130 loss tensor(27709.7734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 131 loss tensor(27364.6699, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 132 loss tensor(26995.2832, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 133 loss tensor(26584.6465, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 134 loss tensor(26087.1211, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 135 loss tensor(25663.6035, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 136 loss tensor(25221.5996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 137 loss tensor(24830.8594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 138 loss tensor(24432.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 139 loss tensor(24003.2754, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 140 loss tensor(23591.0273, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 141 loss tensor(23156.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 142 loss tensor(22753.0352, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 143 loss tensor(22339.5996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 144 loss tensor(21926.0234, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 145 loss tensor(21562.5918, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 146 loss tensor(21237.4941, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 147 loss tensor(20971.7832, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 148 loss tensor(20760.1055, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 149 loss tensor(20589.2793, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 150 loss tensor(20462.2754, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 151 loss tensor(20338.9746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 152 loss tensor(20254.4395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 153 loss tensor(20155.1309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 154 loss tensor(20047.6113, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 155 loss tensor(19924.0879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 156 loss tensor(19794.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 157 loss tensor(19646.8008, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 158 loss tensor(19489.1934, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 159 loss tensor(19367.0156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 160 loss tensor(19267.1387, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 161 loss tensor(19171.5176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 162 loss tensor(19079.1152, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 163 loss tensor(18997.3672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 164 loss tensor(18919.1348, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 165 loss tensor(18847.6836, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 166 loss tensor(18777.8164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 167 loss tensor(18694.0898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 168 loss tensor(18608.3750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 169 loss tensor(18520.2656, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 170 loss tensor(18437.6777, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 171 loss tensor(18365.9199, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 172 loss tensor(18310.9766, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 173 loss tensor(18267.5469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 174 loss tensor(18225.6172, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 175 loss tensor(18194.3652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 176 loss tensor(18160.9785, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 177 loss tensor(18134.8203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 178 loss tensor(18102.2246, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 179 loss tensor(18079.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 180 loss tensor(18052.6445, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 181 loss tensor(18017.3340, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 182 loss tensor(17986.2090, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 183 loss tensor(17958.0996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 184 loss tensor(17927.2812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 185 loss tensor(17892.4492, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 186 loss tensor(17861.7871, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 187 loss tensor(17831.6816, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 188 loss tensor(17795.0762, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 189 loss tensor(17741.3691, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 190 loss tensor(17683.1777, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 191 loss tensor(17631.5586, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 192 loss tensor(17580.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 193 loss tensor(17521.5273, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 194 loss tensor(17449.6211, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 195 loss tensor(17367.6816, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 196 loss tensor(17281.3828, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 197 loss tensor(17191.1621, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 198 loss tensor(17104.1191, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 199 loss tensor(17010.5938, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 200 loss tensor(16906.0469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 201 loss tensor(16795.7539, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 202 loss tensor(16689.0918, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 203 loss tensor(16584.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 204 loss tensor(16485.5820, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 205 loss tensor(16388.8613, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 206 loss tensor(16292.3076, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 207 loss tensor(16196.1094, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 208 loss tensor(16105.7676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 209 loss tensor(16013.5547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 210 loss tensor(15916.2217, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 211 loss tensor(15814.2275, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 212 loss tensor(15711.3037, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 213 loss tensor(15610.3135, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 214 loss tensor(15506.3545, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 215 loss tensor(15402.9834, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 216 loss tensor(15304.0566, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 217 loss tensor(15204.5947, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 218 loss tensor(15100.2979, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 219 loss tensor(14999.8672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 220 loss tensor(14893.8799, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 221 loss tensor(14783.6348, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 222 loss tensor(14674.9092, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 223 loss tensor(14569.7637, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 224 loss tensor(14465.2080, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 225 loss tensor(14361.2217, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 226 loss tensor(14264.2695, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 227 loss tensor(14164.5898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 228 loss tensor(14064.5576, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 229 loss tensor(13959.1230, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 230 loss tensor(13855.0049, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 231 loss tensor(13750.7285, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 232 loss tensor(13648.4502, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 233 loss tensor(13546.1045, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 234 loss tensor(13448.0225, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 235 loss tensor(13345.5645, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 236 loss tensor(13237.9824, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 237 loss tensor(13128.6670, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 238 loss tensor(13019.8174, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 239 loss tensor(12910.2920, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 240 loss tensor(12796.4717, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 241 loss tensor(12686.1611, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 242 loss tensor(12575.2822, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 243 loss tensor(12476.9756, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 244 loss tensor(12381.3096, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 245 loss tensor(12289.1787, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 246 loss tensor(12196.0918, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 247 loss tensor(12106.0195, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 248 loss tensor(12011.1797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 249 loss tensor(11914.4766, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 250 loss tensor(11822.9150, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 251 loss tensor(11737.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 252 loss tensor(11652.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 253 loss tensor(11568.6299, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 254 loss tensor(11485.9043, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 255 loss tensor(11398.8613, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 256 loss tensor(11317.1406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 257 loss tensor(11239.5059, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 258 loss tensor(11163.4258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 259 loss tensor(11084.2139, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 260 loss tensor(11007.3281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 261 loss tensor(10930.3799, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 262 loss tensor(10853.9385, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 263 loss tensor(10781.3398, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 264 loss tensor(10710.8721, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 265 loss tensor(10639.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 266 loss tensor(10569.0225, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 267 loss tensor(10490.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 268 loss tensor(10408.8936, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 269 loss tensor(10330.0303, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 270 loss tensor(10254.5088, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 271 loss tensor(10182.2314, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 272 loss tensor(10112.5527, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 273 loss tensor(10045.1826, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 274 loss tensor(9977.1172, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 275 loss tensor(9910.6270, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 276 loss tensor(9842.6699, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 277 loss tensor(9776.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 278 loss tensor(9711.5107, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 279 loss tensor(9648.1025, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 280 loss tensor(9584.8027, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 281 loss tensor(9518.6533, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 282 loss tensor(9453.3730, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 283 loss tensor(9392.3916, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 284 loss tensor(9339.0889, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 285 loss tensor(9290.5703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 286 loss tensor(9245.1318, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 287 loss tensor(9205.0312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 288 loss tensor(9169.2080, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 289 loss tensor(9131.1592, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 290 loss tensor(9090.6582, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 291 loss tensor(9046.8721, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 292 loss tensor(9003.8535, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 293 loss tensor(8963.2939, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 294 loss tensor(8928.9678, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 295 loss tensor(8901.0264, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 296 loss tensor(8875.5723, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 297 loss tensor(8856.8691, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 298 loss tensor(8845.5693, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 299 loss tensor(8839.5996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 300 loss tensor(8837.1865, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 301 loss tensor(8841.1396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 302 loss tensor(8849.6729, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 303 loss tensor(8863.1084, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 304 loss tensor(8880.1611, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 305 loss tensor(8903.2988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 306 loss tensor(8932.2246, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 307 loss tensor(8965.3682, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 308 loss tensor(9005.6025, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 309 loss tensor(9050.1992, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 310 loss tensor(9094.6748, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 311 loss tensor(9137.9453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 312 loss tensor(9180.3271, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 313 loss tensor(9222.7158, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 314 loss tensor(9266.9785, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 315 loss tensor(9310.3389, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 316 loss tensor(9351.7520, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 317 loss tensor(9392.4668, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 318 loss tensor(9434.8682, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 319 loss tensor(9474.9492, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 320 loss tensor(9510.5479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 321 loss tensor(9544.3711, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 322 loss tensor(9574.3760, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 323 loss tensor(9602.3662, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 324 loss tensor(9624.6523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 325 loss tensor(9640.5859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 326 loss tensor(9651.3652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 327 loss tensor(9656.6104, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 328 loss tensor(9656.8135, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 329 loss tensor(9651.4609, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 330 loss tensor(9640.1240, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 331 loss tensor(9623.2275, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 332 loss tensor(9598.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 333 loss tensor(9560.4629, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 334 loss tensor(9511.3447, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 335 loss tensor(9456.4688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 336 loss tensor(9400.0801, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 337 loss tensor(9344.6895, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 338 loss tensor(9285.4297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 339 loss tensor(9222.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 340 loss tensor(9155.3701, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 341 loss tensor(9087.1768, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 342 loss tensor(9014.6777, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 343 loss tensor(8945.5508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 344 loss tensor(8876.5293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 345 loss tensor(8804.3770, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 346 loss tensor(8733.0859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 347 loss tensor(8660.2373, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 348 loss tensor(8586.0996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 349 loss tensor(8513.2617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 350 loss tensor(8440.6416, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 351 loss tensor(8367.7812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 352 loss tensor(8292.6152, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 353 loss tensor(8217.9688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 354 loss tensor(8143.5562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 355 loss tensor(8067.1089, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 356 loss tensor(7993.3989, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 357 loss tensor(7924.6001, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 358 loss tensor(7857.6396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 359 loss tensor(7796.6792, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 360 loss tensor(7738.9863, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 361 loss tensor(7683.1284, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 362 loss tensor(7631.6919, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 363 loss tensor(7582.1021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 364 loss tensor(7534.1489, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 365 loss tensor(7486.4072, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 366 loss tensor(7440.9814, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 367 loss tensor(7395.9458, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 368 loss tensor(7348.8057, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 369 loss tensor(7301.3442, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 370 loss tensor(7256.0493, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 371 loss tensor(7212.8223, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 372 loss tensor(7167.5034, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 373 loss tensor(7117.0205, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 374 loss tensor(7064.4834, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 375 loss tensor(7016.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 376 loss tensor(6970.8511, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 377 loss tensor(6927.8701, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 378 loss tensor(6886.3320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 379 loss tensor(6844.9048, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 380 loss tensor(6805.3486, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 381 loss tensor(6767.0493, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 382 loss tensor(6727.8364, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 383 loss tensor(6692.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 384 loss tensor(6659.3516, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 385 loss tensor(6631.8657, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 386 loss tensor(6607.0229, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 387 loss tensor(6582.7910, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 388 loss tensor(6558.8086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 389 loss tensor(6533.4116, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 390 loss tensor(6508.7881, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 391 loss tensor(6487.2788, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 392 loss tensor(6469.8730, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 393 loss tensor(6457.9819, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 394 loss tensor(6448.0229, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 395 loss tensor(6441.5063, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 396 loss tensor(6438.4067, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 397 loss tensor(6437.5449, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 398 loss tensor(6437.3105, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 399 loss tensor(6439.7437, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 400 loss tensor(6446.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 401 loss tensor(6458.9180, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 402 loss tensor(6479.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 403 loss tensor(6505.3110, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 404 loss tensor(6537.0879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 405 loss tensor(6564.9121, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 406 loss tensor(6585.6294, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 407 loss tensor(6610.4243, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 408 loss tensor(6636.6973, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 409 loss tensor(6665.9380, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 410 loss tensor(6697.5459, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 411 loss tensor(6731.8657, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 412 loss tensor(6761.6021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 413 loss tensor(6792.0952, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 414 loss tensor(6823.1255, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 415 loss tensor(6854.5747, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 416 loss tensor(6891.3794, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 417 loss tensor(6932.7949, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 418 loss tensor(6983.7168, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 419 loss tensor(7036.8716, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 420 loss tensor(7087.9731, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 421 loss tensor(7134.0723, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 422 loss tensor(7181.3271, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 423 loss tensor(7228.6914, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 424 loss tensor(7272.9629, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 425 loss tensor(7314.4819, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 426 loss tensor(7356.0098, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 427 loss tensor(7393.3877, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 428 loss tensor(7420.9487, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 429 loss tensor(7433.9307, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 430 loss tensor(7444.0791, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 431 loss tensor(7450.1323, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 432 loss tensor(7450.7451, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 433 loss tensor(7450.4893, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 434 loss tensor(7447.4478, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 435 loss tensor(7440.3730, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 436 loss tensor(7427.8530, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 437 loss tensor(7414.8296, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 438 loss tensor(7406.5283, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 439 loss tensor(7404.0283, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 440 loss tensor(7405.5825, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 441 loss tensor(7412.0737, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 442 loss tensor(7425.9136, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 443 loss tensor(7449.5264, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 444 loss tensor(7478.9800, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 445 loss tensor(7508.0786, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 446 loss tensor(7541.4253, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 447 loss tensor(7584.3848, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 448 loss tensor(7625.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 449 loss tensor(7653.4375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 450 loss tensor(7673.4653, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 451 loss tensor(7697.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 452 loss tensor(7723.1055, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 453 loss tensor(7752.7017, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 454 loss tensor(7784.6694, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 455 loss tensor(7813.4438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 456 loss tensor(7836.4448, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 457 loss tensor(7852.6436, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 458 loss tensor(7858.6079, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 459 loss tensor(7869.6792, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 460 loss tensor(7886.5493, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 461 loss tensor(7903.6357, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 462 loss tensor(7918.8115, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 463 loss tensor(7922.3765, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 464 loss tensor(7926.5913, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 465 loss tensor(7934.8057, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 466 loss tensor(7949.2915, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 467 loss tensor(7962.0850, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 468 loss tensor(7978.1416, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 469 loss tensor(7994.4619, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 470 loss tensor(8000.6733, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 471 loss tensor(8001.4595, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 472 loss tensor(7996.8174, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 473 loss tensor(7987.3257, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 474 loss tensor(7976.5171, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 475 loss tensor(7962.2056, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 476 loss tensor(7946.5449, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 477 loss tensor(7931.3999, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 478 loss tensor(7913.7056, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 479 loss tensor(7897.8481, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 480 loss tensor(7882.3345, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 481 loss tensor(7864.7710, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 482 loss tensor(7848.2261, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 483 loss tensor(7828.8062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 484 loss tensor(7806.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 485 loss tensor(7778.7070, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 486 loss tensor(7746.9849, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 487 loss tensor(7710.1226, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 488 loss tensor(7675.4385, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 489 loss tensor(7639.7715, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 490 loss tensor(7601.6187, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 491 loss tensor(7563.2520, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 492 loss tensor(7528.8149, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 493 loss tensor(7493.4404, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 494 loss tensor(7457.6045, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 495 loss tensor(7421.4668, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 496 loss tensor(7384.7183, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 497 loss tensor(7351.3833, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 498 loss tensor(7316.5820, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 499 loss tensor(7280.9287, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 500 loss tensor(7242.2065, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 501 loss tensor(7205.2817, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 502 loss tensor(7169.5176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 503 loss tensor(7135.3960, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 504 loss tensor(7103.8535, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 505 loss tensor(7077.0210, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 506 loss tensor(7051.3623, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 507 loss tensor(7024.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 508 loss tensor(6999.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 509 loss tensor(6977.0278, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 510 loss tensor(6959.2129, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 511 loss tensor(6944.3066, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 512 loss tensor(6931.7720, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 513 loss tensor(6916.8589, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 514 loss tensor(6904.8555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 515 loss tensor(6897.3203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 516 loss tensor(6893.8794, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 517 loss tensor(6893.5454, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 518 loss tensor(6899.8350, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 519 loss tensor(6912.2261, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 520 loss tensor(6926.4683, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 521 loss tensor(6942.9858, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 522 loss tensor(6961.0903, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 523 loss tensor(6980.4951, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 524 loss tensor(7004., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 525 loss tensor(7031.3882, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 526 loss tensor(7059.4868, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 527 loss tensor(7089.2896, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 528 loss tensor(7120.2656, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 529 loss tensor(7150.3320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 530 loss tensor(7176.1118, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 531 loss tensor(7199.3481, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 532 loss tensor(7217.1367, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 533 loss tensor(7232.9478, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 534 loss tensor(7250.4404, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 535 loss tensor(7268.3018, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 536 loss tensor(7279.7861, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 537 loss tensor(7284.4888, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 538 loss tensor(7281.5742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 539 loss tensor(7278.1343, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 540 loss tensor(7277.7129, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 541 loss tensor(7276.0127, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 542 loss tensor(7275.0996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 543 loss tensor(7278.4722, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 544 loss tensor(7285.7539, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 545 loss tensor(7295.1504, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 546 loss tensor(7305.8711, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 547 loss tensor(7314.8154, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 548 loss tensor(7324.2095, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 549 loss tensor(7332.5713, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 550 loss tensor(7343.4722, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 551 loss tensor(7361.7676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 552 loss tensor(7383.2822, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 553 loss tensor(7398.6260, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 554 loss tensor(7394.6479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 555 loss tensor(7381.0420, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 556 loss tensor(7366.4316, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 557 loss tensor(7355.2944, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 558 loss tensor(7346.1367, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 559 loss tensor(7339.4565, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 560 loss tensor(7334.2456, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 561 loss tensor(7322.9990, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 562 loss tensor(7308.6831, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 563 loss tensor(7295.8477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 564 loss tensor(7283.5396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 565 loss tensor(7268.1348, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 566 loss tensor(7238.7280, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 567 loss tensor(7207.6230, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 568 loss tensor(7176.5122, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 569 loss tensor(7147.7559, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 570 loss tensor(7120.3960, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 571 loss tensor(7095.2305, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 572 loss tensor(7074.7896, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 573 loss tensor(7057.2085, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 574 loss tensor(7038.6426, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 575 loss tensor(7019.6523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 576 loss tensor(7002.5615, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 577 loss tensor(6986.9883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 578 loss tensor(6972.9790, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 579 loss tensor(6962.5659, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 580 loss tensor(6950.9692, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 581 loss tensor(6941.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 582 loss tensor(6928.1143, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 583 loss tensor(6908.5278, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 584 loss tensor(6891.3003, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 585 loss tensor(6876.2510, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 586 loss tensor(6864.9238, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 587 loss tensor(6856.3477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 588 loss tensor(6851.7139, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 589 loss tensor(6850.1548, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 590 loss tensor(6849.7642, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 591 loss tensor(6848.5771, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 592 loss tensor(6843.5454, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 593 loss tensor(6815.3989, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 594 loss tensor(6784.1045, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 595 loss tensor(6755.8867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 596 loss tensor(6726.4712, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 597 loss tensor(6696.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 598 loss tensor(6665.4458, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 599 loss tensor(6634.0449, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 600 loss tensor(6597.0972, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 601 loss tensor(6559.5908, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 602 loss tensor(6503.2573, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 603 loss tensor(6436.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 604 loss tensor(6371.0791, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 605 loss tensor(6305.8784, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 606 loss tensor(6245.9258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 607 loss tensor(6192.2256, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 608 loss tensor(6145.7109, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 609 loss tensor(6101.9409, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 610 loss tensor(6062.1738, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 611 loss tensor(6025.1860, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 612 loss tensor(5988.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 613 loss tensor(5958.6694, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 614 loss tensor(5919.5356, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 615 loss tensor(5875.4243, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 616 loss tensor(5833.0337, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 617 loss tensor(5799.6553, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 618 loss tensor(5771.8325, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 619 loss tensor(5740.7280, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 620 loss tensor(5718.0249, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 621 loss tensor(5705.3174, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 622 loss tensor(5699.0850, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 623 loss tensor(5697.8159, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 624 loss tensor(5700.6045, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 625 loss tensor(5715.9907, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 626 loss tensor(5745.6953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 627 loss tensor(5782.7959, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 628 loss tensor(5828.2568, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 629 loss tensor(5889.5557, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 630 loss tensor(5961.2090, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 631 loss tensor(6048.6978, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 632 loss tensor(6145.8755, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 633 loss tensor(6252.2905, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 634 loss tensor(6368.0479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 635 loss tensor(6481.0034, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 636 loss tensor(6589.9756, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 637 loss tensor(6701.7197, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 638 loss tensor(6794.6919, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 639 loss tensor(6871.0518, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 640 loss tensor(6938.2119, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 641 loss tensor(7001.8755, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 642 loss tensor(7051.7705, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 643 loss tensor(7092.9585, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 644 loss tensor(7128.8667, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 645 loss tensor(7157.6226, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 646 loss tensor(7180.0840, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 647 loss tensor(7193.4917, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 648 loss tensor(7202.9873, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 649 loss tensor(7203.0713, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 650 loss tensor(7190.2227, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 651 loss tensor(7177.3911, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 652 loss tensor(7162.4561, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 653 loss tensor(7135.2417, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 654 loss tensor(7099.2744, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 655 loss tensor(7055.7817, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 656 loss tensor(7005.5884, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 657 loss tensor(6948.6265, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 658 loss tensor(6888.5562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 659 loss tensor(6830.8604, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 660 loss tensor(6769.9824, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 661 loss tensor(6704.6689, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 662 loss tensor(6634.8198, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 663 loss tensor(6564.9854, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 664 loss tensor(6496.5728, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 665 loss tensor(6431.6865, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 666 loss tensor(6370.9551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 667 loss tensor(6315.1206, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 668 loss tensor(6260.2773, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 669 loss tensor(6206.2388, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 670 loss tensor(6154.3013, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 671 loss tensor(6106.0518, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 672 loss tensor(6060.8657, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 673 loss tensor(6017.0220, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 674 loss tensor(5974.7476, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 675 loss tensor(5933.7705, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 676 loss tensor(5894.1855, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 677 loss tensor(5855.7275, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 678 loss tensor(5819.2056, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 679 loss tensor(5786.5728, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 680 loss tensor(5759.1768, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 681 loss tensor(5733.3911, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 682 loss tensor(5711.6177, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 683 loss tensor(5694.2983, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 684 loss tensor(5680.0054, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 685 loss tensor(5669.4551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 686 loss tensor(5663.2837, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 687 loss tensor(5660.2788, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 688 loss tensor(5658.1021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 689 loss tensor(5657.4497, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 690 loss tensor(5661.5645, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 691 loss tensor(5670.7744, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 692 loss tensor(5683.5239, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 693 loss tensor(5700.6372, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 694 loss tensor(5720.9644, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 695 loss tensor(5741.7739, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 696 loss tensor(5766.8008, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 697 loss tensor(5795.4385, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 698 loss tensor(5828.1436, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 699 loss tensor(5864.1890, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 700 loss tensor(5901.8901, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 701 loss tensor(5944.1670, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 702 loss tensor(5991.5776, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 703 loss tensor(6040.4209, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 704 loss tensor(6090.1221, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 705 loss tensor(6141.4634, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 706 loss tensor(6194.4126, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 707 loss tensor(6242.7583, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 708 loss tensor(6284.7197, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 709 loss tensor(6325.8047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 710 loss tensor(6365.5054, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 711 loss tensor(6399.6680, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 712 loss tensor(6429.3555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 713 loss tensor(6458.2202, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 714 loss tensor(6489.6270, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 715 loss tensor(6519.6841, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 716 loss tensor(6547.8540, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 717 loss tensor(6574.3784, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 718 loss tensor(6600.2622, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 719 loss tensor(6627.0884, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 720 loss tensor(6652.8623, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 721 loss tensor(6673.4858, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 722 loss tensor(6693.6870, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 723 loss tensor(6712.1123, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 724 loss tensor(6729.0679, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 725 loss tensor(6743.3838, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 726 loss tensor(6757.7847, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 727 loss tensor(6766.8975, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 728 loss tensor(6770.3203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 729 loss tensor(6770.2720, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 730 loss tensor(6766.4639, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 731 loss tensor(6758.3096, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 732 loss tensor(6746.2822, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 733 loss tensor(6732.0151, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 734 loss tensor(6718.8433, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 735 loss tensor(6705.7583, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 736 loss tensor(6687.4053, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 737 loss tensor(6667.6724, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 738 loss tensor(6646.4712, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 739 loss tensor(6624.0039, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 740 loss tensor(6601.0396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 741 loss tensor(6577.0464, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 742 loss tensor(6551.9160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 743 loss tensor(6526.4111, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 744 loss tensor(6500.9355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 745 loss tensor(6474.3848, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 746 loss tensor(6446.8853, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 747 loss tensor(6417.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 748 loss tensor(6385.4331, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 749 loss tensor(6353.5830, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 750 loss tensor(6322.2632, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 751 loss tensor(6292.2544, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 752 loss tensor(6263.3027, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 753 loss tensor(6234.5879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 754 loss tensor(6202.8320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 755 loss tensor(6172.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 756 loss tensor(6142.8862, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 757 loss tensor(6113.0557, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 758 loss tensor(6082.0605, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 759 loss tensor(6050.9761, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 760 loss tensor(6019.2485, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 761 loss tensor(5987.1519, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 762 loss tensor(5955.4614, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 763 loss tensor(5922.0928, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 764 loss tensor(5883.1177, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 765 loss tensor(5834.5342, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 766 loss tensor(5785.7285, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 767 loss tensor(5737.3350, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 768 loss tensor(5688.4399, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 769 loss tensor(5640.1670, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 770 loss tensor(5591.5938, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 771 loss tensor(5540.9639, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 772 loss tensor(5488.0479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 773 loss tensor(5433.2900, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 774 loss tensor(5378.6475, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 775 loss tensor(5327.8354, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 776 loss tensor(5280.6470, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 777 loss tensor(5238.3237, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 778 loss tensor(5196.9243, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 779 loss tensor(5156.0342, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 780 loss tensor(5117.1597, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 781 loss tensor(5080.9927, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 782 loss tensor(5050.7935, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 783 loss tensor(5027.3882, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 784 loss tensor(5011.0166, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 785 loss tensor(5000.1528, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 786 loss tensor(4994.3647, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 787 loss tensor(4988.3682, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 788 loss tensor(4984.5239, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 789 loss tensor(4983.4102, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 790 loss tensor(4987.0732, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 791 loss tensor(4996.5967, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 792 loss tensor(5011.8784, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 793 loss tensor(5029.6504, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 794 loss tensor(5052.2754, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 795 loss tensor(5077.5898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 796 loss tensor(5107.2769, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 797 loss tensor(5142.0317, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 798 loss tensor(5177.9258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 799 loss tensor(5210.6919, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 800 loss tensor(5243.7124, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 801 loss tensor(5279.8120, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 802 loss tensor(5317.1978, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 803 loss tensor(5348.3931, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 804 loss tensor(5379.7334, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 805 loss tensor(5415.0713, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 806 loss tensor(5454.8037, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 807 loss tensor(5498.2969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 808 loss tensor(5543.3555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 809 loss tensor(5587.7104, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 810 loss tensor(5627.4033, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 811 loss tensor(5662.2104, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 812 loss tensor(5695.8647, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 813 loss tensor(5732.2056, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 814 loss tensor(5767.7954, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 815 loss tensor(5807.6362, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 816 loss tensor(5854.8091, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 817 loss tensor(5910.8672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 818 loss tensor(5972.7432, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 819 loss tensor(6040.3149, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 820 loss tensor(6116.5483, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 821 loss tensor(6194.2598, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 822 loss tensor(6275.2690, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 823 loss tensor(6354.6802, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 824 loss tensor(6439.4854, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 825 loss tensor(6530.9263, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 826 loss tensor(6627.7852, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 827 loss tensor(6727.7612, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 828 loss tensor(6834.8311, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 829 loss tensor(6942.8032, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 830 loss tensor(7051.8008, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 831 loss tensor(7164.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 832 loss tensor(7285.5488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 833 loss tensor(7412.6099, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 834 loss tensor(7543.0762, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 835 loss tensor(7673.8975, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 836 loss tensor(7809.9292, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 837 loss tensor(7948.9092, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 838 loss tensor(8085.8486, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 839 loss tensor(8221.8096, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 840 loss tensor(8358.9238, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 841 loss tensor(8492.1191, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 842 loss tensor(8609.8447, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 843 loss tensor(8712.0576, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 844 loss tensor(8798.2852, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 845 loss tensor(8881.5176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 846 loss tensor(8962.3760, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 847 loss tensor(9042.1602, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 848 loss tensor(9122.4473, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 849 loss tensor(9202.9248, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 850 loss tensor(9283.0723, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 851 loss tensor(9360.6816, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 852 loss tensor(9436.7402, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 853 loss tensor(9510.6035, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 854 loss tensor(9580.9717, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 855 loss tensor(9645.2842, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 856 loss tensor(9701.5381, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 857 loss tensor(9748.0361, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 858 loss tensor(9788.3086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 859 loss tensor(9822.0156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 860 loss tensor(9849.9463, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 861 loss tensor(9872.0996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 862 loss tensor(9889.6172, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 863 loss tensor(9902.0664, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 864 loss tensor(9909.1328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 865 loss tensor(9911.3486, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 866 loss tensor(9908.2324, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 867 loss tensor(9899.1455, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 868 loss tensor(9883.6514, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 869 loss tensor(9862.8848, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 870 loss tensor(9835.6221, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 871 loss tensor(9802.2148, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 872 loss tensor(9762.3340, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 873 loss tensor(9716.5459, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 874 loss tensor(9664.8887, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 875 loss tensor(9607.4834, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 876 loss tensor(9544.4062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 877 loss tensor(9475.6924, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 878 loss tensor(9401.7207, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 879 loss tensor(9322.2646, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 880 loss tensor(9237.3389, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 881 loss tensor(9147.1309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 882 loss tensor(9052.3711, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 883 loss tensor(8953.2852, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 884 loss tensor(8848.8027, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 885 loss tensor(8740.0430, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 886 loss tensor(8627.6514, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 887 loss tensor(8511.9346, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 888 loss tensor(8393.1455, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 889 loss tensor(8273.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 890 loss tensor(8151.9170, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 891 loss tensor(8029.9888, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 892 loss tensor(7904.9600, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 893 loss tensor(7778.9634, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 894 loss tensor(7655.0093, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 895 loss tensor(7533.9136, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 896 loss tensor(7413.6318, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 897 loss tensor(7296.6128, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 898 loss tensor(7179.5327, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 899 loss tensor(7057.0376, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 900 loss tensor(6932.4204, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 901 loss tensor(6811.5537, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 902 loss tensor(6692.1709, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 903 loss tensor(6575.2969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 904 loss tensor(6461.1943, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 905 loss tensor(6351.3213, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 906 loss tensor(6247.1533, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 907 loss tensor(6148.4814, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 908 loss tensor(6053.5845, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 909 loss tensor(5961.1650, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 910 loss tensor(5873.9004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 911 loss tensor(5792.7480, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 912 loss tensor(5716.8755, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 913 loss tensor(5646.6050, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 914 loss tensor(5583.2842, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 915 loss tensor(5526.3535, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 916 loss tensor(5478.4302, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 917 loss tensor(5441.4854, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 918 loss tensor(5411.6069, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 919 loss tensor(5385.5923, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 920 loss tensor(5361.7305, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 921 loss tensor(5343.0605, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 922 loss tensor(5331.9805, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 923 loss tensor(5329.6216, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 924 loss tensor(5338.2949, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 925 loss tensor(5349.0708, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 926 loss tensor(5365.7314, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 927 loss tensor(5381.5317, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 928 loss tensor(5399.1865, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 929 loss tensor(5426.3887, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 930 loss tensor(5463.1572, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 931 loss tensor(5503.3784, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 932 loss tensor(5542.9937, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 933 loss tensor(5583.2720, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 934 loss tensor(5622.0801, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 935 loss tensor(5678.1494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 936 loss tensor(5737.9614, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 937 loss tensor(5802.6978, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 938 loss tensor(5869.6401, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 939 loss tensor(5937.5825, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 940 loss tensor(6006.5488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 941 loss tensor(6085.0249, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 942 loss tensor(6176.3999, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 943 loss tensor(6279.8926, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 944 loss tensor(6394.4556, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 945 loss tensor(6517.7217, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 946 loss tensor(6647.1411, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 947 loss tensor(6763.9795, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 948 loss tensor(6867.8174, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 949 loss tensor(6973.7148, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 950 loss tensor(7079.0308, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 951 loss tensor(7180.4448, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 952 loss tensor(7287.1157, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 953 loss tensor(7398.1255, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 954 loss tensor(7510.5854, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 955 loss tensor(7623.3135, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 956 loss tensor(7739.8149, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 957 loss tensor(7859.1685, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 958 loss tensor(7976.6421, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 959 loss tensor(8088.5835, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 960 loss tensor(8194.6348, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 961 loss tensor(8294.0205, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 962 loss tensor(8393.5586, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 963 loss tensor(8484.1855, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 964 loss tensor(8571.8955, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 965 loss tensor(8659.1270, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 966 loss tensor(8736.5996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 967 loss tensor(8812.0576, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 968 loss tensor(8891.5264, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 969 loss tensor(8976.9082, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 970 loss tensor(9051.9551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 971 loss tensor(9122.2832, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 972 loss tensor(9192.4814, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 973 loss tensor(9259.6768, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 974 loss tensor(9318.1064, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 975 loss tensor(9371.5859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 976 loss tensor(9410.5615, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 977 loss tensor(9442.4326, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 978 loss tensor(9472.6787, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 979 loss tensor(9500.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 980 loss tensor(9519.5107, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 981 loss tensor(9529.8838, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 982 loss tensor(9533.9688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 983 loss tensor(9531.9189, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 984 loss tensor(9525.5479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 985 loss tensor(9513.9629, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 986 loss tensor(9492.0547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 987 loss tensor(9457.8438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 988 loss tensor(9412.7744, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 989 loss tensor(9354.6514, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 990 loss tensor(9284.5010, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 991 loss tensor(9202.7148, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 992 loss tensor(9115.2861, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 993 loss tensor(9016.7119, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 994 loss tensor(8895.5889, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 995 loss tensor(8761.6045, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 996 loss tensor(8615.2490, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 997 loss tensor(8463.0908, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 998 loss tensor(8307.9541, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 999 loss tensor(8149.1377, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "jHYMzoLTbFyR",
        "outputId": "29f23aab-844d-4304-d1d0-3aaee2d06084"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa961efdcd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 281
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation"
      ],
      "metadata": {
        "id": "twoS2qPPcSPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi[0,0,:,:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmYDRsmlc0-b",
        "outputId": "bfafd4fb-e215-42fe-ae9e-abfb0ffece6a"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psicheck = torch.tensor(psi[0,0,:,:],requires_grad=False)\n",
        "psiMasked = (psicheck*wallsMask) + (inverseUpperWallMask*Q)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psiMasked)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "Tx_qNIxjcZoa",
        "outputId": "df89b69b-38e0-4d78-89ec-a00eb1d40b97"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'psi function with mask')"
            ]
          },
          "metadata": {},
          "execution_count": 286
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(psiMasked[:,250])"
      ],
      "metadata": {
        "id": "r-cNSoA-vtz4",
        "outputId": "86e05eda-db1f-42d8-bc8d-63cf4eac1744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa9625d7190>]"
            ]
          },
          "metadata": {},
          "execution_count": 289
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psiMasked,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "IcEzHkrgcVWx",
        "outputId": "7ebdc47d-62b1-44e7-db56-4135a35c657c"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'v2')"
            ]
          },
          "metadata": {},
          "execution_count": 287
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(v2[:,250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "tM5Nv56YeC9r",
        "outputId": "97fb85f5-b559-4355-c598-7ff5a897203b"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa962cc7c90>]"
            ]
          },
          "metadata": {},
          "execution_count": 288
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wcd3nv8c+zF10sWfFNdpwE20lIcHCIQyNIe2ggbSikOaWFuO1Jk7SUtpiGpu2LtAV6jgMGAjSH0vbVA5S6JA0kUCA0BFoCbdMmkEJDkRNscG6Qi3Oxnci2LOu61+f8MTPyai3JknZW0s5+36+XXtLOzO7MT9I+evT8fvP7mbsjIiLJlVroCxARkfpSoBcRSTgFehGRhFOgFxFJOAV6EZGEyyz0BUxm1apVvmHDhoW+DBGRhrJz586D7t5dvX1RBvoNGzbQ29u70JchItJQzGzvZNtVuhERSTgFehGRhFOgFxFJOAV6EZGEU6AXEUm4GQV6M7vWzHrNLGdmt1TtW2JmnzCzg2Y2YGbfqthnZnajmR0KP240M4u5DSIiMo2ZDq/cB9wAvB5or9q3I3ydc4DDwPkV+7YCbwQ2Aw78G/Ak8Mm5X7KIiMzGjDJ6d7/D3e8EDlVuN7ONwC8CW929z91L7r6z4pA3Ax9192fd/Tngo8BvxnPpIvG66wf76RvMLfRliMSu1hr9K4G9wPvC0s0PzGxLxf5NwK6Kx7vCbccxs61heai3r6+vxssSmZ2+wRxv/+wD/P4/PLDQlyISu1oD/WnAucAAcApwLfBpMzsn3N8Z7osMAJ2T1endfYe797h7T3f3cXfwitTFg0/38+s3fZdn+kcAODJSWOArEolfrVMgjAIF4AZ3LwLfNLN7gNcBDwNDQFfF8V3AkGtZK1kk/uRLu/nxC0NcePoKAFZ1ti7wFYnEr9aMfvck2yqD+B6CjtjI5nCbyKIQ/Wv5bP8oACs7WxbuYkTqZKbDKzNm1gakgbSZtZlZBvgW8DTwp+ExrwJ+BviX8KmfAa4zs1PN7BTgj4Bb4m6ESK2iQN+eTS/wlYjEb6YZ/TaCMs27gavDr7e5ewH4JeAygvr73wG/4e6PhM/7W+CfgB8APwS+Fm4TWRRSYXdRNNomVyxz34/6UHVRksQW4y90T0+Pa5pimQ+X/tW3eOTAIKctbx/P6gH+8n9t5k0vP20Br0xk9sxsp7v3VG/XFAjS1KIBYKP50oTtzx/VeHpJDgV6aWpRZ+xwvjhhe2tGbw1JDv02S1OL7ugYK5QnbM+kNCWTJIcCvTS1qabYG64q5Yg0MgV6aWrG5JF+JFecdLtII1Kgl6Y2VYVmKKeMXpJDgV6a2xS1m2Fl9JIgCvTS1Kbqch3KK9BLcijQS9N5xxe+z7d/fBCYunSjjF6SRIFemkq+WObLDz7HVZ/6LnDshqlqCvSSJAr00lSiO2CjTH6yML+qs1WdsZIoCvTSVKI7YDPp4Fe/MqGP7oZ98eoOxgoK9JIctS48ItJQRsKMPhum9JXj6P/iV8/n1OXt3Hb/Xp45PDrp80UakTJ6aSoj02T0y5dkOf9Fy8imU+RL5cmeLtKQFOilqUQZfTSXTWWgbwlLN62ZFPmiAr0kx0xXmLrWzHrNLGdmt0xxzHvMzM3stRXbWs3sZjM7amYHzOy6mK5bZE6OZfTHl26iQJ9NGwVl9JIgM63R7wNuAF4PtFfvNLMzgV8B9lft2g6cBawHTgbuMbOH3P0bc71gkVocy+gn64wNlhFsUUYvCTOjjN7d73D3O4FDUxzyceBdQL5q+5uBD7h7v7s/TLDU4G/O8VpFajYSDpvMpqcu3WTTKYplp1xefKuvicxFzTV6M/sVIOfud1VtXw6sBXZVbN4FbJridbaG5aHevr6+Wi9LZFLVnbEpO750E31Wh6wkRU2B3syWAh8C/nCS3Z3h54GKbQPA0sley913uHuPu/d0d3fXclkiUxqu6oyt1BIG/+iz6vSSFLVm9NuBW939qUn2DYWfuyq2dQGDNZ5TZM6q14adNqNXnV4SotZAfwnwB+GImgPAi4Avmtm73L2foHN2c8Xxm4E9NZ5TZM6iztgoW5/sztgoo1fpRpJiRqNuzCwTHpsG0mbWBhQJAn224tDvAdcBXw8ffwbYZma9wBrgrcBb4rl0kdk7MhKMF8iXyvze5x7g3keP9QdFAT4blW6K6oyVZJhpRr8NGAXeDVwdfr3N3Q+5+4HoAygB/e4elW3eCzwO7AW+CXxEQytlIT13JJjaIF8s87XdE0cDp8K6/bHOWM13I8kwo4ze3bcT1ONPdNyGqsc54LfCD5EFVxnopxJl9Hll9JIQmgJBmkap7BwYGAOmD/StGl4pCaNAL02jbzBHsewsbctQKE2drWc1vFISRoFemsbBoRwApy5rnzZb1/BKSRoFemkaUXBf2jZ911Q0PYJKN5IUCvTSNAphht7ROn2gV0YvSaNAL00jytBPGOhVo5eEUaCXphEF7qXK6KXJKNBL08irdCNNSoFemkY+HFJ5okCv4ZWSNAr00jSiztjO1vRx+7oqRuJEGX1OGb0khAK9NI2pOmNPXdbOd/70kvHHxzpjNQWCJIMCvTSNqBTTWRXou9qzE7Ydm+tGGb0kgwK9NI18cfJA7z4xc0+njHTKVKOXxFCgl6YxVemm7MeXaFrSKd0ZK4kxo0BvZteGC3fnzOyWiu0/aWb/ZmaHzazPzG43s7UV+83MbjSzQ+HHjWZ2/GKdIvMgWkiko6U60B9/bDZtKt1IYsw0o98H3ADcXLV9ObAD2ACsJ1gP9u8r9m8F3kiwhOB5wBuAt839ckXmLl8qkU4Z7S0Tf+3Lk0T6lkxaGb0kxkwXHrkDwMx6gNMqtn+98jgz+xjBSlKRNwMfdfdnw/0fJVhO8JO1XbbI7BVKTjZttKQnDq+cvHSjjF6SI+4a/auZuPj3JmBXxeNd4bbjmNnWsDzU29fXN9khIjXJF8u0pFPj4+QjpckCfSalzlhJjNgCvZmdB7wH+JOKzZ3AQMXjAaBzsjq9u+9w9x537+nu7o7rskTG5UtlWjLHB/ryJPE8m04po5fEiCXQm9mLga8Df+ju91XsGgK6Kh53AUNePZ5NZB4UimWy6dT4fPORyX4dldFLktQc6M1sPXA38AF3v7Vq9x6CjtjIZiaWdkTmzVQZ/VSlG02BIEkx0+GVGTNrA9JA2szawm2nAv8BfMzdJ+tg/QxwnZmdamanAH8E3BLTtYvMSqEUZPTRFAeRyYdXKqOX5JjRqBtgG/DeisdXA+8DHDgD2G5m26Od7t4Zfvm34f4fhI8/FW4TmXf5otOSTmFmE26Imqx005pJMZwrzvclitTFTIdXbge2T7H7fdM8z4F3hh8iCypfKpMNyzYtmWOBfuqMXl1JkgyaAkGaRqFYpiXsiK3skJ1yCgTV6CUhFOilaUSdscCEDtnSJCl9VqNuJEEU6KVpRDdMwcRAP9lg35a0Rt1IcijQS9MYK5RoywbTH1SOvJkso2/JmOa6kcRQoJemMVasCPSZY/PdnLa8/bhjWzS8UhJEgV6axmi+TFs2LN2EnbEbVi7hs79z4XHHagoESRIFemkauUKJ1kyU0Qe/+pe9bC2ru9qOO1ZTIEiSKNBL05hYugl+9dOpydfBCQK9TzpXvUijUaCXplAqO4WSV5Rugs+pKRY8ixYI18gbSQIFemkKY4USAO1hRp89QaA/fVUHAI8+PzgPVydSXwr00hSiQH986Wby4y9YvxyAnXv7639xInWmQC9NYSwswYyXbsJAn5qiRr+mq401Xa08tO/o/FygSB0p0EtTqM7oW6OMforSDUBXW5aRvGawlManQC9NIQr048Mr09OPugFozWoaBEkGBXppCmOFiaWbE3XGArRl0uN/IEQa2UxXmLrWzHrNLGdmt1Ttu8TMHjGzETO7J1xaMNrXamY3m9lRMztgZtfFfP0iM5KbojN2moSetqwCvSTDTDP6fcANwM2VG81sFXAHcD2wAugFvlBxyHbgLGA98DPAO83s0touWWT2RqccdTNNRp9Njf8nINLIZhTo3f0Od78TOFS163Jgj7vf7u5jBIF9s5ltDPe/mWDR8H53fxj4O+A3Y7lykVmoLt2caNQNQGs2Ta6ojF4aX601+k3AruiBuw8DjwObzGw5sLZyf/j1psleyMy2huWh3r6+vhovS2Si8VE31Z2x09ToWzPK6CUZag30ncBA1bYBYGm4j6r90b7juPsOd+9x957u7u4aL0tkomiCsuoVpqbL6NuU0UtC1Broh4Cuqm1dwGC4j6r90T6ReVUIJyfLhNMTzySjD0bdKKOXxldroN8DbI4emFkHcCZB3b4f2F+5P/x6T43nFJm1QjgevnopwRN3xiqjl8Y30+GVGTNrA9JA2szazCwDfBk418y2hPvfA+x290fCp34G2GZmy8MO2rcCt8TeCpETKJaDQJ+pCvTTJPS0ZdMUy05R89JLg5tpRr8NGAXeDVwdfr3N3fuALcAHgX7gQuCKiue9l6Bzdi/wTeAj7v6NeC5dZOYKpbB0k6oq3Uw36iajqYolGTIzOcjdtxMMnZxs393Axin25YDfCj9EFkwxDPTRHbHZGcx1E425HyuU6Gid0VtFZFHSFAjSFIrlMik7lsG3pmcy6iY4ZkwZvTQ4BXppCoWSj9fnoaIzdoYZvUgjU6CXplAolclWZO/rVi7hRSvaOaO7Y8rnRDNd5jTEUhqcCo/SFIql8oSMfvXSNu57589O+5zW8dKNMnppbMropSkUyk42Pc1YyklE0yWodCONToFemkKxVB4fcTNTUWesSjfS6BTopSkUSz4+/cFMRZ2xmu9GGp0CvTSFfKlMNjXbjD4q3Sijl8amQC9NYS4ZfXRnrGr00ugU6KUpFMtlMnPO6BXopbEp0EtTKJR8fNqDmdKdsZIUCvTSFIrliTdMzUSbbpiShFCgl6ZQmEONPpUyWtIp3TAlDU+BXppCYQ7j6CFaN1aBXhqbAr00hWLJx+ein43WrJYTlMYXS6A3sw1mdpeZ9ZvZATP7WLgCFWZ2vpntNLOR8PP5cZxTZDbmmtG3ZVO6YUoaXlwZ/SeAF4C1wPnAa4C3m1kL8BXgNmA58GngK+F2kXlTLPscA31anbHS8OIK9KcDX3T3MXc/AHwD2ARcTDBD5l+5e87d/xowYPppA0ViFsxeOfvSjRYIlySIK9D/FXCFmS0xs1OBn+dYsN/t7l5x7O5w+wRmttXMes2st6+vL6bLEgkUSj7rG6YgmJNeo26k0cUV6L9FELyPAs8CvcCdQCcwUHXsALC0+gXcfYe797h7T3d3d0yXJRIolMq0ZOaa0at0I42t5kBvZimC7P0OoANYRVCPvxEYArqqntIFDNZ6XpHZKJbnltG3ZdLqjJWGF0dGvwJYB3wsrMMfAv4euAzYA5xnNmFhzvPC7SLzpjDnGr2GV0rjqznQu/tB4EngGjPLmNky4M0Etfh7gRLwB2bWambXhk/7j1rPKzIbxdLcRt20qjNWEiCuGv3lwKVAH/BjoAC8w93zwBuB3wCOAL8FvDHcLjJv8qXyrJcShLAzVhm9NLhYFgd39+8TDKWcbN+DwAVxnEdkLgqlMqWys6Rl9r/ubdkUOWX00uA0BYIk3mgYqFtnOU0xhDdMaZpiaXAK9JJ4Y/kg0Le3pGf93LZMmnz4H4FIo1Kgl8SLMvr27BwCfbj4yFWfup+J9/2JNA4Fekm8WgJ9VO65/4nDDIwWYr0ukfmiQC+JNxqWbtrmUrqp+ONwcCgX2zWJzCcFekm82ko3x57TN6hRwdKYFOgl8aIbntpqqNGDMnppXAr0knij+WB45Nxq9CrdSONToJfEG6ulM1YZvSSAAr0kXlSjb2uZ2w1TkYOq0UuDUqCXxKslo2+rKN0cHdPwSmlMCvSSaEO5Ijd87WGg9s5YjaOXRqVAL4n2nz86OP71XKYprlxKQRm9NCoFekm0h/Yfren5J7Vnx78+Olqs9XJEFoQCvSTa7mePsKKjhdt/96fm9PwVHS3s3PZarv7JdSrdSMOKLdCb2RVm9rCZDZvZ42Z2Ubj9EjN7xMxGzOweM1sf1zlFTmT/kTFesWE5r9iwYs6vsbKzleVLWhgcK1DWLJbSgGIJ9Gb2cwSLgb8FWAq8GnjCzFYRLBp+PcHasr3AF+I4p8hMHBrOsbKztebX6WrLUnYYzqt8I40nroz+fcD73f1+dy+7+3Pu/hzBEoN73P12dx8DtgObzWxjTOcVmVKp7BwezrOqo6Xm1+pqD1anUvlGGlHNgd7M0kAP0G1mPzazZ83sY2bWDmwCdkXHuvsw8Hi4vfp1tppZr5n19vX11XpZIvSP5Ck7rFpae0Yfdcoq0EsjiiOjXwNkgV8GLgLOB14ObAM6gYGq4wcIyjsTuPsOd+9x957u7u4YLkua3aGh4E7WlR21B/poDL4WCpdGFEegHw0//z933+/uB4G/AC4DhoCuquO7gMEYzisyrUPh3DQrO2sv3bSEY/ALJQV6aTw1B3p37weeBSqHI0Rf7wE2RxvNrAM4M9wuUld9YaBfFUegzyjQS+OKqzP274HfN7PVZrYceAfwz8CXgXPNbIuZtQHvAXa7+yMxnVdkSlHpZlUMo26iu2rzRQV6aTxxBfoPAN8DHgMeBh4EPujufcAW4INAP3AhcEVM5xSZ1qHhHJmU0dWWPfHBJ5CdpHRzcCinBcOlIcQS6N294O5vd/dl7n6yu/9BOJwSd7/b3Te6e7u7X+zuT8VxTpETOTiYZ0VHC6mUnfjgE2jJBK+RLwWB/ZnDI/TccDd/d98TNb+2SL1pCgRJrEPDuVjKNgAt6WDUTSEs3TzbH4xBuPuhF2J5fZF6UqCXxDo4lI9lxA1AdjyjDwJ99E9CWaUbaQAK9JJYcWb01TX6aMqbkgK9NAAFekmkfLHM80dzrI7hrlg4NrwyGnUzVgxWrdIcZ9IIFOglkX64b4B8sczmFy2L5fWO3TAVRPaxfBDoNepGGoECvSTS9548DFDT9MSVotLNw/uPUi77+ILjqtFLI8gs9AWI1MO+I6N0tWXojql0kw57X7+6ax+ZlPET65cDUNb9U9IAlNFLIg3nS3S21iePuePB5xjNK6OXxqFAL4k0ki+ypE6BHuC5I8E4egV6aQQK9JJIw7kSHS3pur1+tOh4TnPfSANQoJdEGskXWdJSv4z+v8PO3uFcqW7nEImLAr0k0nCuREdr/TL6Y+fRGrKy+CnQSyLVM6O/4hUvGv96tFAiV1RWL4ubAr0k0nC+fhn9e98wccnjw8P5upxHJC6xBnozO8vMxszstoptV5rZXjMbNrM7zSyeO1hEpjGSq19G35ad+LaJFjgRWazizug/TrAACQBmtgn4W+DXCRYRHwE+EfM5RSYol52RQv1G3ZgZu977Onb8+gUA9I8o0MviFlugN7MrgCPAv1dsvgr4J3f/lrsPAdcDl5vZ0rjOK1JtrFjCnbqOoz+pPcsZ3Z0APLTvKGf9n7vYufdw3c4nUotYAr2ZdQHvB66r2rUJ2BU9cPfHgTxw9iSvsdXMes2st6+vL47LkiYVDXms5zh6gJUdwVz3t3znKQol544Hnqvr+UTmKq6U5wPATe7+rNmEZds6gYGqYweA4zJ6d98B7ADo6enR7YYyZ9GQx/aYa/TX/8JLOTiUG398UnuWlMH+gTGA8QxfZLGp+Z1gZucDrwVePsnuIaCralsXMFjreUWmcmS0AMDyJbUvCl7pt3/69AmPUylj9dI2DhwNAn1JM5zJIhVHynMxsAF4OszmO4G0mb0U+AawOTrQzM4AWoHHYjivyKQODwdZ9/KOeJYRnM6ZqzvGA/1YQYFeFqc4Av0O4PMVj/+YIPBfA6wG/svMLgIeIKjj3+Huyuilbg4PBxn9ynkI9JVDOMcKunFKFqeaA727jxAMmwTAzIaAMXfvA/rM7HeBzwIrgbuBt9R6TpHp9Ic3MM1HRn/qsvbxr5XRy2IV+52x7r7d3a+uePw5d1/n7h3u/kvurjFoUleHhvNk08bSOg6vjPzJ61/Chy9/GSs7Wrj30Rd46uCwMntZdDQFgiRO/3CeFR0tVI0Aq4uO1gy/9sp1tGXTPHFwmIv//F5e/X/vqft5RWZDgV4S59BwnuVL6l+2mcoLg7kTHyQyjxToJXGOjhZYFvPQyhPJl1Sfl8VLgV4SZzBXpLN1fgN9TnV5WcQU6CVxhnNFOudh0ZFKyuhlMVOgl8QZyhXpbKv/iJtKlWvH1mP8vrtz6/17GQjv+hWZDQV6SZyhXJGOeRhaWcnD2Zl+duPq8aCfj3Hh8J17+7n+zh/y3q/8MLbXlOahQC+Jki+WyRfL8zKGfjJruloZK5S49f69nL3t67wwOBbL6w7ngz6AQ1rNSuZAgV4SJZq5cr4z+kj30jaKZef6O4PM+4Wj8Qy1LJc1oavMnQK9JMpQGOg75znQX3j6ivC89ekEjtqVmoebwCR5FibtEamThQr0t7zllRwZzXP3Q89P2D6Sj2fY5dGxoBM2pTgvc6BAL4kytEClm/aWNO0t7bRmJ2b0I/liLK8/OKaMXuZOpRtJlPGMfp6HV0baqgJ9XNMhHA2HVRZUq5c5UKCXROkLA+uy9vm9MzbSlpn4lnrnl3bze597gP0DozW9blS6iTqbRWZDgV4S5cGnj7C0LcOGlR0Lcv7qjB7ga7v387Zbd9b0ukdHgwA/NKZAL7NXc6A3s1Yzu8nM9prZoJl938x+vmL/JWb2iJmNmNk9Zra+1nOKTKX3qcP0rF9OaoF6LaMS+nmnnTRh+5GRud/RenSswD2PvgAcK02JzEYcGX0GeAZ4DXASsA34opltMLNVwB3A9cAKoBf4QgznFDlOvljm8b4hXnbqSSc+uE6iVaaqp0k+ZVnbnF/zW4/1MThWZElLeryEIzIbNQd6dx8OV5V6yt3L7v7PwJPABcDlwB53v93dx4DtwGYz21jreUWqPX14hLLDhlULU7YBOLM7OPcbX37KhO0rapj/ZiQXDNG89NyTGcoVKalDVmYp9hq9ma0Bzgb2AJuAXdE+dx8GHg+3Vz9vq5n1mllvX19f3JclTeCpg8PAwgb6M7o7efj9l/Kml582YXst68mOhlMgn3JSO+4wqKxeZinWQG9mWYKFwD/t7o8AncBA1WEDwNLq57r7Dnfvcfee7u7uOC9LmsRTh4JAf/oCdcRG2lsmdsheePqKmkbLRDddnXxSUP6ppd4vzSm2QG9mKeBWIA9cG24eArqqDu0CBuM6r0jkwMAY7dk0y+swTXAtOlozfPfJw/zajvv5+D0/nvXzo4x+bRToNVWxzFIsgd6CVZhvAtYAW9w9+k3cA2yuOK4DODPcLhKrwbEiXe2L72bvJWGG/19PHOIj//LorJ8/mi9O+APWP6IZLGV24sro/wY4B3iDu1feGfJl4Fwz22JmbcB7gN1hWUckVoO5AkvbFuZGqcl86jd6uO23LxwP9BH32XWmjhZKtLekx28CG1DpRmYpjnH064G3AecDB8xsKPy4yt37gC3AB4F+4ELgilrPKTKZwbEiSxdo6oPJvPala/jps1ZRKE0M7Nfc9sCsFiUZyZdoz6ZZFg7ZPKKMXmap5neFu+8Fprw7xd3vBjScUuru6FiRkxZo6oPpDFbdzfqNPQe4++Hnuexla2f0/LEwo+8K/4ipRi+zpSkQJDEGxwqLKqOPDOWCwHzlhevGt739sw/w6IGZjUkYyZdY0pImk06xtDWjUTcyawr0khhHR4vjWe9i0r00GC1zZnfnhO1P9A3N6Pmj+dL4HDpL2zKa2ExmbfG9K0TmKMjoF1/p5oNvOpfXvXTNcROtDcywBDNaKI3fWdvRmtF8NzJryuglEfLFMrkFXBR8Ol1tWd6w+ZTjhn7OtNY+GnbGQjDPvgK9zNbie1eIzEE0LcBirNFHusL/NtIpI2Xw+AtDbP/qHvYdGWX5khb+9LKN4yNrKo3kS+N323Yqo5c5UEYviXBoOBhyuNjuiq3U1Z7l5K42btxyHplUitt3Psst33mKf33oeb7Q+ww3f/up8WNfGBzj3f+4m5F8kZF8cXwsfmdrRnPSy6wp0Esi7D00AsD6BZ7nZjrplHH//76EX77gtPFpDSr1PnV4/Ov3ffUhPv+9Z/i3h56nf6TA6rBDt6NVnbEyewr0kgh7wwnN1q9YssBXMjuvPH3F+NcPPn1kfAriRw4cBeBHzwcjc6J5bjpbMwwq0MssKdBLIuw9NEJXW4ZlSxbfqJvpbA5XolrZ0cJoocThsAQVLSreuzfI8k9Z1g4EgX44V5z1NArS3BZvz5XILDx9eIR1K5dgtjBLCM5Wz/rl9O7tJ5sOcq2VnS0cGs5z54PPMVYojd9N+/1njgAVGX1bhrIHQy6XtOjtKzOj3xRJhAMDY6xf2Thlm8++9UIKJeebjwaL7Lzqxat47PkhPnjXwxOOixYsWXtSkNF3hMNHh3JFBXqZMZVuJBH2D4yOZ72NoDWTprM1w/88by1f/8OLuOrC9ccdE83bs3xJdnx4ZXTn77u+tJuN1399/i5YGpoCvTS84VyRo2NFTg6z3kZzztouVnUePyz0J9YtA45l8wAvXRus43PPo32MFcr0D2smSzkxBXppeAeOjgE0VEZfrati6obopq+fWLccgFOWHWvXi1d3sryiw/nJcLSRyHQU6KXhPdsfrHVzcgMH+lTqWCfyP17zP3jXpRt5ycnB0sqVGb2Z8YbNp4w/jhZEF5lO3QO9ma0wsy+b2bCZ7TWzK+t9Tmke7s6n7nuCrrYM56ytXp64sXzxbT/FvX98MWevWco1F585PqRy7bKJf8De94ubuPP3XkU6Zfz3k4cneymRCeaj2/7jBAuGryFYheprZrbL3bVurNQkXyzzobse5r4fHeT6X3jpolx0ZDYqb56CYFrjV25YwavOXDVhu5lx/ouWcfWF6/j0f+1lTVcb7/i5s+fzUqXBWD1vvAgXA+8HznX3x8JttwLPufu7p3peT0+P9/b2zvp8f/3vP+Kru/bN9XKPU4/vTV2+2zG/aD2uMe7vZdmDsfMAP7txNZ+8+gJaMs1VicwXy7zzS7v4yq59vHGa/iUAAAWDSURBVLhqrntpXB+6/GW8YsOKEx84CTPb6e491dvrndGfDRSjIB/aBbym+kAz2wpsBVi3bl317hlZvbSVl6xZOqfnTqkO99/U45aeuG8Uqs81xvt6r9+0hp88YyWXnLMm3hduEC2ZFDe86WV0tWc5OJRb6MuRmERTUsep3hn9RcDt7n5yxba3Ale5+8VTPW+uGb2ISDObKqOv9/+6Q0B1D1kXMLPFMkVEpGb1DvSPARkzO6ti22ZAHbEiIvOkroHe3YeBO4D3m1mHmb0K+CXg1nqeV0REjpmPYQpvB9qBF4B/AK7R0EoRkflT93H07n4YeGO9zyMiIpNrroHHIiJNSIFeRCThFOhFRBKurjdMzZWZ9QF75/j0VcDBGC9nsWum9jZTW6G52ttMbYX6tXe9u3dXb1yUgb4WZtY72Z1hSdVM7W2mtkJztbeZ2grz316VbkREEk6BXkQk4ZIY6Hcs9AXMs2ZqbzO1FZqrvc3UVpjn9iauRi8iIhMlMaMXEZEKCvQiIgmnQC8iknCJCfRmtsLMvmxmw2a218yuXOhrqoWZXWtmvWaWM7NbqvZdYmaPmNmImd1jZusr9rWa2c1mdtTMDpjZdfN+8bMUXvNN4c9t0My+b2Y/X7E/ae29zcz2h9f8mJn9TsW+RLW1kpmdZWZjZnZbxbYrw5/7sJndaWYrKvY15HvazO4N2zkUfjxasW9h2uvuifggmAL5C0An8NPAALBpoa+rhvZcTjDr598At1RsXxW27VeANuAjwP0V+z8M3AcsB84BDgCXLnR7TtDWDmA7sIEg+fgFglXINiS0vZuA1vDrjeE1X5DEtla1+1/D67+t4vswCLw6fN9+Dvh8xfEN+Z4G7gV+Z4qf+4K0d8G/KTF9YzuAPHB2xbZbgT9b6GuLoW03VAX6rcB3qto+CmwMH+8DXlex/wOVv0yN8gHsBrYkvb3AS4D9wK8mua3AFcAXCf6gR4H+Q8DnKo45M3wfL23k9/Q0gX7B2puU0s3ZQNHdH6vYtovgL2jSbCJoGzC+itfjwCYzWw6srdxPA34fzGwNwc90Dwltr5l9wsxGgEcIAv1dJLetXcD7gepSU3V7HycMdjT+e/rDZnbQzL5tZheH2xasvUkJ9J3A0aptAwR/KZOmk6BtlaK2dlY8rt7XEMwsC3wW+LS7P0JC2+vubye4zosIltvMkdC2EvzncZO7P1u1/UTtbdT39LuAM4BTCW6M+iczO5MFbG9SAv0Q0FW1rYugHpY007V1qOJx9b5Fz8xSBP+u5oFrw82Jba+7l9z9P4HTgGtIYFvN7HzgtcBfTrL7RO1tyPe0u3/X3QfdPefunwa+DVzGArY3KYH+MSBjZmdVbNtM8K9/0uwhaBsAZtZBUOvb4+79BGWAzRXHN8T3wcwMuAlYA2xx90K4K5HtrZIhbBPJa+vFBJ3qT5vZAeCPgS1m9gDHt/cMoJXg/Zyk97QDxkK2d6E7LmLsAPk8Qa91B/AqGqSHfpr2ZAhGXnyYIMttC7d1h23bEm67kYkjM/4M+CbByIyNBMFh0Y/MAD4J3A90Vm1PVHuB1QQdk51AGng9MAz8YtLaGl7zEuDkio8/B74UtnUTQbniovB9exsTR6E03HsaWBb+TKP361Xhz/fshWzvgn9jYvwGrwDuDL+pTwNXLvQ11die7QSZQOXH9nDfawk68UYJevg3VDyvFbg5/IV6Hrhuodsyg7auD9s3RvAvbPRxVdLaGwa4bwJHwmv+AfDWiv2JaesU7d9OOOomfHxl+H4dBr4CrKjY13Dv6fDn+z2CkssRguTl5xa6vZrUTEQk4ZJSoxcRkSko0IuIJJwCvYhIwinQi4gknAK9iEjCKdCLiCScAr2ISMIp0IuIJNz/B7Ncq4na3UauAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Links\n",
        "\n",
        "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
        "\n",
        "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
      ],
      "metadata": {
        "id": "rpGo7xQz6cny"
      }
    }
  ]
}