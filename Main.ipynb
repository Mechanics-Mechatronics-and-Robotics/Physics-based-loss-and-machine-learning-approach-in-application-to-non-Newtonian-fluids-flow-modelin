{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Physics-based loss and machine learing approach in application to fluids flow modelling: 2D flow domains**\n",
        "\n",
        "The program recieves an image of the flow domain and the flow rate value, then calculate velocity distribution. The main idea is power loss minimization. The main unknown function is the stream function $\\psi = \\psi(x_1, x_2)$ that determines the velocity field $\\textbf{V} = [[v_1, v_2]]$, where $v_1 = \\frac{\\partial \\psi}{\\partial x_2}$, $v_2 = - \\frac{\\partial \\psi}{\\partial x_1}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "RJkKJ83igGYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "ozT2l1DxVSOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "s3KFs0M9r7EQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "jPSaJ-z614Tm"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "ydwhZV95sFoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "Go3JwW4hICsK"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "BT8OQ6AkVb6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional functions"
      ],
      "metadata": {
        "id": "Hw2AD3oWsfJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical derivative"
      ],
      "metadata": {
        "id": "2JAf1YAHtV15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mydiff(j,y,dx):\n",
        "  '''The function calculates the first order derivative in a specific direction \n",
        "     'dx' at a specific point 'j' for a given array 'y' \n",
        "     using parabolic approximation\n",
        "  '''\n",
        "  dydx = 0\n",
        "  n = len(y)\n",
        "  if j==0:\n",
        "    dydx=(-y[3]+4*y[2]-3*y[1])/(2*dx)\n",
        "  elif j==n-1:\n",
        "    dydx=(3*y[j]-4*y[j-1]+y[j-2])/(2*dx)\n",
        "  else:\n",
        "    dydx=(y[j+1]-y[j-1])/(2*dx);\n",
        "  return dydx"
      ],
      "metadata": {
        "id": "MSTF3qPgtbn8"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_diff(f, dx1, dx2):\n",
        "  '''function to find partial derivatives of a two variables function:\n",
        "  i - index along x1\n",
        "  j - index along x2\n",
        "  for internal points - central differences e.q. df_dx = (f_{i+1}-f_{i-1})/(2*dx)\n",
        "  for boundaries - left and right finite differences e.q. df_dx = (f_{i+1}-f_{i})/dx or df_dx = (f_{i}-f_{i-1})/dx\n",
        "  '''\n",
        "  n1, n2 = f.shape\n",
        "  df_dx1, df_dx2 = torch.zeros(n1,n2), torch.zeros(n1,n2)\n",
        "  # x1 derivative:\n",
        "  df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:])/(2*dx1)\n",
        "  df_dx1[0,:] = (f[1,:] - f[0,:])/dx1\n",
        "  df_dx1[n1-1,:] = (f[n1-1,:] - f[n1-2,:])/dx1\n",
        "  # x2 derivative:\n",
        "  df_dx2[:, 1:n2-1] = (f[:,2:] - f[:,:-2])/(2*dx2)\n",
        "  df_dx2[:, 0] = (f[:,1] - f[:,0])/dx2\n",
        "  df_dx2[:,n2-1] = (f[:,n2-1] - f[:,n2-2])/dx2\n",
        "  return df_dx1, df_dx2"
      ],
      "metadata": {
        "id": "5P2RND6cYEOK"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical integrals: single and double"
      ],
      "metadata": {
        "id": "1i1RAg4ozeGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singleIntegral(f,lowerLim,upperLim):\n",
        "  '''The function calculates the single integral using Simpson's formula. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the difference between the upper and lower limits.\n",
        "  '''  \n",
        "  sglInt = 0\n",
        "  n = len(f)\n",
        "  x = torch.linspace(0,1,n)\n",
        "  dxn = x[1]-x[0]\n",
        "\n",
        "  for i in range (1, (n-1), 2):\n",
        "    sglInt += (f[i-1] + 4*f[i]+f[i+1])*dxn/3\n",
        "  if (n % 2) == 0:\n",
        "    sglInt += (f[-1]+f[-2])*dxn/2\n",
        "\n",
        "  sglInt = sglInt*(upperLim-lowerLim)\n",
        "\n",
        "  return sglInt"
      ],
      "metadata": {
        "id": "MbSgsSbO0srV"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doublelIntegral(f,lim1,lim2):\n",
        "  '''The function calculates the double integral using Simpson's formula twice. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the differences between the upper and lower limits.\n",
        "  '''\n",
        "  dblInt = 0\n",
        "  n = f.shape\n",
        "  x1 = torch.linspace(0,1,n[0])\n",
        "  x2 = torch.linspace(0,1,n[1])\n",
        "  dx1n = x1[1]-x1[0]\n",
        "  dx2n = x2[1]-x2[0]\n",
        "\n",
        "  for i in range (1, (n[0]-1), 2):\n",
        "    for j in range (1, (n[1]-1), 2):\n",
        "      dblInt += (f[i-1][j-1] + f[i+1][j-1] + f[i-1][j+1] + f[i+1][j+1] + \n",
        "                   4*(f[i][j+1] + f[i][j-1] + f[i-1][j] + f[i+1][j]) + \n",
        "                   16*f[i][j])*dx1n*dx2n/9\n",
        "          \n",
        "  dblInt = dblInt*(lim1[1]-lim1[0])*(lim2[1]-lim2[0])\n",
        "\n",
        "  return (dblInt)"
      ],
      "metadata": {
        "id": "fxibGVL-zkCW"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check double integral "
      ],
      "metadata": {
        "id": "qyl0qTFMj-lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 101\n",
        "x = torch.linspace(0,1,ss)\n",
        "y = torch.linspace(0,1,ss)\n",
        "y = y.reshape(1,-1).t()\n",
        "z = (x*x) * (y*y)\n",
        "print(doublelIntegral(z,[0,1],[0,1]),'- calculated', 1/9, '- exact')"
      ],
      "metadata": {
        "id": "byisjmu7c8C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1f2a52-8056-48da-8834-593f1266f4b9"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1111) - calculated 0.1111111111111111 - exact\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color filter "
      ],
      "metadata": {
        "id": "lon3t_mIeGEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colorFilter(img, color):\n",
        "  white = (255,255,255,255)\n",
        "  black = (0,0,0,255)\n",
        "  width,heigth = img.size\n",
        "  for i in range(width):\n",
        "    for j in range(heigth):\n",
        "      if img.getpixel((i,j)) == color:\n",
        "        img.putpixel((i,j),black)\n",
        "      else:\n",
        "        #print(img.getpixel((i,j)))\n",
        "        img.putpixel((i,j),white)\n",
        "  return (img)"
      ],
      "metadata": {
        "id": "626DXTn0eKR-"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Major functions\n",
        "\n",
        "Distributions: the velocity components [[$v_1$, $v_2$]], the strain rate tensor components [[$\\xi_{ij}$]], $\\xi_{ij}=\\xi_{ji}$ . And the shear rate intensity Î—. "
      ],
      "metadata": {
        "id": "mH8zURs8A1Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def velocityDistr(psi,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = psi.shape\n",
        "  dpsidx1, dpsidx2 = num_diff(psi, dx1n, dx2n)\n",
        "  v1 = dpsidx2/lim2[1]\n",
        "  v2 = - dpsidx1/lim1[1]\n",
        "\n",
        "  return v1,v2"
      ],
      "metadata": {
        "id": "WMUIipgs5t3Q"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = v1.shape\n",
        "  dv1dx1, dv1dx2 = num_diff(v1, dx1n, dx2n)\n",
        "  dv2dx1, dv2dx2 = num_diff(v2, dx1n, dx2n)\n",
        "\n",
        "  xi11 = dv1dx1/lim1[1]\n",
        "  xi12 = 0.5*(dv1dx2/lim2[1] + dv2dx1/lim1[1])\n",
        "  xi22 = dv2dx2/lim2[1]\n",
        "  EtaEta = (2*(xi11*xi11 + 2*xi12*xi12 + xi22*xi22))\n",
        "\n",
        "  return xi11,xi12,xi22,EtaEta"
      ],
      "metadata": {
        "id": "716qlRJoNglx"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "nzMpruhsYD38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image of the flow domain"
      ],
      "metadata": {
        "id": "itN_H_kFke1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path"
      ],
      "metadata": {
        "id": "3NCXTaNK4V4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " path =  Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss')\n",
        " imgPath = path/'ToyDataset'\n",
        " imgList = imgPath.ls()\n",
        " imgPath.ls()"
      ],
      "metadata": {
        "id": "tDbZIropJMjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59342e35-9811-4f93-fea1-a2bdf3929d7a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates and ball.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates with notch.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates.png')]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simulation"
      ],
      "metadata": {
        "id": "GYoObHLVIZWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "noOfEpoch = 1500\n",
        "learnRate = 0.001"
      ],
      "metadata": {
        "id": "YsKHT1J2Ibx9"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometry\n",
        "The domain of size *'L x L'*  with flow channel is represented as an image of size *'imgSize x imgSize'*. S1 is the upper wall with black label [0 0 0]. S2 and S4 are outlet and inlet surfaces, respectivelly. S3 is the lower wall with blue label [0 0 255]. "
      ],
      "metadata": {
        "id": "ORhTWZZvVw7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = 0.1 # L x L flow domain\n",
        "imgSize = 512 # imgSize x imgSize pixels image\n",
        "imgNo = 2\n",
        "upperWallColor =  (0, 0, 0,255)\n",
        "lowerWallColor =  (0, 0, 255,255)\n",
        "#Normalized coordinates\n",
        "x1n = torch.linspace(0,1,imgSize)\n",
        "x2n = torch.linspace(0,1,imgSize)\n",
        "dx1n = x1n[1] - x1n[0]\n",
        "dx2n = x2n[1] - x2n[0]\n",
        "lim1 = [0, L]\n",
        "lim2 = [0, L]\n",
        "#Visualisation\n",
        "figSize = 3\n"
      ],
      "metadata": {
        "id": "y8Q_jxpUYIEm"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "domainMask "
      ],
      "metadata": {
        "id": "1hKq9A5gtHzs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "26980c70-311a-43a1-9774-4e7a1c43a4c7"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB+CAYAAADiI6WIAAABQ0lEQVR4nO3cwQ3AMAgAMVJl/5XpGHmcPQHSiSecmdkh53s9AG8IHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81N31rr7IxkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkedGeeyRTY+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aN+UssG9+2j5aIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=126x126 at 0x7FA74A93E0D0>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create masks for the walls and resize image"
      ],
      "metadata": {
        "id": "45EnY5VmEcjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2n.dtype"
      ],
      "metadata": {
        "id": "SgL2YvbN3rmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1760021c-a86b-4751-9959-32eac03fc4e7"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "upperWallMask = colorFilter(domainMask, upperWallColor)\n",
        "upperWallMask = upperWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#upperWallMask"
      ],
      "metadata": {
        "id": "lmyMgC4op_o_"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "lowerWallMask = colorFilter(domainMask, lowerWallColor)\n",
        "lowerWallMask = lowerWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#lowerWallMask"
      ],
      "metadata": {
        "id": "FF424vauuCi8"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kinematic properties\n",
        "The velocity is equal to zero on all the surfaces. The flow rate is known."
      ],
      "metadata": {
        "id": "XaVb_Ejsmynq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 1 #flow rate through the inlet (outlet) boundary, m^3/s\n",
        "psim = 0 # lower wall\n",
        "psip = Q # upper wall\n",
        "psi00 = torch.linspace(Q,0,imgSize, dtype=torch.float32)*torch.ones(imgSize,imgSize)\n",
        "psi0 = torch.t(psi00)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0)"
      ],
      "metadata": {
        "id": "Gb4BFZNWnBsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "7339fbe7-3783-4b4b-9f92-862b00d66bd6"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa74a8f2f90>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psi00.dtype"
      ],
      "metadata": {
        "id": "H-xEZhto3cLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1b7d27-69a6-491c-e625-b2c3fb891320"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wallsMask = (tensor(upperWallMask)[:,:,1]*tensor(lowerWallMask)[:,:,1])\n",
        "inverseUpperWallMask = (tensor(upperWallMask)[:,:,1]/(-255)+1)\n",
        "psi0Masked = (psi0*wallsMask) + (inverseUpperWallMask*Q)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0Masked)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "id": "lyOiYXNSUVnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "28956e8d-f33c-4e05-f61b-0904c6c4d9e3"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'psi function with mask')"
            ]
          },
          "metadata": {},
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.plot(psi0Masked[:,200])"
      ],
      "metadata": {
        "id": "e_0lRm44DIkI",
        "outputId": "cddbf7f2-d2b8-4534-9688-e7dcb7fcf4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa74a836610>]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMwAAADCCAYAAAAFKC2CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPM0lEQVR4nO3dfZBV9X3H8ff37i6sAQRhEZWnxYpO0CrICkt1RifYjiFW07Eh0vhMXDtJrU5SM3HSIU6baUc7xcapRhcfUGtBpU6lCTFRQ6Zp6iqLigaIAjYaDAqIARXl8ds/7tmz67LsuRfO8ru/u5/XzA733nO493sWPnN+5+H3vebuiEhpCqELEImJAiNSBgVGpAwKjEgZFBiRMigwImWoDfXBDQ0N3tjYGOrjRQ5q5cqVW919ZE/LggWmsbGR9vb2UB8vclBm9ubBlmlIJlIGBUakDJmBMbP7zWyzmf3qIMvNzO4ws/Vm9oqZnZl/mSKVoZQ9zELggl6Wfx6YmPy0AD84/LJEKlPmQb+7/7eZNfayysXAQ168i7PNzIaZ2fHuvulQCtq5ey/ffXL1ofzV6Aypr+NbF5xCfV1N6FKkRHmcJRsN/LbL843JawcExsxaKO6FGDduXI9vtmef88v1W3Moq7J9snc/2z7azUWTT2Dy2GGhy5ESHdHTyu7eCrQCNDU19TivYOhRdfzvzTOPZFlBLH9tM1c/sIL9ml4RlTzOkr0NjO3yfEzymvTCkj+Vl7jkEZilwBXJ2bJmYPuhHr/0JwVLIxO0DilP5pDMzBYB5wENZrYR+C5QB+DudwPLgFnAemAncHVfFVtNOvKyX3mJSilnyeZkLHfg67lV1E9YMijTkCwuutIfSCHZw6inQlwUmFA0JIuSAhNIOiTTQX9UFJhACjpJFiUFJhBLTpNpSBYXBSaQjtPKGpLFRYEJpPMsWdg6pDwKTDAdQzIlJiYKTCCdQzKJiQITSEGJiZICE0jHWWUNyeKiwARiOuiPkgITSMeQTHmJiwITmIZkcVFgAkn3MMpLVBSYQNIJlxqURUWBCUQzLuOkwASiIVmcFJhAOu/uV2JiosAEoiFZnEoKjJldYGavJQ3Hv93D8nFmttzMXkoaks/Kv9TqYumQTImJSSnd+2uAOyk2HZ8EzDGzSd1W+1vgMXefAlwK3JV3odXGsleRClTKHmYasN7d33D33cBiig3Iu3Lg6OTxUOB3+ZVYnTpnXGoPE5NSeiv31Gx8erd1bgF+ambXA4OA83OproppAlmc8jronwMsdPcxFLtgPmxmB7y3mbWYWbuZtW/ZsiWnj46TGvnFqZTAlNJsfC7wGIC7PwfUAw3d38jdW929yd2bRo7s8Utq+43Os2RKTExKCcwKYKKZTTCzARQP6pd2W+ctYCaAmX2WYmD69y4kg+aPxSkzMO6+F/gr4CfAWopnw1ab2d+Z2UXJat8ErjWzVcAi4CrX+dJemRITpZK+UMndl1Hs0t/1tXldHq8Bzs63tOqmGZdx0pX+QDSBLE4KTCCaohwnBSYQDcnipMAEYhqSRUmBCaTzKy4VmZgoMIF0DsmCliFlUmACKej2/igpMIHoumWcFJhADH2hUowUmEA67uXWkCwuCkwgmnEZJwUmEM24jJMCE4hmXMZJgQkknXEZuA4pjwITiGZcxkmBCUR3K8dJgQnEdJ4sSgpMIB0H/ft15TIqCkwgur0/TgpMILq7P04KTCA6SxanXLr3J+vMNrM1ZrbazP493zKrj5lRV2Os2bSDfTqOiUYu3fvNbCJwM3C2u58K3NgHtVad6z83kafXvMtNj69SaCJRSl+ytHs/gJl1dO9f02Wda4E73f19AHffnHeh1eivZ07EgH9++nX27Hfmzz6DuhqNkitZXt37TwYws18CNcAt7v5U9zcysxagBWDcuHGHUm/VuX7mRAbUFvjHH/+aPXv3c8ecKQyoVWgqVV7/MrXAROA8ip38F5jZsO4rqRl5z6479w+Yd+Eknlr9Dl97ZCW79u4LXZIcRF7d+zcCS919j7v/H/A6xQBJia45ZwLf++JpPLN2M9c+tJJP9ig0lSiv7v3/SXHvgpk1UByivZFjnf3CZc3jue2S0/nFui1cs3AFO3fvDV2SdJNX9/6fAO+Z2RpgOXCTu7/XV0VXs9lnjWX+7DNoe+M9rnpgBR/uUmgqiYWaU97U1OTt7e1BPjsG/7Xqd9z46MucMWYoC6+ZxtH1daFL6jfMbKW7N/W0TKdjKtSfnnECd/7FFF59ezuX3/s823fuCV2SoMBUtAtOO567L5vK2k0fMGdBG9s+2h26pH5PgalwMz87igVXNrFhy4fMaW1j64e7QpfUrykwETj35JE8cNVZvLVtJ5e2trF5xyehS+q3FJhI/NFJDSy8+iw2/f5jvtzaxqbtH4cuqV9SYCIy/cQRPDR3Ols/2MXse57jt9t2hi6p31FgIjN1/DH821ens33nHi5tbePN9z4KXVK/osBE6Iyxw1jU0szO3XuZfc9zbNjyYeiS+g0FJlKnnjCUxS0z2Lff+fI9bax794PQJfULCkzETjluCItbmikYXNraxtpNO0KXVPUUmMiddOwQHr1uBgNqC8xZ0Mav3t4euqSqpsBUgQkNg3jsuhkMGlDLnAVtvPTW+6FLqloKTJUYO/wzPPaXMxg+aACX3/cC7b/ZFrqkqqTAVJHRw47i0ZYZHDtkIFfc/wLPbdAMi7wpMFXmuKH1LL6umdHDjuLqhS/wP+u2hi6pqigwVejYIfUsbmmmccQgrnlwBct/rSY+eVFgqtSIwQNZdG0zJ48aTMvD7fx09TuhS6oKCkwVO2bQAB75ajOnnjCUrz3yIste3RS6pOgpMFVu6FF1PDx3GpPHDuP6RS/x5MvdG/5IORSYfmBIfR0PXjONsxqP4cZHX2bJyo2hS4qWAtNPDBpYywNXTeOckxq4ackqFr3wVuiSopRb9/5kvUvMzM2sx44bEtZRA2pYcEUT5508kpufeJWHnvtN6JKik0v3/mS9IcANwPN5Fyn5qa+r4e7Lp/LHk0Yx78nV3PsL9VssRyl7mLR7v7vvBjq693f398CtgCacV7iBtTXc9ZUzmfWHx/G9H63lrp+vD11SNEoJTE/d+0d3XcHMzgTGuvuPensjM2sxs3Yza9+yZUvZxUp+6moK3HHpFC6efAK3PfUa339mHaGaOsaklK+76JWZFYD5wFVZ67p7K9AKxc6Xh/vZcnhqawrMnz2ZupoCtz/zOrv37eNv/uSU9Atr5UClBCare/8Q4DTg58kv+jhgqZld5O7qBVvhagrGbZecTl1NgTuXb2D88EHMPmts9l/spw67e7+7b3f3BndvdPdGoA1QWCJSKBj/8GenUV9XYN1mTXXuTV7d+yVyZkbBTF+DnqGkYxh3XwYs6/bavIOse97hlyUhGKC89E5X+iVVMGO/djG9UmCkk6EhWQYFRlI6mZxNgZFUoaAhWRYFRlKGhmRZFBhJmQ76MykwkiqYTitnUWCkC124zKLASKpg6I7lDAqMpEzXYTIpMJIyDNdRTK8UGEkVDPYrL71SYCRluls5kwIjn6IhWe8UGEkVCjroz6LASMownVbOoMBIynSlP5MCI6niBLLQVVQ2BUZSxbuVlZjeKDDSSUOyTLk0Izezb5jZGjN7xcyeNbPx+Zcqfa3YNUaR6U1ezchfAprc/XRgCXBb3oVK39MEsmy5NCN39+XuvjN52kaxO6ZERjdfZsulGXk3c4EfH05REobaLGU77GbkXZnZZUATcO5BlrcALQDjxo3L86MlJ4pL70rZw2Q1IwfAzM4HvkOxr/Kunt7I3Vvdvcndm0aOHHko9Uof0s2X2Q67GTmAmU0B7qEYls35lylHgmZcZsurGfk/AYOBx83sZTNbepC3kwqmW2Oy5dKM3N3Pz7kuCUDXYbLpSr+kDM24zKLASCczDckyKDCS0kF/NgVGUro1JpsCIykztVnKosBIqqB7yTIpMJIydC9ZFgVGOmkPk0mBkZS+7iKbAiMptVnKpsBIShPIsikwktIEsmwKjKR0t3I2BUY+RTuY3ikwktLt/dkUGElpSJZNgZFUQXP6MykwkipOIFNieqPASErXYbIpMJIyzbjMpMBISl93kS2v7v0DzezRZPnzZtaYd6HS9zQky5ZX9/65wPvufhJwO3Br3oVK3ytoxmWmUvqSpd37Acyso3v/mi7rXAzckjxeAvyrmZlr/x4VM9j+8R6eeHFj6FL63PgRn2Hq+OFl/71SAtNT9/7pB1vH3fea2XZgBLC160pqRl7ZGgYP5N0du/jGY6tCl9LnvjR1TJ8FJjfu3gq0AjQ1NWnvU2HmXTiJuedMCF3GETFo4KH91y/lb5XSvb9jnY1mVgsMBd47pIokmNqaAuNHDApdRkXLpXt/8vzK5PGfAz/T8YtUo8w9THJM0tG9vwa4v6N7P9Du7kuB+4CHzWw9sI1iqESqTl7d+z8BvpRvaSKVR1f6RcqgwIiUwUIdm5vZFuDNXlZpoNt1nCrWn7YVKn97x7t7j1/CGiwwWcys3d2bQtdxJPSnbYW4t1dDMpEyKDAiZajkwLSGLuAI6k/bChFvb8Uew4hUokrew4hUnIoLTNbszhiZ2VgzW25ma8xstZndkLw+3MyeNrN1yZ/HJK+bmd2R/A5eMbMzw25B+cysxsxeMrMfJs8nJLNx1yezcwckr0c1W7eiAlPi7M4Y7QW+6e6TgGbg68l2fRt41t0nAs8mz6G4/ROTnxbgB0e+5MN2A7C2y/NbgduTWbnvU5ylC5HN1q2owNBldqe77wY6ZndGzd03ufuLyeMPKP5HGk1x2x5MVnsQ+GLy+GLgIS9qA4aZ2fFHuOxDZmZjgC8A9ybPDfgcxdm4cOC2dvwOlgAzk/UrUqUFpqfZnaMD1dInkiHHFOB5YJS7b0oWvQOMSh7H/nv4F+BbwP7k+Qjg9+6+N3nedXs+NVsX6JitW5EqLTBVzcwGA/8B3OjuO7ouS+YPRX/K0swuBDa7+8rQtfSFIzpFuQSlzO6MkpnVUQzLI+7+RPLyu2Z2vLtvSoZcm5PXY/49nA1cZGazgHrgaOD7FIeVtclepOv2RDVbt9L2MKXM7oxOMia/D1jr7vO7LOo6U/VK4Mkur1+RnC1rBrZ3GbpVNHe/2d3HuHsjxX+/n7n7V4DlFGfjwoHbGs9sXXevqB9gFvA6sAH4Tuh6ctqmcygOt14BXk5+ZlEcqz8LrAOeAYYn6xvFs4UbgFeBptDbcIjbfR7ww+TxicALwHrgcWBg8np98nx9svzE0HX39qMr/SJlqLQhmUhFU2BEyqDAiJRBgREpgwIjUgYFRqQMCoxIGRQYkTL8P4aA9l7ubDMbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Velocity distribution"
      ],
      "metadata": {
        "id": "B7LQzVv63_0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psi0Masked,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "id": "qbVbaBjT3aOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "c1e4e23a-4b49-434d-ad55-668b7b4ae2a9"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'v2')"
            ]
          },
          "metadata": {},
          "execution_count": 150
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dynamic properties\n",
        "The fluid is Newtonian."
      ],
      "metadata": {
        "id": "hvAQmdvsnZQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 1e-3 # koefficient of dynamic viscosity (viscosity), Pa*s"
      ],
      "metadata": {
        "id": "t4YCVOBPneFt"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check assimptotic solution\n",
        "Newtonian fluid flows between parallel plates "
      ],
      "metadata": {
        "id": "wOpHVjQdkxS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=(126-92)*L/126\n",
        "pressureDrop = Q*3*mu*L/(2*h*h*h)\n",
        "externalPower = pressureDrop*Q\n",
        "v1ex = pressureDrop/(2*mu*L)*(1-x2n*x2n)*h*h\n",
        "psiex = pressureDrop/(2*mu*L)*(1-x2n*x2n/3)*h*h*h*x2n\n",
        "print('h =',h,'pressure drop =',pressureDrop,'external power =',externalPower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpG0AV2LlF-W",
        "outputId": "b7432302-a43e-4cbb-b016-53be352bfdc0"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h = 0.026984126984126985 pressure drop = 7.634245878282108 external power = 7.634245878282108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(v1ex)\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(psiex)"
      ],
      "metadata": {
        "id": "QZ7FdI9-GB6e",
        "outputId": "907d33f9-be6e-4160-8d3a-c47010864de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa74d460750>]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "PhZutgNIyYhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create model\n",
        "Unet architecture [2] is used"
      ],
      "metadata": {
        "id": "FPeLHoR31p1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=4):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return torch.sigmoid(self.conv(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        \n",
        "model = UNet(in_channels=1, out_channels=1, init_features=32)"
      ],
      "metadata": {
        "id": "PID82zl-cxN4"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "2yb3P0n1c8df"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "PwikCXOPyPPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learnRate, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "oKBkisM7hASi"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input image"
      ],
      "metadata": {
        "id": "TyTAp5u0yroJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi0Masked.dtype"
      ],
      "metadata": {
        "id": "j6BFOOEv3OhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55df3c06-7cd6-49b3-f848-c51143227a3d"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = torch.randn((1, 1, 512, 512))\n",
        "x = torch.ones((1, 1, imgSize, imgSize))*psi0Masked\n",
        "#fig = plt.figure(figsize=(3, 3))\n",
        "#plt.imshow(x[0,0,:,:])\n",
        "x.dtype, x.shape"
      ],
      "metadata": {
        "id": "xruHyQ-vdVhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c621f83e-5a9a-458c-99fc-427d91767c3e"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.Size([1, 1, 512, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model(x)"
      ],
      "metadata": {
        "id": "f1L8QG9ndbML"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = dx1n*dx2n*lim1[1]*lim2[1]\n",
        "s"
      ],
      "metadata": {
        "id": "osreN0VAdhZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed157a0-5d18-4670-f049-1e32628304c7"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8296e-08)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "\n",
        "for epoch in range(noOfEpoch):\n",
        "  psi = model(x)\n",
        "  psiMasked = (psi[0,0,:,:]*wallsMask) + (inverseUpperWallMask*Q)\n",
        "  print(psi[0,0,:,:].shape)\n",
        "  v1,v2 = velocityDistr(psiMasked,dx1n,dx2n,lim1,lim2)\n",
        "  xi11,xi12,xi22,EtaEta = TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2)\n",
        "  out = 0.5*mu*s*EtaEta.sum() #doublelIntegral(0.5*mu*EtaEta,lim1,lim2) #loss\n",
        "  #out = loss(out)\n",
        "  if out < 1e-6:\n",
        "      break\n",
        "  history.append(out.item())\n",
        "  out.backward()\n",
        "  optimizer.step()\n",
        "  print('#iter',epoch,'loss',out)"
      ],
      "metadata": {
        "id": "CsBCY3g4gspY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce06f5e-b92f-4400-c166-24c8e3030c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 512])\n",
            "#iter 0 loss tensor(1513302.7500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 1 loss tensor(1428006.3750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 2 loss tensor(434927.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 3 loss tensor(216691.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 4 loss tensor(225005.6094, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 5 loss tensor(289591.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 6 loss tensor(305606.4375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 7 loss tensor(271963.6875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 8 loss tensor(227569.2344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 9 loss tensor(188486.5312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 10 loss tensor(168689.4844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 11 loss tensor(146080.9844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 12 loss tensor(116310.5859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 13 loss tensor(87795.5547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 14 loss tensor(72029.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 15 loss tensor(68112.2812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 16 loss tensor(76469.6016, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 17 loss tensor(86145.9375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 18 loss tensor(92110.9688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 19 loss tensor(91128.4297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 20 loss tensor(85512.0312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 21 loss tensor(73933.9531, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 22 loss tensor(60642.0469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 23 loss tensor(52307.9414, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 24 loss tensor(50138.0039, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 25 loss tensor(57601.8516, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 26 loss tensor(72385.6719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 27 loss tensor(114843.0859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 28 loss tensor(94928.9375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 29 loss tensor(50256.6602, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 30 loss tensor(44983.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 31 loss tensor(47029.8516, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 32 loss tensor(52233.4414, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 33 loss tensor(58067.0078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 34 loss tensor(68627.5234, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 35 loss tensor(80763.8516, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 36 loss tensor(89565.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 37 loss tensor(84477.8047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 38 loss tensor(66576.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 39 loss tensor(51439.9336, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 40 loss tensor(44116.3516, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 41 loss tensor(38426.3164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 42 loss tensor(33982.0586, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 43 loss tensor(29904.5273, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 44 loss tensor(26247.0176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 45 loss tensor(24719.8242, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 46 loss tensor(24261.8965, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 47 loss tensor(24007.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 48 loss tensor(23758.9082, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 49 loss tensor(23678.6191, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 50 loss tensor(23646.6523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 51 loss tensor(23577.6680, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 52 loss tensor(23398.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 53 loss tensor(23243.0781, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 54 loss tensor(23095.5586, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 55 loss tensor(22878.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 56 loss tensor(22560.2324, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 57 loss tensor(22161.6504, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 58 loss tensor(21587.6582, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 59 loss tensor(20800.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 60 loss tensor(20145.2656, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 61 loss tensor(19566.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 62 loss tensor(19052.7051, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 63 loss tensor(18554.0977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 64 loss tensor(18077.4219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 65 loss tensor(17596.2129, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 66 loss tensor(17106.0430, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 67 loss tensor(16627.6953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 68 loss tensor(16183.9453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 69 loss tensor(15778.6260, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 70 loss tensor(15430.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 71 loss tensor(15074.4033, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 72 loss tensor(14733.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 73 loss tensor(14402.4854, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 74 loss tensor(14073.7891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 75 loss tensor(13767.9941, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 76 loss tensor(13464.9785, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 77 loss tensor(13183.2012, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 78 loss tensor(12915.1064, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 79 loss tensor(12648.5566, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 80 loss tensor(12395.8682, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 81 loss tensor(12157.9238, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 82 loss tensor(11928.0098, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 83 loss tensor(11711.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 84 loss tensor(11510.3740, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 85 loss tensor(11302.4561, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 86 loss tensor(11092.6523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 87 loss tensor(10887.9521, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 88 loss tensor(10691.8193, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 89 loss tensor(10528.6943, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 90 loss tensor(10376.5010, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 91 loss tensor(10232.5850, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 92 loss tensor(10104.4893, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 93 loss tensor(9991.3340, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 94 loss tensor(9889.0215, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 95 loss tensor(9799.7061, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 96 loss tensor(9713.9951, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 97 loss tensor(9632.6240, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 98 loss tensor(9552.2812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 99 loss tensor(9481.2021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 100 loss tensor(9415.3887, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 101 loss tensor(9356.2891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 102 loss tensor(9303.9492, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 103 loss tensor(9260.7578, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 104 loss tensor(9227.2197, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 105 loss tensor(9202.0811, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 106 loss tensor(9158.8467, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 107 loss tensor(9110.6445, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 108 loss tensor(9059.8057, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 109 loss tensor(9016.6689, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 110 loss tensor(8986.3623, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 111 loss tensor(8950.6943, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 112 loss tensor(8902.8994, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 113 loss tensor(8868.6357, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 114 loss tensor(8873.3721, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 115 loss tensor(8900.0410, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 116 loss tensor(8919.9258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 117 loss tensor(8923.4453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 118 loss tensor(8944.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 119 loss tensor(8945.7900, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 120 loss tensor(8939.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 121 loss tensor(8928.0879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 122 loss tensor(8916.1768, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 123 loss tensor(8890.0439, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 124 loss tensor(8850.9893, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 125 loss tensor(8803.6270, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 126 loss tensor(8749.4004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 127 loss tensor(8681.8574, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 128 loss tensor(8602.5527, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 129 loss tensor(8527.9648, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 130 loss tensor(8461.8467, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 131 loss tensor(8404.0400, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 132 loss tensor(8359.6807, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 133 loss tensor(8322.7256, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 134 loss tensor(8322.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 135 loss tensor(8329.4443, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 136 loss tensor(8333.4912, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 137 loss tensor(8329.5283, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 138 loss tensor(8327.9004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 139 loss tensor(8324.3682, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 140 loss tensor(8318.6230, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 141 loss tensor(8336.2256, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 142 loss tensor(8386.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 143 loss tensor(8449.4473, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 144 loss tensor(8536.1494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 145 loss tensor(8632.3135, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 146 loss tensor(8720.4824, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 147 loss tensor(8779.3066, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 148 loss tensor(8826.5791, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 149 loss tensor(8881.0986, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 150 loss tensor(8931.5605, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 151 loss tensor(8967.6963, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 152 loss tensor(8983.7207, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 153 loss tensor(8968.4023, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 154 loss tensor(8934.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 155 loss tensor(8863.6650, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 156 loss tensor(8747.2852, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 157 loss tensor(8594.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 158 loss tensor(8381.2188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 159 loss tensor(8133.8867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 160 loss tensor(7866.0356, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 161 loss tensor(7574.1289, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 162 loss tensor(7261.1021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 163 loss tensor(6938.6602, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 164 loss tensor(6625.6147, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 165 loss tensor(6326.3369, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 166 loss tensor(6040.1865, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 167 loss tensor(5775.6528, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 168 loss tensor(5520.3589, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 169 loss tensor(5288.0864, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 170 loss tensor(5115.3916, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 171 loss tensor(5006.8179, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 172 loss tensor(4948.1567, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 173 loss tensor(4924.7939, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 174 loss tensor(4950.7036, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 175 loss tensor(5024.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 176 loss tensor(5146.0425, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 177 loss tensor(5315.2886, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 178 loss tensor(5524.1240, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 179 loss tensor(5761.9185, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 180 loss tensor(6020.1323, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 181 loss tensor(6299.3291, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 182 loss tensor(6598.3433, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 183 loss tensor(6915.5249, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 184 loss tensor(7246.6538, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 185 loss tensor(7575.7310, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 186 loss tensor(7897.6338, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 187 loss tensor(8205.0371, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 188 loss tensor(8494.7529, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 189 loss tensor(8774.7256, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 190 loss tensor(9004.1543, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 191 loss tensor(9260.3818, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 192 loss tensor(9463.2988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 193 loss tensor(9681.4551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 194 loss tensor(9864.1240, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 195 loss tensor(9983.6367, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 196 loss tensor(10056.4414, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 197 loss tensor(10065.8320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 198 loss tensor(10034.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 199 loss tensor(9943.2021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 200 loss tensor(9787.0020, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 201 loss tensor(9578.1816, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 202 loss tensor(9314.0430, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 203 loss tensor(9055.0605, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 204 loss tensor(8777.1973, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 205 loss tensor(8530.0732, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 206 loss tensor(8284.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 207 loss tensor(8050.1558, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 208 loss tensor(7785.1606, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 209 loss tensor(7554.5459, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 210 loss tensor(7398.2559, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 211 loss tensor(7163.2271, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 212 loss tensor(6971.0986, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 213 loss tensor(6842.5039, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 214 loss tensor(6670.9126, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 215 loss tensor(6419.2534, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 216 loss tensor(6212.1797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 217 loss tensor(5980.0659, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 218 loss tensor(5761.5278, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 219 loss tensor(5609.2495, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 220 loss tensor(5540.3525, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 221 loss tensor(5458.7583, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 222 loss tensor(5397.3784, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 223 loss tensor(5421.9839, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 224 loss tensor(5446.9922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 225 loss tensor(5480.7700, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 226 loss tensor(5520.2002, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 227 loss tensor(5565.9458, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 228 loss tensor(5594.8779, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 229 loss tensor(5626.1997, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 230 loss tensor(5681.7559, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 231 loss tensor(5743.2446, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 232 loss tensor(5812.8589, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 233 loss tensor(5885.3813, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 234 loss tensor(5952.0024, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 235 loss tensor(6017.2393, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 236 loss tensor(6080.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 237 loss tensor(6151.6943, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 238 loss tensor(6228.5537, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 239 loss tensor(6316.1606, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 240 loss tensor(6413.2769, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 241 loss tensor(6508.2998, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 242 loss tensor(6602.5596, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 243 loss tensor(6685.9673, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 244 loss tensor(6774.1934, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 245 loss tensor(6869.7539, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 246 loss tensor(6957.4390, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 247 loss tensor(7031.3696, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 248 loss tensor(7094.2314, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 249 loss tensor(7166.1396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 250 loss tensor(7245.4839, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 251 loss tensor(7330.2812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 252 loss tensor(7420.3325, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 253 loss tensor(7518.4253, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 254 loss tensor(7622.1421, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 255 loss tensor(7727.9102, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 256 loss tensor(7834.1055, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 257 loss tensor(7939.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 258 loss tensor(8042.3672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 259 loss tensor(8136.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 260 loss tensor(8225.9053, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 261 loss tensor(8307.3066, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 262 loss tensor(8381.9648, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 263 loss tensor(8446.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 264 loss tensor(8506.3594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 265 loss tensor(8562.0869, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 266 loss tensor(8616.7773, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 267 loss tensor(8669.6934, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 268 loss tensor(8722.7666, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 269 loss tensor(8777.2412, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 270 loss tensor(8830.9150, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 271 loss tensor(8871.8623, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 272 loss tensor(8909.5508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 273 loss tensor(8934.9844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 274 loss tensor(8934.6953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 275 loss tensor(8930.7988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 276 loss tensor(8916.7041, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 277 loss tensor(8901.6201, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 278 loss tensor(8883.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 279 loss tensor(8859.8789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 280 loss tensor(8823.7607, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 281 loss tensor(8785.6885, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 282 loss tensor(8758.8877, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 283 loss tensor(8740.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 284 loss tensor(8716.6709, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 285 loss tensor(8684.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 286 loss tensor(8627.0693, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 287 loss tensor(8563.7871, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 288 loss tensor(8498.0039, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 289 loss tensor(8449.8789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 290 loss tensor(8418.0879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 291 loss tensor(8401.1377, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 292 loss tensor(8374.2783, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 293 loss tensor(8359.3086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 294 loss tensor(8358.9307, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 295 loss tensor(8363.5762, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 296 loss tensor(8354.7617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 297 loss tensor(8349.3252, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 298 loss tensor(8359.3662, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 299 loss tensor(8360.8438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 300 loss tensor(8369.4424, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 301 loss tensor(8345.3096, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 302 loss tensor(8280.8926, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 303 loss tensor(8207.7402, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 304 loss tensor(8114.6519, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 305 loss tensor(8011.7666, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 306 loss tensor(7939.6509, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 307 loss tensor(7890.3359, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 308 loss tensor(7835.6309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 309 loss tensor(7758.9424, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 310 loss tensor(7663.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 311 loss tensor(7559.3560, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 312 loss tensor(7458.5913, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 313 loss tensor(7353.5786, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 314 loss tensor(7254.3877, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 315 loss tensor(7165.2153, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 316 loss tensor(7078.5654, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 317 loss tensor(6994.5796, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 318 loss tensor(6899.0425, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 319 loss tensor(6806.0161, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 320 loss tensor(6713.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 321 loss tensor(6624.8560, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 322 loss tensor(6542.6968, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 323 loss tensor(6468.7588, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 324 loss tensor(6393.1021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 325 loss tensor(6314.7139, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 326 loss tensor(6243.1367, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 327 loss tensor(6179.8311, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 328 loss tensor(6139.1465, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 329 loss tensor(6095.3140, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 330 loss tensor(6042.6245, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 331 loss tensor(5996.3271, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 332 loss tensor(5963.6743, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 333 loss tensor(5989.2793, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 334 loss tensor(6031.5879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 335 loss tensor(6085.5308, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 336 loss tensor(6136.8960, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 337 loss tensor(6212.7920, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 338 loss tensor(6312.3369, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 339 loss tensor(6477.7812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 340 loss tensor(6615.5972, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 341 loss tensor(6710.0864, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 342 loss tensor(6810.2554, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 343 loss tensor(6893.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 344 loss tensor(6923.3120, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 345 loss tensor(6932.9375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 346 loss tensor(6921.9312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 347 loss tensor(6909.1685, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 348 loss tensor(6900.3110, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 349 loss tensor(6905.2969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 350 loss tensor(6928.8867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 351 loss tensor(6967.5923, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 352 loss tensor(7013.2271, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 353 loss tensor(7097.1284, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 354 loss tensor(7172.1353, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 355 loss tensor(7242.0903, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 356 loss tensor(7293.7002, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 357 loss tensor(7324.8828, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 358 loss tensor(7298.0737, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 359 loss tensor(7268.6934, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 360 loss tensor(7231.2632, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 361 loss tensor(7188.0327, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 362 loss tensor(7130.2144, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 363 loss tensor(7042.5654, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 364 loss tensor(6976.4141, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 365 loss tensor(6940.5620, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 366 loss tensor(6829.0117, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 367 loss tensor(6764.4419, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 368 loss tensor(6835.2822, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 369 loss tensor(6826.4160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 370 loss tensor(6879.3936, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 371 loss tensor(6971.5889, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 372 loss tensor(7089.1855, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 373 loss tensor(7211.4038, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 374 loss tensor(7211.6396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 375 loss tensor(7228.7866, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 376 loss tensor(7246.5513, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 377 loss tensor(7267.5098, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 378 loss tensor(7303.3091, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 379 loss tensor(7329.2622, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 380 loss tensor(7346.2959, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 381 loss tensor(7347.9497, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 382 loss tensor(7338.2124, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 383 loss tensor(7325.3271, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 384 loss tensor(7315.5576, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 385 loss tensor(7302.9014, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 386 loss tensor(7284.0015, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 387 loss tensor(7255.6797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 388 loss tensor(7215.1133, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 389 loss tensor(7159.3496, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 390 loss tensor(7090.0127, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 391 loss tensor(7010.5352, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 392 loss tensor(6917.4282, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 393 loss tensor(6821.6030, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 394 loss tensor(6729.7876, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 395 loss tensor(6639.4844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 396 loss tensor(6548.7285, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 397 loss tensor(6448.4395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 398 loss tensor(6337.9067, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 399 loss tensor(6219.5127, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 400 loss tensor(6091.8003, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 401 loss tensor(5959.7026, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 402 loss tensor(5829.0278, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 403 loss tensor(5705.0576, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 404 loss tensor(5580.7681, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 405 loss tensor(5459.3296, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 406 loss tensor(5335.3667, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 407 loss tensor(5198.4458, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 408 loss tensor(5063.0010, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 409 loss tensor(4918.3350, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 410 loss tensor(4776.4565, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 411 loss tensor(4648.4321, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 412 loss tensor(4530.3994, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 413 loss tensor(4422.1245, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 414 loss tensor(4306.2666, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 415 loss tensor(4196.5571, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 416 loss tensor(4100.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 417 loss tensor(4010.9292, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 418 loss tensor(3940.1733, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 419 loss tensor(3892.7463, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 420 loss tensor(3856.5315, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 421 loss tensor(3828.1677, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 422 loss tensor(3814.1497, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 423 loss tensor(3797.6179, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 424 loss tensor(3783.1313, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 425 loss tensor(3777.0151, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 426 loss tensor(3780.7434, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 427 loss tensor(3796.0728, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 428 loss tensor(3823.7986, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 429 loss tensor(3867.1897, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 430 loss tensor(3907.7014, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 431 loss tensor(3931.7585, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 432 loss tensor(3975.3923, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 433 loss tensor(4047.5171, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 434 loss tensor(4140.6313, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 435 loss tensor(4255.7622, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 436 loss tensor(4392.1133, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 437 loss tensor(4524.5952, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 438 loss tensor(4639.4883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 439 loss tensor(4742.0942, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 440 loss tensor(4857.1787, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 441 loss tensor(4971.5103, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 442 loss tensor(5077.8789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 443 loss tensor(5183.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 444 loss tensor(5294.0894, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 445 loss tensor(5408.6743, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 446 loss tensor(5515.8779, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 447 loss tensor(5620.1069, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 448 loss tensor(5717.1626, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 449 loss tensor(5818.7754, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 450 loss tensor(5922.6216, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 451 loss tensor(6020.5923, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 452 loss tensor(6109.7070, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 453 loss tensor(6190.8433, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 454 loss tensor(6264.3687, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 455 loss tensor(6331.5293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 456 loss tensor(6387.1001, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 457 loss tensor(6430.8618, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 458 loss tensor(6468.3027, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 459 loss tensor(6500.5518, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 460 loss tensor(6518.4106, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 461 loss tensor(6530.6504, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 462 loss tensor(6538.9600, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 463 loss tensor(6539.3408, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 464 loss tensor(6536.1978, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 465 loss tensor(6522.5757, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 466 loss tensor(6504.4502, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 467 loss tensor(6478.8340, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 468 loss tensor(6441.6997, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 469 loss tensor(6397.9321, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 470 loss tensor(6347.8857, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 471 loss tensor(6295.3433, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 472 loss tensor(6243.7451, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 473 loss tensor(6195.5801, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 474 loss tensor(6145.0127, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 475 loss tensor(6085.5244, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 476 loss tensor(6021.8125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 477 loss tensor(5955.2515, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 478 loss tensor(5881.5107, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 479 loss tensor(5802.6396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 480 loss tensor(5722.9580, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 481 loss tensor(5645.0303, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 482 loss tensor(5569.1362, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 483 loss tensor(5492.9561, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 484 loss tensor(5419.1240, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 485 loss tensor(5346.0156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 486 loss tensor(5271.8164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 487 loss tensor(5203.3086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 488 loss tensor(5138.0537, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 489 loss tensor(5077.9878, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 490 loss tensor(5024.6089, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 491 loss tensor(4976.9717, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 492 loss tensor(4938.1890, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 493 loss tensor(4905.7256, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 494 loss tensor(4882.8076, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 495 loss tensor(4862.9272, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 496 loss tensor(4841.9961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 497 loss tensor(4823.9292, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 498 loss tensor(4805.6392, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 499 loss tensor(4791.0161, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 500 loss tensor(4779.2827, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 501 loss tensor(4773.6543, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 502 loss tensor(4773.8989, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 503 loss tensor(4778.0371, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 504 loss tensor(4783.6626, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 505 loss tensor(4793.7930, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 506 loss tensor(4814.0137, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 507 loss tensor(4843.4536, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 508 loss tensor(4873.4434, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 509 loss tensor(4904.3569, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 510 loss tensor(4942.2759, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 511 loss tensor(4986.3306, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 512 loss tensor(5034.3994, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 513 loss tensor(5079.1821, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 514 loss tensor(5120.3232, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 515 loss tensor(5152.0283, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 516 loss tensor(5180.1831, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 517 loss tensor(5206.6660, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 518 loss tensor(5234.3120, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 519 loss tensor(5264.5986, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 520 loss tensor(5300.4106, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 521 loss tensor(5340.2012, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 522 loss tensor(5395.7627, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 523 loss tensor(5465.3320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 524 loss tensor(5530.7158, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 525 loss tensor(5588.9116, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 526 loss tensor(5641.3003, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 527 loss tensor(5686.1060, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 528 loss tensor(5725.0771, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 529 loss tensor(5772.5693, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 530 loss tensor(5827.5293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 531 loss tensor(5854.1909, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 532 loss tensor(5910.5415, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 533 loss tensor(5977.9668, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 534 loss tensor(6038.5518, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 535 loss tensor(6110.9414, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 536 loss tensor(6157.5396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 537 loss tensor(6228.0288, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 538 loss tensor(6327.6616, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 539 loss tensor(6428.6353, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 540 loss tensor(6509.5034, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 541 loss tensor(6564.4795, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 542 loss tensor(6612.2437, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 543 loss tensor(6663.2656, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 544 loss tensor(6733.2432, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 545 loss tensor(6814.6860, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 546 loss tensor(6883.0107, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 547 loss tensor(6944.5767, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 548 loss tensor(6995.2622, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 549 loss tensor(7042.8511, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 550 loss tensor(7089.7363, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 551 loss tensor(7133.2075, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 552 loss tensor(7178.2871, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 553 loss tensor(7223.6064, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 554 loss tensor(7262.6357, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 555 loss tensor(7292.8921, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 556 loss tensor(7317.8677, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 557 loss tensor(7337.4434, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 558 loss tensor(7352.7222, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 559 loss tensor(7361.8286, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 560 loss tensor(7367.0571, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 561 loss tensor(7365.7466, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 562 loss tensor(7367.0796, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 563 loss tensor(7362.0508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 564 loss tensor(7355.0366, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 565 loss tensor(7333.5981, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 566 loss tensor(7308.9814, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 567 loss tensor(7286.2080, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 568 loss tensor(7251.5034, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 569 loss tensor(7220.7095, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 570 loss tensor(7187.4199, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 571 loss tensor(7144.4736, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 572 loss tensor(7095.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 573 loss tensor(7039.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 574 loss tensor(6987.7568, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 575 loss tensor(6967.0488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 576 loss tensor(6990.7852, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 577 loss tensor(7025.9287, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 578 loss tensor(7006.9170, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 579 loss tensor(6987.6118, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 580 loss tensor(6964.8193, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 581 loss tensor(6918.8364, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 582 loss tensor(6895.0444, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 583 loss tensor(6918.8467, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 584 loss tensor(6986.5488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 585 loss tensor(7081.6519, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 586 loss tensor(7145.6953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 587 loss tensor(7155.3301, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 588 loss tensor(7195.6245, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 589 loss tensor(7296.7642, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 590 loss tensor(7437.7788, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 591 loss tensor(7649.0884, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 592 loss tensor(7847.2427, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 593 loss tensor(8064.1919, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 594 loss tensor(8321.8066, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 595 loss tensor(8585.8311, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 596 loss tensor(8781.3037, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 597 loss tensor(8936.5479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 598 loss tensor(9053.5703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 599 loss tensor(9114.8496, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 600 loss tensor(9102.6035, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 601 loss tensor(9010.2705, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 602 loss tensor(8838.6846, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 603 loss tensor(8594.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 604 loss tensor(8303.4229, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 605 loss tensor(7984.7285, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 606 loss tensor(7598.8975, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 607 loss tensor(7155.6685, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 608 loss tensor(6695.4116, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 609 loss tensor(6379.3550, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 610 loss tensor(6141.8447, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 611 loss tensor(6126.0659, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 612 loss tensor(5844.6738, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 613 loss tensor(5585.1968, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 614 loss tensor(5328.9961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 615 loss tensor(5266.6968, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 616 loss tensor(5340.4692, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 617 loss tensor(5308.2856, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 618 loss tensor(5165.6763, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 619 loss tensor(5052.0298, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 620 loss tensor(5050.4160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 621 loss tensor(5261.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 622 loss tensor(5313.0620, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 623 loss tensor(5190.1177, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 624 loss tensor(5042.0132, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 625 loss tensor(5032.3701, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 626 loss tensor(5215.4028, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 627 loss tensor(5311.7593, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 628 loss tensor(5285.4229, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 629 loss tensor(5206.2329, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 630 loss tensor(5184.1616, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 631 loss tensor(5160.7480, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 632 loss tensor(5210.9297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 633 loss tensor(5272.0498, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 634 loss tensor(5306.3257, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 635 loss tensor(5287.8818, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 636 loss tensor(5252.8936, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 637 loss tensor(5249.0654, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 638 loss tensor(5166.9346, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 639 loss tensor(5151.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 640 loss tensor(5062.6455, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 641 loss tensor(4972.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 642 loss tensor(4940.3926, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 643 loss tensor(4944.4976, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 644 loss tensor(5014.9482, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 645 loss tensor(5050.6919, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 646 loss tensor(5006.5635, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 647 loss tensor(4990.6582, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 648 loss tensor(4998.2007, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 649 loss tensor(4959.1396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 650 loss tensor(4901.9985, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 651 loss tensor(4828.8569, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 652 loss tensor(4770.3711, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 653 loss tensor(4760.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 654 loss tensor(4742.7163, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 655 loss tensor(4725.4644, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 656 loss tensor(4719.5576, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 657 loss tensor(4734.5732, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 658 loss tensor(4792.2446, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 659 loss tensor(4791.1006, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 660 loss tensor(4750.8594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 661 loss tensor(4725.0161, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 662 loss tensor(4748.5879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 663 loss tensor(4749.5317, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 664 loss tensor(4748.0312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 665 loss tensor(4735.9683, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 666 loss tensor(4759.3867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 667 loss tensor(4805.3594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 668 loss tensor(4855.5962, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 669 loss tensor(4897.8994, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 670 loss tensor(4915.1372, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 671 loss tensor(4934.1206, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 672 loss tensor(4948.8223, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 673 loss tensor(4984.3262, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 674 loss tensor(5045.7285, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 675 loss tensor(5122.7358, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 676 loss tensor(5202.4404, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 677 loss tensor(5255.5518, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 678 loss tensor(5298.2896, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 679 loss tensor(5353.7090, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 680 loss tensor(5427.0425, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 681 loss tensor(5500.8765, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 682 loss tensor(5571.4888, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 683 loss tensor(5644.7617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 684 loss tensor(5715.8506, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 685 loss tensor(5792.8037, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 686 loss tensor(5875.2935, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 687 loss tensor(5956.5303, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[5:])"
      ],
      "metadata": {
        "id": "jHYMzoLTbFyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation"
      ],
      "metadata": {
        "id": "twoS2qPPcSPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi[0,0,:,:].shape"
      ],
      "metadata": {
        "id": "cmYDRsmlc0-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psicheck = torch.tensor(psi[0,0,:,:],requires_grad=False)\n",
        "psiMasked = (psicheck*wallsMask) + (inverseUpperWallMask*Q)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psiMasked)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "id": "Tx_qNIxjcZoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(psiMasked[:,250])\n",
        "plt.title('psi function slice')"
      ],
      "metadata": {
        "id": "r-cNSoA-vtz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psiMasked,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "id": "IcEzHkrgcVWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(v2[:,250])"
      ],
      "metadata": {
        "id": "tM5Nv56YeC9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Links\n",
        "\n",
        "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
        "\n",
        "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
      ],
      "metadata": {
        "id": "rpGo7xQz6cny"
      }
    }
  ]
}