{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Physics-based loss and machine learing approach in application to fluids flow modelling: 2D flow domains**\n",
        "\n",
        "The program recieves an image of the flow domain and the flow rate value, then calculate velocity distribution. The main idea is power loss minimization. The main unknown function is the stream function $\\psi = \\psi(x_1, x_2)$ that determines the velocity field $\\textbf{V} = [[v_1, v_2]]$, where $v_1 = \\frac{\\partial \\psi}{\\partial x_2}$, $v_2 = - \\frac{\\partial \\psi}{\\partial x_1}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "RJkKJ83igGYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "ozT2l1DxVSOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "s3KFs0M9r7EQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "jPSaJ-z614Tm"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "ydwhZV95sFoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "Go3JwW4hICsK"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "BT8OQ6AkVb6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional functions"
      ],
      "metadata": {
        "id": "Hw2AD3oWsfJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical derivative"
      ],
      "metadata": {
        "id": "2JAf1YAHtV15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mydiff(j,y,dx):\n",
        "  '''The function calculates the first order derivative in a specific direction \n",
        "     'dx' at a specific point 'j' for a given array 'y' \n",
        "     using parabolic approximation\n",
        "  '''\n",
        "  dydx = 0\n",
        "  n = len(y)\n",
        "  if j==0:\n",
        "    dydx=(-y[3]+4*y[2]-3*y[1])/(2*dx)\n",
        "  elif j==n-1:\n",
        "    dydx=(3*y[j]-4*y[j-1]+y[j-2])/(2*dx)\n",
        "  else:\n",
        "    dydx=(y[j+1]-y[j-1])/(2*dx);\n",
        "  return dydx"
      ],
      "metadata": {
        "id": "MSTF3qPgtbn8"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_diff(f, dx1, dx2):\n",
        "  '''function to find partial derivatives of a two variables function:\n",
        "  i - index along x1\n",
        "  j - index along x2\n",
        "  for internal points - central differences e.q. df_dx = (f_{i+1}-f_{i-1})/(2*dx)\n",
        "  for boundaries - left and right finite differences e.q. df_dx = (f_{i+1}-f_{i})/dx or df_dx = (f_{i}-f_{i-1})/dx\n",
        "  '''\n",
        "  n1, n2 = f.shape\n",
        "  df_dx1, df_dx2 = torch.zeros(n1,n2), torch.zeros(n1,n2)\n",
        "  # x1 derivative:\n",
        "  df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:])/(2*dx1)\n",
        "  df_dx1[0,:] = (f[1,:] - f[0,:])/dx1\n",
        "  df_dx1[n1-1,:] = (f[n1-1,:] - f[n1-2,:])/dx1\n",
        "  # x2 derivative:\n",
        "  df_dx2[:, 1:n2-1] = (f[:,2:] - f[:,:-2])/(2*dx2)\n",
        "  df_dx2[:, 0] = (f[:,1] - f[:,0])/dx2\n",
        "  df_dx2[:,n2-1] = (f[:,n2-1] - f[:,n2-2])/dx2\n",
        "  return df_dx1, df_dx2"
      ],
      "metadata": {
        "id": "5P2RND6cYEOK"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical integrals: single and double"
      ],
      "metadata": {
        "id": "1i1RAg4ozeGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singleIntegral(f,lowerLim,upperLim):\n",
        "  '''The function calculates the single integral using Simpson's formula. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the difference between the upper and lower limits.\n",
        "  '''  \n",
        "  sglInt = 0\n",
        "  n = len(f)\n",
        "  x = torch.linspace(0,1,n)\n",
        "  dxn = x[1]-x[0]\n",
        "\n",
        "  for i in range (1, (n-1), 2):\n",
        "    sglInt += (f[i-1] + 4*f[i]+f[i+1])*dxn/3\n",
        "  if (n % 2) == 0:\n",
        "    sglInt += (f[-1]+f[-2])*dxn/2\n",
        "\n",
        "  sglInt = sglInt*(upperLim-lowerLim)\n",
        "\n",
        "  return sglInt"
      ],
      "metadata": {
        "id": "MbSgsSbO0srV"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doublelIntegral(f,lim1,lim2):\n",
        "  '''The function calculates the double integral using Simpson's formula twice. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the differences between the upper and lower limits.\n",
        "  '''\n",
        "  dblInt = 0\n",
        "  n = f.shape\n",
        "  x1 = torch.linspace(0,1,n[0])\n",
        "  x2 = torch.linspace(0,1,n[1])\n",
        "  dx1n = x1[1]-x1[0]\n",
        "  dx2n = x2[1]-x2[0]\n",
        "\n",
        "  for i in range (1, (n[0]-1), 2):\n",
        "    for j in range (1, (n[1]-1), 2):\n",
        "      dblInt += (f[i-1][j-1] + f[i+1][j-1] + f[i-1][j+1] + f[i+1][j+1] + \n",
        "                   4*(f[i][j+1] + f[i][j-1] + f[i-1][j] + f[i+1][j]) + \n",
        "                   16*f[i][j])*dx1n*dx2n/9\n",
        "          \n",
        "  dblInt = dblInt*(lim1[1]-lim1[0])*(lim2[1]-lim2[0])\n",
        "\n",
        "  return (dblInt)"
      ],
      "metadata": {
        "id": "fxibGVL-zkCW"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check double integral "
      ],
      "metadata": {
        "id": "qyl0qTFMj-lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 101\n",
        "x = torch.linspace(0,1,ss)\n",
        "y = torch.linspace(0,1,ss)\n",
        "y = y.reshape(1,-1).t()\n",
        "z = (x*x) * (y*y)\n",
        "print(doublelIntegral(z,[0,1],[0,1]),'- calculated', 1/9, '- exact')"
      ],
      "metadata": {
        "id": "byisjmu7c8C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf41255-09cf-4e89-e245-7259bdbf6175"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1111) - calculated 0.1111111111111111 - exact\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color filter "
      ],
      "metadata": {
        "id": "lon3t_mIeGEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colorFilter(img, color):\n",
        "  white = (255,255,255,255)\n",
        "  black = (0,0,0,255)\n",
        "  width,heigth = img.size\n",
        "  for i in range(width):\n",
        "    for j in range(heigth):\n",
        "      if img.getpixel((i,j)) == color:\n",
        "        img.putpixel((i,j),black)\n",
        "      else:\n",
        "        #print(img.getpixel((i,j)))\n",
        "        img.putpixel((i,j),white)\n",
        "  return (img)"
      ],
      "metadata": {
        "id": "626DXTn0eKR-"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Major functions\n",
        "\n",
        "Distributions: the velocity components [[$v_1$, $v_2$]], the strain rate tensor components [[$\\xi_{ij}$]], $\\xi_{ij}=\\xi_{ji}$ . And the shear rate intensity Î—. "
      ],
      "metadata": {
        "id": "mH8zURs8A1Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def velocityDistr(psi,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = psi.shape\n",
        "  dpsidx1, dpsidx2 = num_diff(psi, dx1n, dx2n)\n",
        "  v1 = dpsidx2/lim2[1]\n",
        "  v2 = - dpsidx1/lim1[1]\n",
        "\n",
        "  return v1,v2"
      ],
      "metadata": {
        "id": "WMUIipgs5t3Q"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = v1.shape\n",
        "  dv1dx1, dv1dx2 = num_diff(v1, dx1n, dx2n)\n",
        "  dv2dx1, dv2dx2 = num_diff(v2, dx1n, dx2n)\n",
        "\n",
        "  xi11 = dv1dx1/lim1[1]\n",
        "  xi12 = 0.5*(dv1dx2/lim2[1] + dv2dx1/lim1[1])\n",
        "  xi22 = dv2dx2/lim2[1]\n",
        "  EtaEta = (2*(xi11*xi11 + 2*xi12*xi12 + xi22*xi22))\n",
        "\n",
        "  return xi11,xi12,xi22,EtaEta"
      ],
      "metadata": {
        "id": "716qlRJoNglx"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "nzMpruhsYD38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image of the flow domain"
      ],
      "metadata": {
        "id": "itN_H_kFke1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path"
      ],
      "metadata": {
        "id": "3NCXTaNK4V4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " path =  Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss')\n",
        " imgPath = path/'ToyDataset'\n",
        " imgList = imgPath.ls()\n",
        " imgPath.ls()"
      ],
      "metadata": {
        "id": "tDbZIropJMjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd6e020-f847-4bc2-841a-97513faa410b"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates and ball.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates with notch.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates.png')]"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometry\n",
        "The domain of size *'L x L'*  with flow channel is represented as an image of size *'imgSize x imgSize'*. S1 is the upper wall with black label [0 0 0]. S2 and S4 are outlet and inlet surfaces, respectivelly. S3 is the lower wall with blue label [0 0 255]. "
      ],
      "metadata": {
        "id": "ORhTWZZvVw7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = 0.1 # L x L flow domain\n",
        "imgSize = 512 # imgSize x imgSize pixels image\n",
        "imgNo = 2\n",
        "upperWallColor =  (0, 0, 0,255)\n",
        "lowerWallColor =  (0, 0, 255,255)\n",
        "#Normalized coordinates\n",
        "x1n = torch.linspace(0,1,imgSize)\n",
        "x2n = torch.linspace(0,1,imgSize)\n",
        "dx1n = x1n[1] - x1n[0]\n",
        "dx2n = x2n[1] - x2n[0]\n",
        "lim1 = [0, L]\n",
        "lim2 = [0, L]\n",
        "#Visualisation\n",
        "figSize = 3\n",
        "#Training\n",
        "noOfEpoch = 1000\n",
        "learnRate = 0.001"
      ],
      "metadata": {
        "id": "y8Q_jxpUYIEm"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "domainMask "
      ],
      "metadata": {
        "id": "1hKq9A5gtHzs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c4606a3d-6b2b-40f1-ee88-89f4607eaf31"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB+CAYAAADiI6WIAAABQ0lEQVR4nO3cwQ3AMAgAMVJl/5XpGHmcPQHSiSecmdkh53s9AG8IHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81N31rr7IxkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkedGeeyRTY+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aN+UssG9+2j5aIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=126x126 at 0x7FA9624A1C50>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create masks for the walls and resize image"
      ],
      "metadata": {
        "id": "45EnY5VmEcjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2n.dtype"
      ],
      "metadata": {
        "id": "SgL2YvbN3rmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed4807f-b7ce-4977-8d0e-1b050484fd19"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "upperWallMask = colorFilter(domainMask, upperWallColor)\n",
        "upperWallMask = upperWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#upperWallMask"
      ],
      "metadata": {
        "id": "lmyMgC4op_o_"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "lowerWallMask = colorFilter(domainMask, lowerWallColor)\n",
        "lowerWallMask = lowerWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#lowerWallMask"
      ],
      "metadata": {
        "id": "FF424vauuCi8"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kinematic properties\n",
        "The velocity is equal to zero on all the surfaces. The flow rate is known."
      ],
      "metadata": {
        "id": "XaVb_Ejsmynq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 1 #flow rate through the inlet (outlet) boundary, m^3/s\n",
        "psim = 0 # lower wall\n",
        "psip = Q # upper wall\n",
        "psi00 = torch.linspace(0,1,imgSize, dtype=torch.float32)*torch.ones(imgSize,imgSize)\n",
        "psi0 = torch.t(psi00)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0)"
      ],
      "metadata": {
        "id": "Gb4BFZNWnBsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "0036b705-64e8-445d-9a2a-c3dce7b727da"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9627b9f10>"
            ]
          },
          "metadata": {},
          "execution_count": 232
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psi00.dtype"
      ],
      "metadata": {
        "id": "H-xEZhto3cLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16180e3-7e5d-4186-b7e9-b22db3061d5b"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wallsMask = (tensor(upperWallMask)[:,:,1]*tensor(lowerWallMask)[:,:,1])\n",
        "inverseUpperWallMask = (tensor(upperWallMask)[:,:,1]/(-255)+1)\n",
        "psi0Masked = (psi0*wallsMask) + (inverseUpperWallMask*Q)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0Masked)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "id": "lyOiYXNSUVnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "01db208b-be0f-4d6c-ba24-d213923f02aa"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'psi function with mask')"
            ]
          },
          "metadata": {},
          "execution_count": 234
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Velocity distribution"
      ],
      "metadata": {
        "id": "B7LQzVv63_0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psi0Masked,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "id": "qbVbaBjT3aOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "114565be-a180-41b3-cd35-70550e5d1407"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'v2')"
            ]
          },
          "metadata": {},
          "execution_count": 235
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dynamic properties\n",
        "The fluid is Newtonian."
      ],
      "metadata": {
        "id": "hvAQmdvsnZQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 1e-3 # koefficient of dynamic viscosity (viscosity), Pa*s"
      ],
      "metadata": {
        "id": "t4YCVOBPneFt"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check exact solution\n",
        "Newtonian fluid flows between parallel plates "
      ],
      "metadata": {
        "id": "wOpHVjQdkxS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=L/5\n",
        "pressureDrop = Q*3*mu*L/(2*h*h*h)\n",
        "internalPower = pressureDrop*Q\n",
        "print('pressure drop',pressureDrop,'internal power',internalPower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpG0AV2LlF-W",
        "outputId": "764563a8-a9fc-4c1c-9393-b0f7fefa1bb9"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pressure drop 18.75 internal power 18.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "PhZutgNIyYhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create model\n",
        "Unet architecture [2] is used"
      ],
      "metadata": {
        "id": "FPeLHoR31p1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return torch.sigmoid(self.conv(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        \n",
        "model = UNet(in_channels=1, out_channels=1, init_features=32)"
      ],
      "metadata": {
        "id": "PID82zl-cxN4"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "2yb3P0n1c8df"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "PwikCXOPyPPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learnRate, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "oKBkisM7hASi"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input image"
      ],
      "metadata": {
        "id": "TyTAp5u0yroJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi0Masked.dtype"
      ],
      "metadata": {
        "id": "j6BFOOEv3OhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56acd9c8-814e-491b-b198-97a58c1ba421"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = torch.randn((1, 1, 512, 512))\n",
        "x = torch.ones((1, 1, imgSize, imgSize))*psi0Masked\n",
        "#fig = plt.figure(figsize=(3, 3))\n",
        "#plt.imshow(x[0,0,:,:])\n",
        "x.dtype, x.shape"
      ],
      "metadata": {
        "id": "xruHyQ-vdVhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab62ace-7c1b-4806-a0ed-f72b6621d0a7"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.Size([1, 1, 512, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model(x)"
      ],
      "metadata": {
        "id": "f1L8QG9ndbML"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = dx1n*dx2n*lim1[1]*lim2[1]\n",
        "s"
      ],
      "metadata": {
        "id": "osreN0VAdhZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e3d7dc-d7e2-4b51-de5a-7a64a14e75ce"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8296e-08)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "\n",
        "for epoch in range(noOfEpoch):\n",
        "  psi = model(x)\n",
        "  psiMasked = (psi[0,0,:,:]*wallsMask) + (inverseUpperWallMask*Q)\n",
        "  print(psi[0,0,:,:].shape)\n",
        "  v1,v2 = velocityDistr(psiMasked,dx1n,dx2n,lim1,lim2)\n",
        "  xi11,xi12,xi22,EtaEta = TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2)\n",
        "  out = 0.5*mu*s*EtaEta.sum() #doublelIntegral(0.5*mu*EtaEta,lim1,lim2) #loss\n",
        "  #out = loss(out)\n",
        "  if out < 1e-6:\n",
        "      break\n",
        "  history.append(out.item())\n",
        "  out.backward()\n",
        "  optimizer.step()\n",
        "  print('#iter',epoch,'loss',out)"
      ],
      "metadata": {
        "id": "CsBCY3g4gspY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "495a15ae-0695-4cb3-f336-b632dee98804"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 512])\n",
            "#iter 0 loss tensor(2890986.7500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 1 loss tensor(1975912.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 2 loss tensor(1612033., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 3 loss tensor(805153.8750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 4 loss tensor(585709.4375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 5 loss tensor(504592.3750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 6 loss tensor(490037.6875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 7 loss tensor(441961.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 8 loss tensor(381599.4375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 9 loss tensor(379059.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 10 loss tensor(458460.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 11 loss tensor(518667.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 12 loss tensor(469636.9688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 13 loss tensor(363836.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 14 loss tensor(329471.5000, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 15 loss tensor(341686.8750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 16 loss tensor(371497.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 17 loss tensor(382455.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 18 loss tensor(381368.8438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 19 loss tensor(370433.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 20 loss tensor(354106., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 21 loss tensor(332586.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 22 loss tensor(309005.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 23 loss tensor(285170.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 24 loss tensor(263830.5625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 25 loss tensor(246691.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 26 loss tensor(231741.2969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 27 loss tensor(220161.7031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 28 loss tensor(212318.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 29 loss tensor(204040.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 30 loss tensor(193682.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 31 loss tensor(183095.4062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 32 loss tensor(172734.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 33 loss tensor(162555.5781, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 34 loss tensor(153198.3906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 35 loss tensor(144923.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 36 loss tensor(138233.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 37 loss tensor(133752.3906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 38 loss tensor(131420.4844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 39 loss tensor(131589.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 40 loss tensor(132693.7031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 41 loss tensor(133705.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 42 loss tensor(134043.5000, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 43 loss tensor(133436.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 44 loss tensor(130606.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 45 loss tensor(125846.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 46 loss tensor(120405.8203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 47 loss tensor(115158.9453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 48 loss tensor(110748.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 49 loss tensor(107316.2188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 50 loss tensor(104932.9609, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 51 loss tensor(103888.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 52 loss tensor(103647.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 53 loss tensor(103630.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 54 loss tensor(103418.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 55 loss tensor(102123.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 56 loss tensor(101296.2891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 57 loss tensor(100147.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 58 loss tensor(98516.8125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 59 loss tensor(96475.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 60 loss tensor(94008.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 61 loss tensor(91233.2344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 62 loss tensor(88050.0312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 63 loss tensor(84538.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 64 loss tensor(81073.4141, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 65 loss tensor(77861.3281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 66 loss tensor(74996.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 67 loss tensor(72424.8984, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 68 loss tensor(70388.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 69 loss tensor(68808.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 70 loss tensor(67768.4688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 71 loss tensor(67366.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 72 loss tensor(67499.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 73 loss tensor(67955.1406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 74 loss tensor(68654.8828, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 75 loss tensor(69565.2422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 76 loss tensor(70265.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 77 loss tensor(70432.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 78 loss tensor(70393.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 79 loss tensor(70221.6172, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 80 loss tensor(69773.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 81 loss tensor(69051.7734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 82 loss tensor(68154.1641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 83 loss tensor(67175.1406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 84 loss tensor(66052.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 85 loss tensor(64817.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 86 loss tensor(63533.4453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 87 loss tensor(62150.2070, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 88 loss tensor(60761.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 89 loss tensor(59313.6953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 90 loss tensor(57825.1211, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 91 loss tensor(56185.0352, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 92 loss tensor(54567.7383, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 93 loss tensor(53270.3398, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 94 loss tensor(52236.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 95 loss tensor(51612.8359, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 96 loss tensor(51184.5508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 97 loss tensor(51047.3320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 98 loss tensor(51205.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 99 loss tensor(51491.9805, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 100 loss tensor(51356.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 101 loss tensor(51037.1523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 102 loss tensor(50465.5898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 103 loss tensor(49880.2617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 104 loss tensor(49455.1641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 105 loss tensor(49178.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 106 loss tensor(48824.7812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 107 loss tensor(48604.4258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 108 loss tensor(48553.3164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 109 loss tensor(48505.0977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 110 loss tensor(48361.0117, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 111 loss tensor(48210.9688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 112 loss tensor(48215.4570, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 113 loss tensor(48100.4062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 114 loss tensor(47885.8359, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 115 loss tensor(47592.2148, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 116 loss tensor(47445.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 117 loss tensor(47018.7891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 118 loss tensor(46532.8086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 119 loss tensor(46088.5117, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 120 loss tensor(45439.0742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 121 loss tensor(44531.9180, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 122 loss tensor(43576.1523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 123 loss tensor(42537.7422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 124 loss tensor(41635.1953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 125 loss tensor(40633.8594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 126 loss tensor(39352.2461, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 127 loss tensor(38262.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 128 loss tensor(37029.8555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 129 loss tensor(35900.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 130 loss tensor(34864.2891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 131 loss tensor(33965.6289, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 132 loss tensor(33192.5742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 133 loss tensor(32616.4883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 134 loss tensor(32253.5957, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 135 loss tensor(32188.9492, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 136 loss tensor(32248.3477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 137 loss tensor(32638.5020, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 138 loss tensor(33320.9766, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 139 loss tensor(34240.7617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 140 loss tensor(35294.6094, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 141 loss tensor(36576.4180, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 142 loss tensor(37960.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 143 loss tensor(39437.5625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 144 loss tensor(40932.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 145 loss tensor(42315.8867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 146 loss tensor(43642.8086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 147 loss tensor(44762.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 148 loss tensor(45436.9102, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 149 loss tensor(45584.2812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 150 loss tensor(45179., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 151 loss tensor(44317.5586, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 152 loss tensor(42897.0508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 153 loss tensor(41065.0039, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 154 loss tensor(38881.0781, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 155 loss tensor(36388.4219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 156 loss tensor(33798.6758, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 157 loss tensor(31164.4004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 158 loss tensor(28634.3652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 159 loss tensor(26409.8457, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 160 loss tensor(24626.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 161 loss tensor(23431.5977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 162 loss tensor(22957.0215, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 163 loss tensor(23259.4551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 164 loss tensor(24379.5020, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 165 loss tensor(26336.8027, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 166 loss tensor(29065.1992, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 167 loss tensor(32485.7363, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 168 loss tensor(36498.3672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 169 loss tensor(40938.8398, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 170 loss tensor(45656.9453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 171 loss tensor(50465.4297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 172 loss tensor(55155.9961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 173 loss tensor(59517.0859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 174 loss tensor(63383.3633, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 175 loss tensor(66730.3203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 176 loss tensor(69281.3672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 177 loss tensor(70857.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 178 loss tensor(71516.2969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 179 loss tensor(71257.4844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 180 loss tensor(70318.6641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 181 loss tensor(68538.8203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 182 loss tensor(65934.4453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 183 loss tensor(62606.5742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 184 loss tensor(58420.1328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 185 loss tensor(53681.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 186 loss tensor(49126.5820, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 187 loss tensor(44615.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 188 loss tensor(40415.7305, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 189 loss tensor(36789.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 190 loss tensor(33783.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 191 loss tensor(31159.2988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 192 loss tensor(28769.1094, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 193 loss tensor(26613.9980, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 194 loss tensor(25060.2070, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 195 loss tensor(23807.8184, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 196 loss tensor(22815.7715, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 197 loss tensor(22015.8145, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 198 loss tensor(21369.0977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 199 loss tensor(20869.9883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 200 loss tensor(20490.9355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 201 loss tensor(20229.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 202 loss tensor(20040.0078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 203 loss tensor(19885.6719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 204 loss tensor(19764.8691, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 205 loss tensor(19676.1348, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 206 loss tensor(19614.3613, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 207 loss tensor(19577.1387, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 208 loss tensor(19553.8594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 209 loss tensor(19537.3477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 210 loss tensor(19519.9238, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 211 loss tensor(19499.4160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 212 loss tensor(19485.5996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 213 loss tensor(19478.3867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 214 loss tensor(19470.7734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 215 loss tensor(19461.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 216 loss tensor(19442.0176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 217 loss tensor(19436.5410, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 218 loss tensor(19458.0469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 219 loss tensor(19486.2676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 220 loss tensor(19522.4961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 221 loss tensor(19560.9004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 222 loss tensor(19595.6367, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 223 loss tensor(19634.1230, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 224 loss tensor(19685.3457, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 225 loss tensor(19739.0762, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 226 loss tensor(19784.7266, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 227 loss tensor(19825.4785, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 228 loss tensor(19858.5898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 229 loss tensor(19883.5547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 230 loss tensor(19892.1797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 231 loss tensor(19907.7734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 232 loss tensor(19920.1465, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 233 loss tensor(19927.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 234 loss tensor(19935.8340, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 235 loss tensor(19964.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 236 loss tensor(19986.0156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 237 loss tensor(20006.5879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 238 loss tensor(20029.6797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 239 loss tensor(20037.4727, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 240 loss tensor(20018.7578, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 241 loss tensor(20009.5664, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 242 loss tensor(20001.1406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 243 loss tensor(19985.3867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 244 loss tensor(19960., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 245 loss tensor(19900.8789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 246 loss tensor(19829.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 247 loss tensor(19758.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 248 loss tensor(19697.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 249 loss tensor(19668.3164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 250 loss tensor(19662.4746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 251 loss tensor(19710.6133, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 252 loss tensor(19788.4805, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 253 loss tensor(19902.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 254 loss tensor(20007.1328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 255 loss tensor(20115.2031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 256 loss tensor(20236.7461, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 257 loss tensor(20373.2988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 258 loss tensor(20557.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 259 loss tensor(20772.6641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 260 loss tensor(20971.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 261 loss tensor(21154.7773, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 262 loss tensor(21331.7207, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 263 loss tensor(21504.1973, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 264 loss tensor(21657.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 265 loss tensor(21786.9766, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 266 loss tensor(21892.3613, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 267 loss tensor(21966.4727, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 268 loss tensor(22010.5430, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 269 loss tensor(22031.4336, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 270 loss tensor(22026.4922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 271 loss tensor(21989.8477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 272 loss tensor(21921.2949, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 273 loss tensor(21819.6426, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 274 loss tensor(21684.7402, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 275 loss tensor(21527.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 276 loss tensor(21329.6309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 277 loss tensor(21104.0488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 278 loss tensor(20857.1797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 279 loss tensor(20616.8164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 280 loss tensor(20400.6895, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 281 loss tensor(20218.0117, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 282 loss tensor(20034.3828, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 283 loss tensor(19792.5430, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 284 loss tensor(19463.9512, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 285 loss tensor(19124.8457, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 286 loss tensor(18789.1543, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 287 loss tensor(18492.3789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 288 loss tensor(18301.2227, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 289 loss tensor(18180.4277, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 290 loss tensor(18155.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 291 loss tensor(18185.8652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 292 loss tensor(18206.4121, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 293 loss tensor(18230.9258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 294 loss tensor(18359.9668, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 295 loss tensor(18584.2031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 296 loss tensor(18947.6680, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 297 loss tensor(19360.7227, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 298 loss tensor(19736.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 299 loss tensor(19915.3281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 300 loss tensor(19915.5273, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 301 loss tensor(19796.6113, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 302 loss tensor(19567.3652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 303 loss tensor(19360.4609, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 304 loss tensor(19174.7480, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 305 loss tensor(18983.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 306 loss tensor(18748.6309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 307 loss tensor(18503.1777, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 308 loss tensor(18290.0977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 309 loss tensor(18072.1465, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 310 loss tensor(17857.3633, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 311 loss tensor(17653.0527, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 312 loss tensor(17500.9004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 313 loss tensor(17372.9297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 314 loss tensor(17200.7832, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 315 loss tensor(16967.4141, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 316 loss tensor(16702.6191, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 317 loss tensor(16389.7676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 318 loss tensor(16066.9189, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 319 loss tensor(15732.8125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 320 loss tensor(15410.9590, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 321 loss tensor(15112.2412, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 322 loss tensor(14827.7705, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 323 loss tensor(14596.1475, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 324 loss tensor(14407.9551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 325 loss tensor(14250.3203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 326 loss tensor(14163.9795, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 327 loss tensor(14118.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 328 loss tensor(14124.1914, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 329 loss tensor(14191.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 330 loss tensor(14317.3555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 331 loss tensor(14466.2119, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 332 loss tensor(14647.4736, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 333 loss tensor(14813.7383, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 334 loss tensor(14988.3223, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 335 loss tensor(15211.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 336 loss tensor(15458.9346, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 337 loss tensor(15694.1992, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 338 loss tensor(15988.3594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 339 loss tensor(16330.1836, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 340 loss tensor(16714.4023, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 341 loss tensor(17119.7129, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 342 loss tensor(17520.4941, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 343 loss tensor(17902.7227, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 344 loss tensor(18241.7207, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 345 loss tensor(18553.2949, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 346 loss tensor(18823.0410, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 347 loss tensor(19026.3711, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 348 loss tensor(19145.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 349 loss tensor(19167.4746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 350 loss tensor(19050.4180, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 351 loss tensor(18833.8066, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 352 loss tensor(18530.2539, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 353 loss tensor(18145.6875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 354 loss tensor(17709.9844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 355 loss tensor(17233.4277, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 356 loss tensor(16783.6504, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 357 loss tensor(16413.3789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 358 loss tensor(16064.5234, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 359 loss tensor(15532.0830, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 360 loss tensor(14905.4463, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 361 loss tensor(14340.3086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 362 loss tensor(13901.0176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 363 loss tensor(13533.3311, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 364 loss tensor(13299.9092, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 365 loss tensor(13120.9043, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 366 loss tensor(12965.2695, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 367 loss tensor(12807.5947, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 368 loss tensor(12657.1016, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 369 loss tensor(12489.8564, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 370 loss tensor(12332.2578, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 371 loss tensor(12197.1104, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 372 loss tensor(12062.4336, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 373 loss tensor(11936.8467, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 374 loss tensor(11821.1182, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 375 loss tensor(11720.4980, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 376 loss tensor(11631.1484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 377 loss tensor(11567.1689, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 378 loss tensor(11525.2529, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 379 loss tensor(11487.2744, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 380 loss tensor(11443.0449, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 381 loss tensor(11426.7744, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 382 loss tensor(11448.0850, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 383 loss tensor(11472.2100, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 384 loss tensor(11517.0674, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 385 loss tensor(11589.6914, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 386 loss tensor(11689.1709, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 387 loss tensor(11782.6543, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 388 loss tensor(11847.4893, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 389 loss tensor(11920.9580, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 390 loss tensor(12005.9746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 391 loss tensor(12091.6143, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 392 loss tensor(12168.9795, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 393 loss tensor(12240.5381, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 394 loss tensor(12297.0020, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 395 loss tensor(12349.2852, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 396 loss tensor(12402.0547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 397 loss tensor(12444.2617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 398 loss tensor(12472.5166, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 399 loss tensor(12479.2842, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 400 loss tensor(12491.1484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 401 loss tensor(12512.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 402 loss tensor(12532.3076, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 403 loss tensor(12539.4004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 404 loss tensor(12549.4697, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 405 loss tensor(12553.3740, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 406 loss tensor(12557.9443, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 407 loss tensor(12566.4746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 408 loss tensor(12581.7783, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 409 loss tensor(12603.1230, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 410 loss tensor(12626.9951, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 411 loss tensor(12655.4717, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 412 loss tensor(12688.8418, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 413 loss tensor(12722.5781, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 414 loss tensor(12758.0059, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 415 loss tensor(12798.3877, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 416 loss tensor(12847.9443, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 417 loss tensor(12867.1309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 418 loss tensor(12883.5479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 419 loss tensor(12907.3945, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 420 loss tensor(12936.9736, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 421 loss tensor(12970.9463, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 422 loss tensor(13002.9482, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 423 loss tensor(13034.8418, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 424 loss tensor(13070.0898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 425 loss tensor(13108.3604, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 426 loss tensor(13149.7578, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 427 loss tensor(13189.9629, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 428 loss tensor(13228.1621, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 429 loss tensor(13265.7568, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 430 loss tensor(13303.6025, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 431 loss tensor(13341.3730, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 432 loss tensor(13354.7207, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 433 loss tensor(13363.4199, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 434 loss tensor(13372.8135, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 435 loss tensor(13382.4883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 436 loss tensor(13393.8047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 437 loss tensor(13407.7080, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 438 loss tensor(13418.7520, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 439 loss tensor(13429.7139, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 440 loss tensor(13440.5586, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 441 loss tensor(13450.5234, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 442 loss tensor(13459.0254, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 443 loss tensor(13462.9883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 444 loss tensor(13459.5391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 445 loss tensor(13456.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 446 loss tensor(13455.4014, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 447 loss tensor(13451.5195, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 448 loss tensor(13447.0479, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 449 loss tensor(13445.1377, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 450 loss tensor(13445.5527, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 451 loss tensor(13445.8408, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 452 loss tensor(13444.6738, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 453 loss tensor(13443.8115, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 454 loss tensor(13443.4629, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 455 loss tensor(13445.3027, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 456 loss tensor(13449.9971, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 457 loss tensor(13456.2881, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 458 loss tensor(13463.3760, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 459 loss tensor(13470.8740, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 460 loss tensor(13480.2305, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 461 loss tensor(13490.5869, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 462 loss tensor(13501.1172, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 463 loss tensor(13509.2676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 464 loss tensor(13516.0557, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 465 loss tensor(13520.0488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 466 loss tensor(13523.9160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 467 loss tensor(13529.1035, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 468 loss tensor(13534.7256, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 469 loss tensor(13541.7129, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 470 loss tensor(13550.3154, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 471 loss tensor(13558.4414, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 472 loss tensor(13567.9902, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 473 loss tensor(13575.2070, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 474 loss tensor(13580.9473, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 475 loss tensor(13585.8623, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 476 loss tensor(13590.9424, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 477 loss tensor(13596.9014, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 478 loss tensor(13602.6602, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 479 loss tensor(13611.7373, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 480 loss tensor(13622.5371, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 481 loss tensor(13635.5986, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 482 loss tensor(13653.5137, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 483 loss tensor(13671.6270, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 484 loss tensor(13687.1436, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 485 loss tensor(13698.3262, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 486 loss tensor(13708.8291, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 487 loss tensor(13717.4512, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 488 loss tensor(13718.1777, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 489 loss tensor(13716.7373, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 490 loss tensor(13709.4150, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 491 loss tensor(13705.3008, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 492 loss tensor(13703.4785, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 493 loss tensor(13702.9199, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 494 loss tensor(13702.7627, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 495 loss tensor(13698.2715, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 496 loss tensor(13693.7793, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 497 loss tensor(13688.8525, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 498 loss tensor(13687.7012, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 499 loss tensor(13689.4043, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 500 loss tensor(13694.4551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 501 loss tensor(13700.7598, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 502 loss tensor(13705.6289, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 503 loss tensor(13710.1904, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 504 loss tensor(13715.2910, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 505 loss tensor(13717.6426, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 506 loss tensor(13718.5420, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 507 loss tensor(13718.2100, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 508 loss tensor(13717.8135, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 509 loss tensor(13718.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 510 loss tensor(13717.9971, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 511 loss tensor(13713.0098, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 512 loss tensor(13704.7021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 513 loss tensor(13696.0576, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 514 loss tensor(13685.5488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 515 loss tensor(13673.7871, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 516 loss tensor(13654.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 517 loss tensor(13627.9121, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 518 loss tensor(13598.3350, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 519 loss tensor(13569.1436, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 520 loss tensor(13540.5752, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 521 loss tensor(13509.9160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 522 loss tensor(13477.6982, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 523 loss tensor(13445.6895, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 524 loss tensor(13414.3096, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 525 loss tensor(13384.4756, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 526 loss tensor(13353.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 527 loss tensor(13321.5469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 528 loss tensor(13288.6221, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 529 loss tensor(13254.0859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 530 loss tensor(13217.4268, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 531 loss tensor(13178.8535, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 532 loss tensor(13141.6396, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 533 loss tensor(13103.7676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 534 loss tensor(13066.3350, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 535 loss tensor(13027.2979, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 536 loss tensor(12986.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 537 loss tensor(12943.3018, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 538 loss tensor(12898.8691, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 539 loss tensor(12849.0674, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 540 loss tensor(12798.1035, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 541 loss tensor(12742.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 542 loss tensor(12689.7334, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 543 loss tensor(12641.1211, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 544 loss tensor(12595.8203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 545 loss tensor(12550.8857, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 546 loss tensor(12506.2910, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 547 loss tensor(12458.9102, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 548 loss tensor(12408.5312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 549 loss tensor(12354.8301, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 550 loss tensor(12298.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 551 loss tensor(12239.0068, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 552 loss tensor(12179.8623, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 553 loss tensor(12122.8135, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 554 loss tensor(12065.7402, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 555 loss tensor(12005.9277, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 556 loss tensor(11939.2861, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 557 loss tensor(11870.7422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 558 loss tensor(11804.1309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 559 loss tensor(11739.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 560 loss tensor(11670.8408, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 561 loss tensor(11598.3164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 562 loss tensor(11521.8633, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 563 loss tensor(11437.5508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 564 loss tensor(11349.5127, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 565 loss tensor(11265.4541, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 566 loss tensor(11183.0537, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 567 loss tensor(11091.5166, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 568 loss tensor(10996.9629, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 569 loss tensor(10903.8711, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 570 loss tensor(10815.3770, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 571 loss tensor(10730.5674, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 572 loss tensor(10648.5068, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 573 loss tensor(10570.3877, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 574 loss tensor(10494., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 575 loss tensor(10418.1934, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 576 loss tensor(10344.6982, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 577 loss tensor(10274.3408, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 578 loss tensor(10203.5166, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 579 loss tensor(10136.7236, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 580 loss tensor(10074.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 581 loss tensor(10016.4238, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 582 loss tensor(9962.6973, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 583 loss tensor(9913.7793, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 584 loss tensor(9869.5840, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 585 loss tensor(9832.0645, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 586 loss tensor(9797.5518, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 587 loss tensor(9762.5928, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 588 loss tensor(9721.4756, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 589 loss tensor(9683.4385, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 590 loss tensor(9650.9746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 591 loss tensor(9623.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 592 loss tensor(9596.2061, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 593 loss tensor(9566.2627, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 594 loss tensor(9529.5029, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 595 loss tensor(9486.5166, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 596 loss tensor(9435.7529, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 597 loss tensor(9381.6348, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 598 loss tensor(9324.2988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 599 loss tensor(9262.7930, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 600 loss tensor(9199.1504, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 601 loss tensor(9134.0908, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 602 loss tensor(9068.1514, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 603 loss tensor(8997.4619, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 604 loss tensor(8927.0674, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 605 loss tensor(8857.9990, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 606 loss tensor(8789.4229, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 607 loss tensor(8720.7061, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 608 loss tensor(8653.3848, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 609 loss tensor(8590.3652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 610 loss tensor(8529.2178, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 611 loss tensor(8471.2920, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 612 loss tensor(8417.4492, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 613 loss tensor(8366.6299, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 614 loss tensor(8317.4756, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 615 loss tensor(8266.7275, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 616 loss tensor(8217.3555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 617 loss tensor(8169.0566, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 618 loss tensor(8123.0752, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 619 loss tensor(8079.2915, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 620 loss tensor(8041.5068, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 621 loss tensor(8008.0093, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 622 loss tensor(7977.3379, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 623 loss tensor(7951.4165, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 624 loss tensor(7927.8120, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 625 loss tensor(7904.4429, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 626 loss tensor(7883.6333, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 627 loss tensor(7864.3726, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 628 loss tensor(7843.6738, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 629 loss tensor(7820.8076, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 630 loss tensor(7799.6084, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 631 loss tensor(7779.0366, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 632 loss tensor(7759.6021, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 633 loss tensor(7743.8774, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 634 loss tensor(7731.2100, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 635 loss tensor(7720.6069, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 636 loss tensor(7708.3643, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 637 loss tensor(7698.2612, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 638 loss tensor(7690.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 639 loss tensor(7684.9697, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 640 loss tensor(7681.7959, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 641 loss tensor(7681.8022, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 642 loss tensor(7682.4341, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 643 loss tensor(7682.7544, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 644 loss tensor(7685.3555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 645 loss tensor(7691.4785, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 646 loss tensor(7699.9312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 647 loss tensor(7709.6743, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 648 loss tensor(7720.2095, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 649 loss tensor(7731.4258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 650 loss tensor(7744.1694, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 651 loss tensor(7757.5630, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 652 loss tensor(7769.5850, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 653 loss tensor(7781.9224, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 654 loss tensor(7795.8491, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 655 loss tensor(7811.1401, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 656 loss tensor(7828.0176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 657 loss tensor(7847.8467, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 658 loss tensor(7869.5815, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 659 loss tensor(7894.8545, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 660 loss tensor(7922.8228, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 661 loss tensor(7952.9209, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 662 loss tensor(7984.8462, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 663 loss tensor(8021.5127, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 664 loss tensor(8063.0791, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 665 loss tensor(8107.3608, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 666 loss tensor(8154.5542, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 667 loss tensor(8203.6299, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 668 loss tensor(8254.7432, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 669 loss tensor(8306.8506, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 670 loss tensor(8354.1475, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 671 loss tensor(8397.7119, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 672 loss tensor(8440.8291, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 673 loss tensor(8478.8271, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 674 loss tensor(8511.8447, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 675 loss tensor(8543.4941, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 676 loss tensor(8571.4834, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 677 loss tensor(8598.5293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 678 loss tensor(8624.2266, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 679 loss tensor(8649.3428, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 680 loss tensor(8675.6143, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 681 loss tensor(8699.7686, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 682 loss tensor(8722.0898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 683 loss tensor(8742.4473, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 684 loss tensor(8761.6758, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 685 loss tensor(8781.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 686 loss tensor(8802.3359, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 687 loss tensor(8821.9297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 688 loss tensor(8837.5273, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 689 loss tensor(8852.0449, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 690 loss tensor(8866.9492, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 691 loss tensor(8878.6123, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 692 loss tensor(8891.0361, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 693 loss tensor(8905.5264, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 694 loss tensor(8920.5859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 695 loss tensor(8936.0986, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 696 loss tensor(8951.3428, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 697 loss tensor(8965.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 698 loss tensor(8980.4570, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 699 loss tensor(8994.4102, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 700 loss tensor(9008.7627, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 701 loss tensor(9019.9482, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 702 loss tensor(9028.8955, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 703 loss tensor(9036.4004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-245-0d1ca103f3ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#iter'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "jHYMzoLTbFyR",
        "outputId": "a450c5e3-4ce5-4bf6-d5b2-bbb92e72138d"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa9622ab390>]"
            ]
          },
          "metadata": {},
          "execution_count": 246
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation"
      ],
      "metadata": {
        "id": "twoS2qPPcSPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi[0,0,:,:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmYDRsmlc0-b",
        "outputId": "b211e4f0-acf7-4bf7-fb8f-e2352f927fcb"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psicheck = torch.tensor(psi[0,0,:,:],requires_grad=False)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psicheck)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "Tx_qNIxjcZoa",
        "outputId": "4a7b5fdf-2f26-4c20-e5be-aab97aa22b21"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'psi function with mask')"
            ]
          },
          "metadata": {},
          "execution_count": 248
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psicheck,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "IcEzHkrgcVWx",
        "outputId": "8c27d62a-e2f3-4020-af56-02d5e2e9cb3f"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'v2')"
            ]
          },
          "metadata": {},
          "execution_count": 249
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(v2[:,250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "tM5Nv56YeC9r",
        "outputId": "88001692-ef8a-4ee4-ef56-4246a44eb8dc"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa9620b67d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 250
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Links\n",
        "\n",
        "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
        "\n",
        "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
      ],
      "metadata": {
        "id": "rpGo7xQz6cny"
      }
    }
  ]
}