{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Physics-based loss and machine learing approach in application to fluids flow modelling: 2D flow domains**\n",
        "\n",
        "The program recieves an image of the flow domain and the flow rate value, then calculate velocity distribution. The main idea is power loss minimization. The main unknown function is the stream function $\\psi = \\psi(x_1, x_2)$ that determines the velocity field $\\textbf{V} = [[v_1, v_2]]$, where $v_1 = \\frac{\\partial \\psi}{\\partial x_2}$, $v_2 = - \\frac{\\partial \\psi}{\\partial x_1}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "RJkKJ83igGYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "ozT2l1DxVSOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "s3KFs0M9r7EQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "jPSaJ-z614Tm"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "ydwhZV95sFoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "Go3JwW4hICsK"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "BT8OQ6AkVb6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional functions"
      ],
      "metadata": {
        "id": "Hw2AD3oWsfJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical derivative"
      ],
      "metadata": {
        "id": "2JAf1YAHtV15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mydiff(j,y,dx):\n",
        "  '''The function calculates the first order derivative in a specific direction \n",
        "     'dx' at a specific point 'j' for a given array 'y' \n",
        "     using parabolic approximation\n",
        "  '''\n",
        "  dydx = 0\n",
        "  n = len(y)\n",
        "  if j==0:\n",
        "    dydx=(-y[3]+4*y[2]-3*y[1])/(2*dx)\n",
        "  elif j==n-1:\n",
        "    dydx=(3*y[j]-4*y[j-1]+y[j-2])/(2*dx)\n",
        "  else:\n",
        "    dydx=(y[j+1]-y[j-1])/(2*dx);\n",
        "  return dydx"
      ],
      "metadata": {
        "id": "MSTF3qPgtbn8"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_diff(f, dx1, dx2):\n",
        "  '''function to find partial derivatives of a two variables function:\n",
        "  i - index along x1\n",
        "  j - index along x2\n",
        "  for internal points - central differences e.q. df_dx = (f_{i+1}-f_{i-1})/(2*dx)\n",
        "  for boundaries - left and right finite differences e.q. df_dx = (f_{i+1}-f_{i})/dx or df_dx = (f_{i}-f_{i-1})/dx\n",
        "  '''\n",
        "  n1, n2 = f.shape\n",
        "  df_dx1, df_dx2 = torch.zeros(n1,n2), torch.zeros(n1,n2)\n",
        "  # x1 derivative:\n",
        "  df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:])/(2*dx1)\n",
        "  df_dx1[0,:] = (f[1,:] - f[0,:])/dx1\n",
        "  df_dx1[n1-1,:] = (f[n1-1,:] - f[n1-2,:])/dx1\n",
        "  # x2 derivative:\n",
        "  df_dx2[:, 1:n2-1] = (f[:,2:] - f[:,:-2])/(2*dx2)\n",
        "  df_dx2[:, 0] = (f[:,1] - f[:,0])/dx2\n",
        "  df_dx2[:,n2-1] = (f[:,n2-1] - f[:,n2-2])/dx2\n",
        "  return df_dx1, df_dx2"
      ],
      "metadata": {
        "id": "5P2RND6cYEOK"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical integrals: single and double"
      ],
      "metadata": {
        "id": "1i1RAg4ozeGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singleIntegral(f,lowerLim,upperLim):\n",
        "  '''The function calculates the single integral using Simpson's formula. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the difference between the upper and lower limits.\n",
        "  '''  \n",
        "  sglInt = 0\n",
        "  n = len(f)\n",
        "  x = torch.linspace(0,1,n)\n",
        "  dxn = x[1]-x[0]\n",
        "\n",
        "  for i in range (1, (n-1), 2):\n",
        "    sglInt += (f[i-1] + 4*f[i]+f[i+1])*dxn/3\n",
        "  if (n % 2) == 0:\n",
        "    sglInt += (f[-1]+f[-2])*dxn/2\n",
        "\n",
        "  sglInt = sglInt*(upperLim-lowerLim)\n",
        "\n",
        "  return sglInt"
      ],
      "metadata": {
        "id": "MbSgsSbO0srV"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doublelIntegral(f,lim1,lim2):\n",
        "  '''The function calculates the double integral using Simpson's formula twice. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the differences between the upper and lower limits.\n",
        "  '''\n",
        "  dblInt = 0\n",
        "  n = f.shape\n",
        "  x1 = torch.linspace(0,1,n[0])\n",
        "  x2 = torch.linspace(0,1,n[1])\n",
        "  dx1n = x1[1]-x1[0]\n",
        "  dx2n = x2[1]-x2[0]\n",
        "\n",
        "  for i in range (1, (n[0]-1), 2):\n",
        "    for j in range (1, (n[1]-1), 2):\n",
        "      dblInt += (f[i-1][j-1] + f[i+1][j-1] + f[i-1][j+1] + f[i+1][j+1] + \n",
        "                   4*(f[i][j+1] + f[i][j-1] + f[i-1][j] + f[i+1][j]) + \n",
        "                   16*f[i][j])*dx1n*dx2n/9\n",
        "          \n",
        "  dblInt = dblInt*(lim1[1]-lim1[0])*(lim2[1]-lim2[0])\n",
        "\n",
        "  return (dblInt)"
      ],
      "metadata": {
        "id": "fxibGVL-zkCW"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check double integral "
      ],
      "metadata": {
        "id": "qyl0qTFMj-lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 101\n",
        "x = torch.linspace(0,1,ss)\n",
        "y = torch.linspace(0,1,ss)\n",
        "y = y.reshape(1,-1).t()\n",
        "z = (x*x) * (y*y)\n",
        "print(doublelIntegral(z,[0,1],[0,1]),'- calculated', 1/9, '- exact')"
      ],
      "metadata": {
        "id": "byisjmu7c8C6",
        "outputId": "daf41255-09cf-4e89-e245-7259bdbf6175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1111) - calculated 0.1111111111111111 - exact\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color filter "
      ],
      "metadata": {
        "id": "lon3t_mIeGEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colorFilter(img, color):\n",
        "  white = (255,255,255,255)\n",
        "  black = (0,0,0,255)\n",
        "  width,heigth = img.size\n",
        "  for i in range(width):\n",
        "    for j in range(heigth):\n",
        "      if img.getpixel((i,j)) == color:\n",
        "        img.putpixel((i,j),black)\n",
        "      else:\n",
        "        #print(img.getpixel((i,j)))\n",
        "        img.putpixel((i,j),white)\n",
        "  return (img)"
      ],
      "metadata": {
        "id": "626DXTn0eKR-"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Major functions\n",
        "\n",
        "Distributions: the velocity components [[$v_1$, $v_2$]], the strain rate tensor components [[$\\xi_{ij}$]], $\\xi_{ij}=\\xi_{ji}$ . And the shear rate intensity Î—. "
      ],
      "metadata": {
        "id": "mH8zURs8A1Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def velocityDistr(psi,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = psi.shape\n",
        "  dpsidx1, dpsidx2 = num_diff(psi, dx1n, dx2n)\n",
        "  v1 = dpsidx2/lim2[1]\n",
        "  v2 = - dpsidx1/lim1[1]\n",
        "\n",
        "  return v1,v2"
      ],
      "metadata": {
        "id": "WMUIipgs5t3Q"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2):\n",
        "\n",
        "  n = v1.shape\n",
        "  dv1dx1, dv1dx2 = num_diff(v1, dx1n, dx2n)\n",
        "  dv2dx1, dv2dx2 = num_diff(v2, dx1n, dx2n)\n",
        "\n",
        "  xi11 = dv1dx1/lim1[1]\n",
        "  xi12 = 0.5*(dv1dx2/lim2[1] + dv2dx1/lim1[1])\n",
        "  xi22 = dv2dx2/lim2[1]\n",
        "  EtaEta = (2*(xi11*xi11 + 2*xi12*xi12 + xi22*xi22))\n",
        "\n",
        "  return xi11,xi12,xi22,EtaEta"
      ],
      "metadata": {
        "id": "716qlRJoNglx"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "nzMpruhsYD38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image of the flow domain"
      ],
      "metadata": {
        "id": "itN_H_kFke1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path"
      ],
      "metadata": {
        "id": "3NCXTaNK4V4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " path =  Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss')\n",
        " imgPath = path/'ToyDataset'\n",
        " imgList = imgPath.ls()\n",
        " imgPath.ls()"
      ],
      "metadata": {
        "id": "tDbZIropJMjw",
        "outputId": "acd6e020-f847-4bc2-841a-97513faa410b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates and ball.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates with notch.png'),Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss/ToyDataset/Parallel plates.png')]"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometry\n",
        "The domain of size *'L x L'*  with flow channel is represented as an image of size *'imgSize x imgSize'*. S1 is the upper wall with black label [0 0 0]. S2 and S4 are outlet and inlet surfaces, respectivelly. S3 is the lower wall with blue label [0 0 255]. "
      ],
      "metadata": {
        "id": "ORhTWZZvVw7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = 0.1 # L x L flow domain\n",
        "imgSize = 512 # imgSize x imgSize pixels image\n",
        "imgNo = 2\n",
        "upperWallColor =  (0, 0, 0,255)\n",
        "lowerWallColor =  (0, 0, 255,255)\n",
        "#Normalized coordinates\n",
        "x1n = torch.linspace(0,1,imgSize)\n",
        "x2n = torch.linspace(0,1,imgSize)\n",
        "dx1n = x1n[1] - x1n[0]\n",
        "dx2n = x2n[1] - x2n[0]\n",
        "lim1 = [0, L]\n",
        "lim2 = [0, L]\n",
        "#Visualisation\n",
        "figSize = 3\n",
        "#Training\n",
        "noOfEpoch = 1000\n",
        "learnRate = 0.001"
      ],
      "metadata": {
        "id": "y8Q_jxpUYIEm"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "domainMask "
      ],
      "metadata": {
        "id": "1hKq9A5gtHzs",
        "outputId": "c4606a3d-6b2b-40f1-ee88-89f4607eaf31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB+CAYAAADiI6WIAAABQ0lEQVR4nO3cwQ3AMAgAMVJl/5XpGHmcPQHSiSecmdkh53s9AG8IHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV81N31rr7IxkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkcJHyV8lPBRwkedGeeyRTY+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aOEjxI+Svgo4aN+UssG9+2j5aIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=126x126 at 0x7FA9624A1C50>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create masks for the walls and resize image"
      ],
      "metadata": {
        "id": "45EnY5VmEcjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2n.dtype"
      ],
      "metadata": {
        "id": "SgL2YvbN3rmT",
        "outputId": "aed4807f-b7ce-4977-8d0e-1b050484fd19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "upperWallMask = colorFilter(domainMask, upperWallColor)\n",
        "upperWallMask = upperWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#upperWallMask"
      ],
      "metadata": {
        "id": "lmyMgC4op_o_"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "lowerWallMask = colorFilter(domainMask, lowerWallColor)\n",
        "lowerWallMask = lowerWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#lowerWallMask"
      ],
      "metadata": {
        "id": "FF424vauuCi8"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kinematic properties\n",
        "The velocity is equal to zero on all the surfaces. The flow rate is known."
      ],
      "metadata": {
        "id": "XaVb_Ejsmynq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 1 #flow rate through the inlet (outlet) boundary, m^3/s\n",
        "psim = 0 # lower wall\n",
        "psip = Q # upper wall\n",
        "psi00 = torch.linspace(0,1,imgSize, dtype=torch.float32)*torch.ones(imgSize,imgSize)\n",
        "psi0 = torch.t(psi00)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0)"
      ],
      "metadata": {
        "id": "Gb4BFZNWnBsh",
        "outputId": "0036b705-64e8-445d-9a2a-c3dce7b727da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9627b9f10>"
            ]
          },
          "metadata": {},
          "execution_count": 232
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "psi00.dtype"
      ],
      "metadata": {
        "id": "H-xEZhto3cLN",
        "outputId": "f16180e3-7e5d-4186-b7e9-b22db3061d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wallsMask = (tensor(upperWallMask)[:,:,1]*tensor(lowerWallMask)[:,:,1])\n",
        "inverseUpperWallMask = (tensor(upperWallMask)[:,:,1]/(-255)+1)\n",
        "psi0Masked = (psi0*wallsMask) + (inverseUpperWallMask*Q)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psi0Masked)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "id": "lyOiYXNSUVnK",
        "outputId": "01db208b-be0f-4d6c-ba24-d213923f02aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'psi function with mask')"
            ]
          },
          "metadata": {},
          "execution_count": 234
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Velocity distribution"
      ],
      "metadata": {
        "id": "B7LQzVv63_0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psi0Masked,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "id": "qbVbaBjT3aOd",
        "outputId": "114565be-a180-41b3-cd35-70550e5d1407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'v2')"
            ]
          },
          "metadata": {},
          "execution_count": 235
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dynamic properties\n",
        "The fluid is Newtonian."
      ],
      "metadata": {
        "id": "hvAQmdvsnZQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 1e-3 # koefficient of dynamic viscosity (viscosity), Pa*s"
      ],
      "metadata": {
        "id": "t4YCVOBPneFt"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check exact solution\n",
        "Newtonian fluid flows between parallel plates "
      ],
      "metadata": {
        "id": "wOpHVjQdkxS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=L/5\n",
        "pressureDrop = Q*3*mu*L/(2*h*h*h)\n",
        "internalPower = pressureDrop*Q\n",
        "print('pressure drop',pressureDrop,'internal power',internalPower)"
      ],
      "metadata": {
        "id": "fpG0AV2LlF-W",
        "outputId": "764563a8-a9fc-4c1c-9393-b0f7fefa1bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pressure drop 18.75 internal power 18.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "PhZutgNIyYhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create model\n",
        "Unet architecture [2] is used"
      ],
      "metadata": {
        "id": "FPeLHoR31p1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return torch.sigmoid(self.conv(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        \n",
        "model = UNet(in_channels=1, out_channels=1, init_features=32)"
      ],
      "metadata": {
        "id": "PID82zl-cxN4"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "2yb3P0n1c8df"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "PwikCXOPyPPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learnRate, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "oKBkisM7hASi"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input image"
      ],
      "metadata": {
        "id": "TyTAp5u0yroJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi0Masked.dtype"
      ],
      "metadata": {
        "id": "j6BFOOEv3OhT",
        "outputId": "56acd9c8-814e-491b-b198-97a58c1ba421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = torch.randn((1, 1, 512, 512))\n",
        "x = torch.ones((1, 1, imgSize, imgSize))*psi0Masked\n",
        "#fig = plt.figure(figsize=(3, 3))\n",
        "#plt.imshow(x[0,0,:,:])\n",
        "x.dtype, x.shape"
      ],
      "metadata": {
        "id": "xruHyQ-vdVhz",
        "outputId": "4ab62ace-7c1b-4806-a0ed-f72b6621d0a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.Size([1, 1, 512, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model(x)"
      ],
      "metadata": {
        "id": "f1L8QG9ndbML"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = dx1n*dx2n*lim1[1]*lim2[1]\n",
        "s"
      ],
      "metadata": {
        "id": "osreN0VAdhZw",
        "outputId": "27e3d7dc-d7e2-4b51-de5a-7a64a14e75ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8296e-08)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "\n",
        "for epoch in range(noOfEpoch):\n",
        "  psi = model(x)\n",
        "  psiMasked = (psi[0,0,:,:]*wallsMask) + (inverseUpperWallMask*Q)\n",
        "  print(psi[0,0,:,:].shape)\n",
        "  v1,v2 = velocityDistr(psiMasked,dx1n,dx2n,lim1,lim2)\n",
        "  xi11,xi12,xi22,EtaEta = TksiDistr(v1,v2,dx1n,dx2n,lim1,lim2)\n",
        "  out = 0.5*mu*s*EtaEta.sum() #doublelIntegral(0.5*mu*EtaEta,lim1,lim2) #loss\n",
        "  #out = loss(out)\n",
        "  if out < 1e-6:\n",
        "      break\n",
        "  history.append(out.item())\n",
        "  out.backward()\n",
        "  optimizer.step()\n",
        "  print('#iter',epoch,'loss',out)"
      ],
      "metadata": {
        "id": "CsBCY3g4gspY",
        "outputId": "495a15ae-0695-4cb3-f336-b632dee98804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 512])\n",
            "#iter 0 loss tensor(2890986.7500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 1 loss tensor(1975912.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 2 loss tensor(1612033., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 3 loss tensor(805153.8750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 4 loss tensor(585709.4375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 5 loss tensor(504592.3750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 6 loss tensor(490037.6875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 7 loss tensor(441961.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 8 loss tensor(381599.4375, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 9 loss tensor(379059.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 10 loss tensor(458460.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 11 loss tensor(518667.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 12 loss tensor(469636.9688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 13 loss tensor(363836.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 14 loss tensor(329471.5000, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 15 loss tensor(341686.8750, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 16 loss tensor(371497.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 17 loss tensor(382455.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 18 loss tensor(381368.8438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 19 loss tensor(370433.9062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 20 loss tensor(354106., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 21 loss tensor(332586.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 22 loss tensor(309005.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 23 loss tensor(285170.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 24 loss tensor(263830.5625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 25 loss tensor(246691.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 26 loss tensor(231741.2969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 27 loss tensor(220161.7031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 28 loss tensor(212318.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 29 loss tensor(204040.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 30 loss tensor(193682.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 31 loss tensor(183095.4062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 32 loss tensor(172734.2500, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 33 loss tensor(162555.5781, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 34 loss tensor(153198.3906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 35 loss tensor(144923.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 36 loss tensor(138233.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 37 loss tensor(133752.3906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 38 loss tensor(131420.4844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 39 loss tensor(131589.9219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 40 loss tensor(132693.7031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 41 loss tensor(133705.8281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 42 loss tensor(134043.5000, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 43 loss tensor(133436.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 44 loss tensor(130606.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 45 loss tensor(125846.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 46 loss tensor(120405.8203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 47 loss tensor(115158.9453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 48 loss tensor(110748.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 49 loss tensor(107316.2188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 50 loss tensor(104932.9609, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 51 loss tensor(103888.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 52 loss tensor(103647.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 53 loss tensor(103630.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 54 loss tensor(103418.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 55 loss tensor(102123.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 56 loss tensor(101296.2891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 57 loss tensor(100147.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 58 loss tensor(98516.8125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 59 loss tensor(96475.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 60 loss tensor(94008.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 61 loss tensor(91233.2344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 62 loss tensor(88050.0312, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 63 loss tensor(84538.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 64 loss tensor(81073.4141, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 65 loss tensor(77861.3281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 66 loss tensor(74996.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 67 loss tensor(72424.8984, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 68 loss tensor(70388.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 69 loss tensor(68808.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 70 loss tensor(67768.4688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 71 loss tensor(67366.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 72 loss tensor(67499.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 73 loss tensor(67955.1406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 74 loss tensor(68654.8828, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 75 loss tensor(69565.2422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 76 loss tensor(70265.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 77 loss tensor(70432.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 78 loss tensor(70393.5156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 79 loss tensor(70221.6172, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 80 loss tensor(69773.1719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 81 loss tensor(69051.7734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 82 loss tensor(68154.1641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 83 loss tensor(67175.1406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 84 loss tensor(66052.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 85 loss tensor(64817.5078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 86 loss tensor(63533.4453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 87 loss tensor(62150.2070, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 88 loss tensor(60761.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 89 loss tensor(59313.6953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 90 loss tensor(57825.1211, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 91 loss tensor(56185.0352, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 92 loss tensor(54567.7383, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 93 loss tensor(53270.3398, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 94 loss tensor(52236.1562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 95 loss tensor(51612.8359, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 96 loss tensor(51184.5508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 97 loss tensor(51047.3320, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 98 loss tensor(51205.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 99 loss tensor(51491.9805, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 100 loss tensor(51356.0703, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 101 loss tensor(51037.1523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 102 loss tensor(50465.5898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 103 loss tensor(49880.2617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 104 loss tensor(49455.1641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 105 loss tensor(49178.6406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 106 loss tensor(48824.7812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 107 loss tensor(48604.4258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 108 loss tensor(48553.3164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 109 loss tensor(48505.0977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 110 loss tensor(48361.0117, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 111 loss tensor(48210.9688, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 112 loss tensor(48215.4570, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 113 loss tensor(48100.4062, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 114 loss tensor(47885.8359, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 115 loss tensor(47592.2148, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 116 loss tensor(47445.1250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 117 loss tensor(47018.7891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 118 loss tensor(46532.8086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 119 loss tensor(46088.5117, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 120 loss tensor(45439.0742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 121 loss tensor(44531.9180, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 122 loss tensor(43576.1523, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 123 loss tensor(42537.7422, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 124 loss tensor(41635.1953, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 125 loss tensor(40633.8594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 126 loss tensor(39352.2461, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 127 loss tensor(38262.7969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 128 loss tensor(37029.8555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 129 loss tensor(35900.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 130 loss tensor(34864.2891, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 131 loss tensor(33965.6289, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 132 loss tensor(33192.5742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 133 loss tensor(32616.4883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 134 loss tensor(32253.5957, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 135 loss tensor(32188.9492, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 136 loss tensor(32248.3477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 137 loss tensor(32638.5020, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 138 loss tensor(33320.9766, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 139 loss tensor(34240.7617, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 140 loss tensor(35294.6094, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 141 loss tensor(36576.4180, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 142 loss tensor(37960.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 143 loss tensor(39437.5625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 144 loss tensor(40932.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 145 loss tensor(42315.8867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 146 loss tensor(43642.8086, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 147 loss tensor(44762.8906, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 148 loss tensor(45436.9102, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 149 loss tensor(45584.2812, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 150 loss tensor(45179., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 151 loss tensor(44317.5586, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 152 loss tensor(42897.0508, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 153 loss tensor(41065.0039, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 154 loss tensor(38881.0781, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 155 loss tensor(36388.4219, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 156 loss tensor(33798.6758, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 157 loss tensor(31164.4004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 158 loss tensor(28634.3652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 159 loss tensor(26409.8457, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 160 loss tensor(24626.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 161 loss tensor(23431.5977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 162 loss tensor(22957.0215, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 163 loss tensor(23259.4551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 164 loss tensor(24379.5020, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 165 loss tensor(26336.8027, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 166 loss tensor(29065.1992, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 167 loss tensor(32485.7363, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 168 loss tensor(36498.3672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 169 loss tensor(40938.8398, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 170 loss tensor(45656.9453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 171 loss tensor(50465.4297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 172 loss tensor(55155.9961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 173 loss tensor(59517.0859, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 174 loss tensor(63383.3633, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 175 loss tensor(66730.3203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 176 loss tensor(69281.3672, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 177 loss tensor(70857.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 178 loss tensor(71516.2969, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 179 loss tensor(71257.4844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 180 loss tensor(70318.6641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 181 loss tensor(68538.8203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 182 loss tensor(65934.4453, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 183 loss tensor(62606.5742, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 184 loss tensor(58420.1328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 185 loss tensor(53681.0391, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 186 loss tensor(49126.5820, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 187 loss tensor(44615.6562, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 188 loss tensor(40415.7305, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 189 loss tensor(36789.6328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 190 loss tensor(33783.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 191 loss tensor(31159.2988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 192 loss tensor(28769.1094, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 193 loss tensor(26613.9980, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 194 loss tensor(25060.2070, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 195 loss tensor(23807.8184, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 196 loss tensor(22815.7715, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 197 loss tensor(22015.8145, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 198 loss tensor(21369.0977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 199 loss tensor(20869.9883, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 200 loss tensor(20490.9355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 201 loss tensor(20229.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 202 loss tensor(20040.0078, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 203 loss tensor(19885.6719, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 204 loss tensor(19764.8691, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 205 loss tensor(19676.1348, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 206 loss tensor(19614.3613, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 207 loss tensor(19577.1387, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 208 loss tensor(19553.8594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 209 loss tensor(19537.3477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 210 loss tensor(19519.9238, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 211 loss tensor(19499.4160, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 212 loss tensor(19485.5996, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 213 loss tensor(19478.3867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 214 loss tensor(19470.7734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 215 loss tensor(19461.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 216 loss tensor(19442.0176, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 217 loss tensor(19436.5410, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 218 loss tensor(19458.0469, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 219 loss tensor(19486.2676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 220 loss tensor(19522.4961, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 221 loss tensor(19560.9004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 222 loss tensor(19595.6367, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 223 loss tensor(19634.1230, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 224 loss tensor(19685.3457, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 225 loss tensor(19739.0762, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 226 loss tensor(19784.7266, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 227 loss tensor(19825.4785, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 228 loss tensor(19858.5898, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 229 loss tensor(19883.5547, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 230 loss tensor(19892.1797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 231 loss tensor(19907.7734, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 232 loss tensor(19920.1465, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 233 loss tensor(19927.7188, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 234 loss tensor(19935.8340, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 235 loss tensor(19964.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 236 loss tensor(19986.0156, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 237 loss tensor(20006.5879, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 238 loss tensor(20029.6797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 239 loss tensor(20037.4727, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 240 loss tensor(20018.7578, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 241 loss tensor(20009.5664, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 242 loss tensor(20001.1406, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 243 loss tensor(19985.3867, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 244 loss tensor(19960., grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 245 loss tensor(19900.8789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 246 loss tensor(19829.7441, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 247 loss tensor(19758.3125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 248 loss tensor(19697.3047, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 249 loss tensor(19668.3164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 250 loss tensor(19662.4746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 251 loss tensor(19710.6133, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 252 loss tensor(19788.4805, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 253 loss tensor(19902.0625, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 254 loss tensor(20007.1328, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 255 loss tensor(20115.2031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 256 loss tensor(20236.7461, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 257 loss tensor(20373.2988, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 258 loss tensor(20557.7344, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 259 loss tensor(20772.6641, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 260 loss tensor(20971.6484, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 261 loss tensor(21154.7773, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 262 loss tensor(21331.7207, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 263 loss tensor(21504.1973, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 264 loss tensor(21657.6250, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 265 loss tensor(21786.9766, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 266 loss tensor(21892.3613, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 267 loss tensor(21966.4727, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 268 loss tensor(22010.5430, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 269 loss tensor(22031.4336, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 270 loss tensor(22026.4922, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 271 loss tensor(21989.8477, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 272 loss tensor(21921.2949, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 273 loss tensor(21819.6426, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 274 loss tensor(21684.7402, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 275 loss tensor(21527.3438, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 276 loss tensor(21329.6309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 277 loss tensor(21104.0488, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 278 loss tensor(20857.1797, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 279 loss tensor(20616.8164, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 280 loss tensor(20400.6895, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 281 loss tensor(20218.0117, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 282 loss tensor(20034.3828, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 283 loss tensor(19792.5430, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 284 loss tensor(19463.9512, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 285 loss tensor(19124.8457, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 286 loss tensor(18789.1543, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 287 loss tensor(18492.3789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 288 loss tensor(18301.2227, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 289 loss tensor(18180.4277, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 290 loss tensor(18155.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 291 loss tensor(18185.8652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 292 loss tensor(18206.4121, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 293 loss tensor(18230.9258, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 294 loss tensor(18359.9668, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 295 loss tensor(18584.2031, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 296 loss tensor(18947.6680, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 297 loss tensor(19360.7227, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 298 loss tensor(19736.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 299 loss tensor(19915.3281, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 300 loss tensor(19915.5273, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 301 loss tensor(19796.6113, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 302 loss tensor(19567.3652, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 303 loss tensor(19360.4609, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 304 loss tensor(19174.7480, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 305 loss tensor(18983.9395, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 306 loss tensor(18748.6309, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 307 loss tensor(18503.1777, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 308 loss tensor(18290.0977, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 309 loss tensor(18072.1465, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 310 loss tensor(17857.3633, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 311 loss tensor(17653.0527, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 312 loss tensor(17500.9004, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 313 loss tensor(17372.9297, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 314 loss tensor(17200.7832, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 315 loss tensor(16967.4141, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 316 loss tensor(16702.6191, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 317 loss tensor(16389.7676, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 318 loss tensor(16066.9189, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 319 loss tensor(15732.8125, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 320 loss tensor(15410.9590, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 321 loss tensor(15112.2412, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 322 loss tensor(14827.7705, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 323 loss tensor(14596.1475, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 324 loss tensor(14407.9551, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 325 loss tensor(14250.3203, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 326 loss tensor(14163.9795, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 327 loss tensor(14118.0293, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 328 loss tensor(14124.1914, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 329 loss tensor(14191.6494, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 330 loss tensor(14317.3555, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 331 loss tensor(14466.2119, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 332 loss tensor(14647.4736, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 333 loss tensor(14813.7383, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 334 loss tensor(14988.3223, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 335 loss tensor(15211.4355, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 336 loss tensor(15458.9346, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 337 loss tensor(15694.1992, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 338 loss tensor(15988.3594, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 339 loss tensor(16330.1836, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 340 loss tensor(16714.4023, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 341 loss tensor(17119.7129, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 342 loss tensor(17520.4941, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 343 loss tensor(17902.7227, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 344 loss tensor(18241.7207, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 345 loss tensor(18553.2949, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 346 loss tensor(18823.0410, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 347 loss tensor(19026.3711, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 348 loss tensor(19145.1875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 349 loss tensor(19167.4746, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 350 loss tensor(19050.4180, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 351 loss tensor(18833.8066, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 352 loss tensor(18530.2539, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 353 loss tensor(18145.6875, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 354 loss tensor(17709.9844, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 355 loss tensor(17233.4277, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 356 loss tensor(16783.6504, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n",
            "#iter 357 loss tensor(16413.3789, grad_fn=<MulBackward0>)\n",
            "torch.Size([512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[5:])"
      ],
      "metadata": {
        "id": "jHYMzoLTbFyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation"
      ],
      "metadata": {
        "id": "twoS2qPPcSPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi[0,0,:,:].shape"
      ],
      "metadata": {
        "id": "cmYDRsmlc0-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psicheck = torch.tensor(psi[0,0,:,:],requires_grad=False)\n",
        "fig = plt.figure(figsize=(figSize, figSize))\n",
        "plt.imshow(psicheck)\n",
        "plt.title('psi function with mask')"
      ],
      "metadata": {
        "id": "Tx_qNIxjcZoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1, v2 = velocityDistr(psicheck,dx1n,dx2n,lim1,lim2)\n",
        "fig = plt.figure(figsize=(figSize*2, figSize))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(v1)\n",
        "plt.title('v1')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(v2)\n",
        "plt.title('v2')"
      ],
      "metadata": {
        "id": "IcEzHkrgcVWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(v2[:,250])"
      ],
      "metadata": {
        "id": "tM5Nv56YeC9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Links\n",
        "\n",
        "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
        "\n",
        "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
      ],
      "metadata": {
        "id": "rpGo7xQz6cny"
      }
    }
  ]
}