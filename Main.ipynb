{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Physics-based loss and machine learing approach in application to fluids flow modelling: 2D flow domains**\n",
        "\n",
        "The program recieves an image of the flow domain and the flow rate value, then calculate velocity distribution. The main idea is power loss minimization. The main unknown function is the stream function $\\psi = \\psi(x_1, x_2)$ that determines the velocity field $\\textbf{V} = [[v_1, v_2]]$, where $v_1 = \\frac{\\partial \\psi}{\\partial x_2}$, $v_2 = - \\frac{\\partial \\psi}{\\partial x_1}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "RJkKJ83igGYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "ozT2l1DxVSOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "s3KFs0M9r7EQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPSaJ-z614Tm"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "ydwhZV95sFoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "Go3JwW4hICsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "BT8OQ6AkVb6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional functions"
      ],
      "metadata": {
        "id": "Hw2AD3oWsfJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical derivative"
      ],
      "metadata": {
        "id": "2JAf1YAHtV15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mydiff(j,y,dx):\n",
        "  '''The function calculates the first order derivative in a specific direction \n",
        "     'dx' at a specific point 'j' for a given array 'y' \n",
        "     using parabolic approximation\n",
        "  '''\n",
        "  dydx = 0\n",
        "  n = len(y)\n",
        "  if j==0:\n",
        "    dydx=(-y[3]+4*y[2]-3*y[1])/(2*dx)\n",
        "  elif j==n-1:\n",
        "    dydx=(3*y[j]-4*y[j-1]+y[j-2])/(2*dx)\n",
        "  else:\n",
        "    dydx=(y[j+1]-y[j-1])/(2*dx);\n",
        "  return (dydx)"
      ],
      "metadata": {
        "id": "MSTF3qPgtbn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_diff(f, dx1, dx2):\n",
        "  '''function to find partial derivatives of a two variables function:\n",
        "  i - index along x1\n",
        "  j - index along x2\n",
        "  for internal points - central differences e.q. df_dx = (f_{i+1}-f_{i-1})/(2*dx)\n",
        "  for boundaries - left and right finite differences e.q. df_dx = (f_{i+1}-f_{i})/dx or df_dx = (f_{i}-f_{i-1})/dx\n",
        "  '''\n",
        "  n1, n2 = f.shape\n",
        "  df_dx1, df_dx2 = torch.zeros(n1,n2), torch.zeros(n1,n2)\n",
        "  # x1 derivative:\n",
        "  df_dx1[1:n1-1,:] = (f[2:,:] - f[:-2,:])/(2*dx1)\n",
        "  df_dx1[0,:] = (f[1,:] - f[0,:])/dx1\n",
        "  df_dx1[n1-1,:] = (f[n1-1,:] - f[n1-2,:])/dx1\n",
        "  # x2 derivative:\n",
        "  df_dx2[:, 1:n2-1] = (f[:,2:] - f[:,:-2])/(2*dx2)\n",
        "  df_dx2[:, 0] = (f[:,1] - f[:,0])/dx2\n",
        "  df_dx2[:,n2-1] = (f[:,n2-1] - f[:,n2-2])/dx2\n",
        "  return df_dx1, df_dx2"
      ],
      "metadata": {
        "id": "5P2RND6cYEOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical integrals: single and double"
      ],
      "metadata": {
        "id": "1i1RAg4ozeGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singleIntegral(f,lowerLim,upperLim):\n",
        "  '''The function calculates the single integral using Simpson's formula. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the difference between the upper and lower limits.\n",
        "  '''  \n",
        "  sglInt = 0\n",
        "  n = len(f)\n",
        "  x = torch.linspace(0,1,n)\n",
        "  dxn = x[1]-x[0]\n",
        "\n",
        "  for i in range (1, (n-1), 2):\n",
        "    sglInt += (f[i-1] + 4*f[i]+f[i+1])*dxn/3\n",
        "  if (n % 2) == 0:\n",
        "    sglInt += (f[-1]+f[-2])*dxn/2\n",
        "\n",
        "  sglInt = sglInt*(upperLim-lowerLim)\n",
        "\n",
        "  return (sglInt)"
      ],
      "metadata": {
        "id": "MbSgsSbO0srV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doublelIntegral(f,lim1,lim2):\n",
        "  '''The function calculates the double integral using Simpson's formula twice. \n",
        "     The formula limits are uniform and set from 0 to 1. So, the obtained\n",
        "     result is multiplied by the differences between the upper and lower limits.\n",
        "  '''\n",
        "  dblInt = 0\n",
        "  n = f.shape\n",
        "  x1 = torch.linspace(0,1,n[0])\n",
        "  x2 = torch.linspace(0,1,n[1])\n",
        "  dx1n = x1[1]-x1[0]\n",
        "  dx2n = x2[1]-x2[0]\n",
        "\n",
        "  for i in range (1, (n[0]-1), 2):\n",
        "    for j in range (1, (n[1]-1), 2):\n",
        "      dblInt += (f[i-1][j-1] + f[i+1][j-1] + f[i-1][j+1] + f[i+1][j+1] + \n",
        "                   4*(f[i][j+1] + f[i][j-1] + f[i-1][j] + f[i+1][j]) + \n",
        "                   16*f[i][j])*dx1n*dx2n/9\n",
        "          \n",
        "  dblInt = dblInt*(lim1[1]-lim1[0])*(lim2[1]-lim2[0])\n",
        "\n",
        "  return (dblInt)"
      ],
      "metadata": {
        "id": "fxibGVL-zkCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check double integral "
      ],
      "metadata": {
        "id": "qyl0qTFMj-lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 101\n",
        "x = torch.linspace(0,1,ss)\n",
        "y = torch.linspace(0,1,ss)\n",
        "y = y.reshape(1,-1).t()\n",
        "z = (x*x) * (y*y)\n",
        "print(doublelIntegral(z,[0,1],[0,1]),'- calculated', 1/9, '- exact')"
      ],
      "metadata": {
        "id": "byisjmu7c8C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color filter "
      ],
      "metadata": {
        "id": "lon3t_mIeGEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colorFilter(img, color):\n",
        "  white = (255,255,255,255)\n",
        "  black = (0,0,0,255)\n",
        "  width,heigth = img.size\n",
        "  for i in range(width):\n",
        "    for j in range(heigth):\n",
        "      if img.getpixel((i,j)) == color:\n",
        "        img.putpixel((i,j),black)\n",
        "      else:\n",
        "        #print(img.getpixel((i,j)))\n",
        "        img.putpixel((i,j),white)\n",
        "  return (img)"
      ],
      "metadata": {
        "id": "626DXTn0eKR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Major functions\n",
        "\n",
        "Distributions: the velocity components [[$v_1$, $v_2$]], the strain rate tensor components [[$\\xi_{ij}$]], $\\xi_{ij}=\\xi_{ji}$ . And the shear rate intensity Î—. "
      ],
      "metadata": {
        "id": "mH8zURs8A1Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def velocityDistr(psi,lim1,lim2):\n",
        "\n",
        "  n = psi.shape\n",
        "\n",
        "  \n",
        "  v1 = torch.zeros(n)\n",
        "  v2 = torch.zeros(n)\n",
        "\n",
        "  x1 = torch.linspace(0,1,n[0])\n",
        "  x2 = torch.linspace(0,1,n[1])\n",
        "  dx1n = x1[1]-x1[0]\n",
        "  dx2n = x2[1]-x2[0]\n",
        "\n",
        "  for i in range (n[0]):\n",
        "    for j in range (n[1]):\n",
        "      # v1[i][j] = - mydiff(i,psi[:,j],dx2n)/lim2[1]\n",
        "      v2[i][j] = - mydiff(j,psi[i,:],dx1n)/lim1[1]\n",
        "\n",
        "  return (v1,v2)"
      ],
      "metadata": {
        "id": "WMUIipgs5t3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dpsi_dx1, dpsi_dx2 = num_diff(psi, dx1, dx2)"
      ],
      "metadata": {
        "id": "uUHJYc9VgPzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TksiDistr(v1,v2,lim1,lim2):\n",
        "\n",
        "  n = v1.shape\n",
        "  xi11 = torch.zeros(n)\n",
        "  xi12 = torch.zeros(n)\n",
        "  xi22 = torch.zeros(n)\n",
        "  Eta = torch.zeros(n)\n",
        "  Eta2 =torch.zeros(n)\n",
        "\n",
        "  x1 = torch.linspace(0,1,n[0])\n",
        "  x2 = torch.linspace(0,1,n[1])\n",
        "  dx1n = x1[1]-x1[0]\n",
        "  dx2n = x2[1]-x2[0]\n",
        "\n",
        "  for i in range (n[0]):\n",
        "    for j in range (n[1]):\n",
        "      xi11[i][j] = mydiff(i,v1[i,:],dx1n)/lim1[1] \n",
        "      xi12[i][j] = 0.5*((mydiff(j,v1[:,j],dx2n)/lim2[1])+\n",
        "                         (mydiff(i,v2[i,:],dx1n)/lim1[1]))\n",
        "      xi22[i][j] = mydiff(j,v2[:,j],dx2n)/lim2[1]\n",
        "      #Eta[i][j] = torch.sqrt(2*(xi11[i][j]*xi11[i][j] + \n",
        "      #                          2*xi12[i][j]*xi12[i][j] + \n",
        "      #                          xi22[i][j]*xi22[i][j]))\n",
        "      Eta2[i][j] = (2*(xi11[i][j]*xi11[i][j] + \n",
        "                                2*xi12[i][j]*xi12[i][j] + \n",
        "                                xi22[i][j]*xi22[i][j]))\n",
        "\n",
        "  return (xi11,xi12,xi22,Eta2)"
      ],
      "metadata": {
        "id": "716qlRJoNglx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "nzMpruhsYD38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image of the flow domain"
      ],
      "metadata": {
        "id": "itN_H_kFke1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path"
      ],
      "metadata": {
        "id": "3NCXTaNK4V4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " path =  Path('/content/gdrive/MyDrive/study/Publications/2022/IEEE-CEC-2022/physical-loss')\n",
        " imgPath = path/'ToyDataset'\n",
        " imgList = imgPath.ls()\n",
        " imgPath.ls()"
      ],
      "metadata": {
        "id": "tDbZIropJMjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometry\n",
        "The domain of size *'L x L'*  with flow channel is represented as an image of size *'imgSize x imgSize'*. S1 is the upper wall with black label [0 0 0]. S2 and S4 are outlet and inlet surfaces, respectivelly. S3 is the lower wall with blue label [0 0 255]. "
      ],
      "metadata": {
        "id": "ORhTWZZvVw7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = 0.1 # L x L flow domain\n",
        "imgSize = 512 # imgSize x imgSize pixels image\n",
        "imgNo = 2\n",
        "upperWallColor =  (0, 0, 0,255)\n",
        "lowerWallColor =  (0, 0, 255,255)\n",
        "#Normalized coordinates\n",
        "x1n = torch.linspace(0,1,imgSize)\n",
        "x2n = torch.linspace(0,1,imgSize)\n",
        "dx1n = x1n[1] - x1n[0]\n",
        "dx2n = x2n[1] - x2n[0]\n",
        "lim1 = [0, L]\n",
        "lim2 = [0, L]"
      ],
      "metadata": {
        "id": "y8Q_jxpUYIEm",
        "outputId": "ba30e27a-c04c-472a-ea07-c5c432109c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9d4b79436f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlowerWallColor\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Normalized coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx1n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx2n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdx1n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx1n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "domainMask "
      ],
      "metadata": {
        "id": "1hKq9A5gtHzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create masks for the walls and resize image"
      ],
      "metadata": {
        "id": "45EnY5VmEcjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2n.dtype"
      ],
      "metadata": {
        "id": "SgL2YvbN3rmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "upperWallMask = colorFilter(domainMask, upperWallColor)\n",
        "upperWallMask = upperWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#upperWallMask"
      ],
      "metadata": {
        "id": "lmyMgC4op_o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domainMask = Image.open(imgList[imgNo])\n",
        "lowerWallMask = colorFilter(domainMask, lowerWallColor)\n",
        "lowerWallMask = lowerWallMask.resize((imgSize,imgSize),resample=4)\n",
        "#lowerWallMask"
      ],
      "metadata": {
        "id": "FF424vauuCi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kinematic properties\n",
        "The velocity is equal to zero on all the surfaces. The flow rate is known."
      ],
      "metadata": {
        "id": "XaVb_Ejsmynq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 1 #flow rate through the inlet (outlet) boundary, m^3/s\n",
        "psim = 0 # lower wall\n",
        "psip = Q # upper wall\n",
        "psi00 = torch.linspace(0,1,imgSize, dtype=torch.float32)*torch.ones(imgSize,imgSize)\n",
        "psi0 = torch.t(psi00)\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "plt.imshow(psi0)"
      ],
      "metadata": {
        "id": "Gb4BFZNWnBsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psi00.dtype"
      ],
      "metadata": {
        "id": "H-xEZhto3cLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wallsMask = (tensor(upperWallMask)[:,:,1]*tensor(lowerWallMask)[:,:,1])\n",
        "inverseUpperWallMask = (tensor(upperWallMask)[:,:,1]/(-255)+1)\n",
        "psi0Masked = (psi0*wallsMask) + (inverseUpperWallMask*Q)\n",
        "fig = plt.figure(figsize=(3, 3))\n",
        "plt.imshow(psi0Masked)"
      ],
      "metadata": {
        "id": "lyOiYXNSUVnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qbVbaBjT3aOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wallsMask[:,1]"
      ],
      "metadata": {
        "id": "xwQwMI3Vwp3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(tensor(upperWallMask)[:,1,1]/(-255)+1)*Q"
      ],
      "metadata": {
        "id": "WwjsdnrqMj9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#psi0Masked[:,1]"
      ],
      "metadata": {
        "id": "Nl95DnF3spvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dynamic properties\n",
        "The fluid is Newtonian."
      ],
      "metadata": {
        "id": "hvAQmdvsnZQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 1e-3 # koefficient of dynamic viscosity (viscosity), Pa*s"
      ],
      "metadata": {
        "id": "t4YCVOBPneFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "PhZutgNIyYhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create model\n",
        "Unet architecture [2] is used"
      ],
      "metadata": {
        "id": "FPeLHoR31p1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return torch.sigmoid(self.conv(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        \n",
        "model = UNet(in_channels=1, out_channels=1, init_features=32)"
      ],
      "metadata": {
        "id": "PID82zl-cxN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "2yb3P0n1c8df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "PwikCXOPyPPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "oKBkisM7hASi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input image"
      ],
      "metadata": {
        "id": "TyTAp5u0yroJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psi0Masked.dtype"
      ],
      "metadata": {
        "id": "j6BFOOEv3OhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x = torch.randn((1, 1, 512, 512))\n",
        "x = torch.ones((1, 1, imgSize, imgSize))*psi0Masked\n",
        "#fig = plt.figure(figsize=(3, 3))\n",
        "#plt.imshow(x[0,0,:,:])\n",
        "x.dtype, x.shape"
      ],
      "metadata": {
        "id": "xruHyQ-vdVhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(x)"
      ],
      "metadata": {
        "id": "f1L8QG9ndbML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "osreN0VAdhZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "for epoch in range(100):\n",
        "  psi = model(x)\n",
        "  print(psi[0,0,:,:].shape)\n",
        "  v1,v2 = velocityDistr(psi[0,0,:,:],lim1,lim2)\n",
        "  xi11,xi12,xi22,Eta2 = TksiDistr(v1,v2,lim1,lim2)\n",
        "  out = doublelIntegral(0.5*mu*Eta2,lim1,lim2) #loss\n",
        "  #out = loss(out)\n",
        "  if out < 1e-6:\n",
        "      break\n",
        "  history.append(out.item())\n",
        "  out.backward()\n",
        "  optimizer.step()\n",
        "  print('loss',out)"
      ],
      "metadata": {
        "id": "CsBCY3g4gspY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Links\n",
        "\n",
        "[1]. https://github.com/Mechanics-Mechatronics-and-Robotics/Mathematical_modelling/blob/main/Practice_1_by_IStebakov.ipynb\n",
        "\n",
        "[2]. https://github.com/mateuszbuda/brain-segmentation-pytorch"
      ],
      "metadata": {
        "id": "rpGo7xQz6cny"
      }
    }
  ]
}